{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allstate Purchase Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, feature selection is performed before buliding multinomial logistic regression to predict the purchase likelyhood. Naive bayes is implemented from scatch to tackle the limitation of the original one can only work on binary categorical predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as st\n",
    "import sympy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomail Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the below functions are written by my instructor Dr. Ming Long Lam\n",
    "# Define a function to visualize the percent of a particular target category by a nominal predictor\n",
    "def TargetPercentByNominal (\n",
    "   targetVar,       # target variable\n",
    "   predictor):      # nominal predictor\n",
    "\n",
    "   countTable = pandas.crosstab(index = predictor, columns = targetVar, margins = True, dropna = True)\n",
    "   x = countTable.drop('All', 1)\n",
    "   percentTable = countTable.div(x.sum(1), axis='index')*100\n",
    "\n",
    "   print(\"Frequency Table: \\n\")\n",
    "   print(countTable)\n",
    "   print( )\n",
    "   print(\"Percent Table: \\n\")\n",
    "   print(percentTable)\n",
    "    \n",
    "    \n",
    "# A function that find alias parameters (redundant columns)\n",
    "def find_alias(df, inds):\n",
    "    alias = []\n",
    "    columns = df.columns\n",
    "    for i in range(len(df.columns)):\n",
    "        if i not in inds:\n",
    "            alias.append(columns[i])\n",
    "    return alias\n",
    "\n",
    "\n",
    "# A function that returns the columnwise product of two dataframes (must have same number of rows)\n",
    "def create_interaction (df1, df2):\n",
    "    name1 = df1.columns\n",
    "    name2 = df2.columns\n",
    "    result_df = pd.DataFrame()\n",
    "    for col1 in name1:\n",
    "        for col2 in name2:\n",
    "            interaction_col = col1 + \" * \" + col2\n",
    "            result_df[interaction_col] = df1[col1] * df2[col2]\n",
    "    return result_df\n",
    "\n",
    "# A function that find the non-aliased columns, fit a logistic model, and return the full parameter estimates\n",
    "def build_mnlogit (fullX, y, debug = 'N'):\n",
    "    # Number of all parameters\n",
    "    nFullParam = fullX.shape[1]\n",
    "\n",
    "    # Number of target categories\n",
    "    y_category = y.cat.categories\n",
    "    nYCat = len(y_category)\n",
    "\n",
    "    # Find the non-redundant columns in the design matrix fullX\n",
    "    reduced_form, inds = sympy.Matrix(fullX.values).rref()\n",
    "\n",
    "    # These are the column numbers of the non-redundant columns\n",
    "    if (debug == 'Y'):\n",
    "        print('Column Numbers of the Non-redundant Columns:')\n",
    "        print(inds)\n",
    "        print()\n",
    "\n",
    "    # Extract only the non-redundant columns for modeling\n",
    "    X = fullX.iloc[:, list(inds)]\n",
    "\n",
    "    # The number of free parameters\n",
    "    thisDF = len(inds) * (nYCat - 1)\n",
    "\n",
    "    # Build a multionomial logistic model\n",
    "    logit = st.MNLogit(y, X)\n",
    "    thisFit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "    thisParameter = thisFit.params\n",
    "    thisLLK = logit.loglike(thisParameter.values)\n",
    "\n",
    "    if (debug == 'Y'):\n",
    "        print(thisFit.summary())\n",
    "        print(\"Model Parameter Estimates:\\n\", thisParameter)\n",
    "        print(\"Model Log-Likelihood Value =\", thisLLK)\n",
    "        print(\"Number of Free Parameters =\", thisDF)\n",
    "        print()\n",
    "\n",
    "    # Recreat the estimates of the full parameters\n",
    "    workParams = pd.DataFrame(np.zeros(shape = (nFullParam, (nYCat - 1))))\n",
    "    workParams = workParams.set_index(keys = fullX.columns)\n",
    "    fullParams = pd.merge(workParams, thisParameter, how = \"left\", left_index = True, right_index = True)\n",
    "    fullParams = fullParams.drop(columns = '0_x').fillna(0.0)\n",
    "\n",
    "    # Return model statistics\n",
    "    return (inds, thisLLK, thisDF, fullParams)\n",
    "\n",
    "\n",
    "# Define a function that performs the Chi-square test\n",
    "def ChiSquareTest (\n",
    "    xCat,           # input categorical feature\n",
    "    yCat,           # input categorical target variable\n",
    "    debug = 'N'     # debugging flag (Y/N) \n",
    "    ):\n",
    "\n",
    "    obsCount = pd.crosstab(index = xCat, columns = yCat, margins = False, dropna = True)\n",
    "    cTotal = obsCount.sum(axis = 1)\n",
    "    rTotal = obsCount.sum(axis = 0)\n",
    "    nTotal = np.sum(rTotal)\n",
    "    expCount = np.outer(cTotal, (rTotal / nTotal))\n",
    "\n",
    "    if (debug == 'Y'):\n",
    "        print('Observed Count:\\n', obsCount)\n",
    "        print('Column Total:\\n', cTotal)\n",
    "        print('Row Total:\\n', rTotal)\n",
    "        print('Overall Total:\\n', nTotal)\n",
    "        print('Expected Count:\\n', expCount)\n",
    "        print('\\n')\n",
    "       \n",
    "    chiSqStat = ((obsCount - expCount)**2 / expCount).to_numpy().sum()\n",
    "    chiSqDf = (obsCount.shape[0] - 1.0) * (obsCount.shape[1] - 1.0)\n",
    "    chiSqSig = scipy.stats.chi2.sf(chiSqStat, chiSqDf)\n",
    "\n",
    "    cramerV = chiSqStat / nTotal\n",
    "    if (cTotal.size > rTotal.size):\n",
    "        cramerV = cramerV / (rTotal.size - 1.0)\n",
    "    else:\n",
    "        cramerV = cramerV / (cTotal.size - 1.0)\n",
    "    cramerV = np.sqrt(cramerV)\n",
    "\n",
    "    return(chiSqStat, chiSqDf, chiSqSig, cramerV)\n",
    "\n",
    "# Define a function that performs the Deviance test\n",
    "def DevianceTest (\n",
    "    xInt,           # input interval feature\n",
    "    yCat,           # input categorical target variable\n",
    "    debug = 'N'     # debugging flag (Y/N) \n",
    "    ):\n",
    "\n",
    "    y = yCat.astype('category')\n",
    "\n",
    "    # Model 0 is yCat = Intercept\n",
    "    X = numpy.where(yCat.notnull(), 1, 0)\n",
    "    objLogit = smodel.MNLogit(y, X)\n",
    "    thisFit = objLogit.fit(method = 'newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "    thisParameter = thisFit.params\n",
    "    LLK0 = objLogit.loglike(thisParameter.values)\n",
    "\n",
    "    if (debug == 'Y'):\n",
    "        print(thisFit.summary())\n",
    "        print(\"Model Log-Likelihood Value =\", LLK0)\n",
    "        print('\\n')\n",
    "\n",
    "    # Model 1 is yCat = Intercept + xInt\n",
    "    X = smodel.add_constant(xInt, prepend = True)\n",
    "    objLogit = smodel.MNLogit(y, X)\n",
    "    thisFit = objLogit.fit(method = 'newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "    thisParameter = thisFit.params\n",
    "    LLK1 = objLogit.loglike(thisParameter.values)\n",
    "\n",
    "    if (debug == 'Y'):\n",
    "        print(thisFit.summary())\n",
    "        print(\"Model Log-Likelihood Value =\", LLK1)\n",
    "\n",
    "    # Calculate the deviance\n",
    "    devianceStat = 2.0 * (LLK1 - LLK0)\n",
    "    devianceDf = (len(y.cat.categories) - 1.0)\n",
    "    devianceSig = scipy.stats.chi2.sf(devianceStat, devianceDf)\n",
    "\n",
    "    mcFaddenRSq = 1.0 - (LLK1 / LLK0)\n",
    "\n",
    "    return(devianceStat, devianceDf, devianceSig, mcFaddenRSq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loat the data set\n",
    "purchases = pd.read_csv(\"Purchase_Likelihood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665249 entries, 0 to 665248\n",
      "Data columns (total 4 columns):\n",
      "group_size        665249 non-null int64\n",
      "homeowner         665249 non-null int64\n",
      "married_couple    665249 non-null int64\n",
      "A                 665249 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 20.3 MB\n"
     ]
    }
   ],
   "source": [
    "purchases.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify A as a categorical response\n",
    "y = purchases['A'].astype('category')\n",
    "purchases.drop(['A'], axis=1, inplace=True)\n",
    "\n",
    "# Specify nominal features as categorical predictors\n",
    "nom_features = ['group_size', 'homeowner', 'married_couple']\n",
    "purchases = purchases[nom_features].astype('category')\n",
    "purchases = pd.get_dummies(purchases)\n",
    "\n",
    "group_size = purchases.iloc[:, 0:4]\n",
    "homeowner = purchases.iloc[:, 4:6]\n",
    "married_couple = purchases.iloc[:, 6:]\n",
    "    \n",
    "# Create columns for the group_size * homeowner interaction effect\n",
    "group_size_homeowner = create_interaction(group_size, homeowner)\n",
    "\n",
    "# Create columns for the homeowner * married_couple\n",
    "homeowner_married_couple = create_interaction(homeowner, married_couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.895013\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.894271\n",
      "         Iterations 5\n",
      "Deviance Chi-Square Test for Model: Intercept + group_size\n",
      "Chi-Square Statistic =  987.5766\n",
      "  Degreee of Freedom =  6\n",
      "        Significance =  4.347871528385848e-210\n",
      "          Importance =  209.3617\n",
      "  Aliased parameters =  ['group_size_4']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Intercept only model\n",
    "design_X = pd.DataFrame(y.where(y.isnull(), 1))\n",
    "INDS0, LLK0, DF0, full_params0 = build_mnlogit(design_X, y)\n",
    "\n",
    "# Intercept + group_size\n",
    "design_X = st.add_constant(group_size, prepend=True)\n",
    "INDS01, LLK_01, DF_01, full_params01 = build_mnlogit (design_X, y)\n",
    "test_dev_01 = round(2 * (LLK_01 - LLK0), 4)\n",
    "test_DF_01 = DF_01 - DF0\n",
    "test_Pvalue_01 = scipy.stats.chi2.sf(test_dev_01, test_DF_01)\n",
    "test_importance_01 = round(-np.log10(test_Pvalue_01), 4)\n",
    "test_alias_01 = find_alias(design_X, INDS01)\n",
    "print('Deviance Chi-Square Test for Model: ' + 'Intercept + group_size')\n",
    "print('Chi-Square Statistic = ', test_dev_01)\n",
    "print('  Degreee of Freedom = ', test_DF_01)\n",
    "print('        Significance = ', test_Pvalue_01)\n",
    "print('          Importance = ', test_importance_01)\n",
    "print('  Aliased parameters = ', test_alias_01)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889861\n",
      "         Iterations 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log10\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviance Chi-Square Test for Model: Intercept + group_size + homeowner\n",
      "Chi-Square Statistic =  5867.7815\n",
      "  Degreee of Freedom =  2\n",
      "        Significance =  0.0\n",
      "          Importance =  inf\n",
      "  Aliased parameters =  ['group_size_4', 'homeowner_1']\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889797\n",
      "         Iterations 5\n",
      "Deviance Chi-Square Test for Model: Intercept + group_size + homeowner + married_couple\n",
      "Chi-Square Statistic =  84.578\n",
      "  Degreee of Freedom =  2\n",
      "        Significance =  4.3064623511902606e-19\n",
      "          Importance =  18.3659\n",
      "  Aliased parameters =  ['group_size_4', 'homeowner_1', 'married_couple_1']\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889606\n",
      "         Iterations 5\n",
      "Deviance Chi-Square Test for Model: Intercept + group_size + homeowner + married_couple + group_size * homeowner\n",
      "Chi-Square Statistic =  254.0781\n",
      "  Degreee of Freedom =  6\n",
      "        Significance =  5.512174780169455e-52\n",
      "          Importance =  51.2587\n",
      "  Aliased parameters =  ['group_size_4', 'homeowner_1', 'married_couple_1', 'group_size_1 * homeowner_1', 'group_size_2 * homeowner_1', 'group_size_3 * homeowner_1', 'group_size_4 * homeowner_0', 'group_size_4 * homeowner_1']\n",
      "\n",
      "Column Numbers of the Non-redundant Columns:\n",
      "(0, 1, 2, 3, 5, 7, 9, 11, 13, 17)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889553\n",
      "         Iterations 5\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      A   No. Observations:               665249\n",
      "Model:                        MNLogit   Df Residuals:                   665229\n",
      "Method:                           MLE   Df Model:                           18\n",
      "Date:                Mon, 25 Nov 2019   Pseudo R-squ.:                0.006101\n",
      "Time:                        13:30:28   Log-Likelihood:            -5.9177e+05\n",
      "converged:                       True   LL-Null:                   -5.9541e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==================================================================================================\n",
      "                           A=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                              0.4396      0.091      4.822      0.000       0.261       0.618\n",
      "group_size_1                       1.0885      0.093     11.763      0.000       0.907       1.270\n",
      "group_size_2                       0.9573      0.092     10.454      0.000       0.778       1.137\n",
      "group_size_3                       0.3439      0.095      3.610      0.000       0.157       0.531\n",
      "homeowner_0                        0.8002      0.259      3.093      0.002       0.293       1.307\n",
      "married_couple_0                  -0.2157      0.017    -12.873      0.000      -0.249      -0.183\n",
      "group_size_1 * homeowner_0        -1.5056      0.260     -5.793      0.000      -2.015      -0.996\n",
      "group_size_2 * homeowner_0        -1.1646      0.259     -4.493      0.000      -1.673      -0.657\n",
      "group_size_3 * homeowner_0        -0.6546      0.267     -2.450      0.014      -1.178      -0.131\n",
      "homeowner_0 * married_couple_0     0.2125      0.026      8.224      0.000       0.162       0.263\n",
      "--------------------------------------------------------------------------------------------------\n",
      "                           A=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "const                             -0.9255      0.134     -6.927      0.000      -1.187      -0.664\n",
      "group_size_1                       0.8015      0.135      5.923      0.000       0.536       1.067\n",
      "group_size_2                       0.7281      0.134      5.429      0.000       0.465       0.991\n",
      "group_size_3                       0.5275      0.138      3.810      0.000       0.256       0.799\n",
      "homeowner_0                        0.5423      0.361      1.504      0.133      -0.164       1.249\n",
      "married_couple_0                  -0.1882      0.023     -8.327      0.000      -0.232      -0.144\n",
      "group_size_1 * homeowner_0        -0.9834      0.362     -2.716      0.007      -1.693      -0.274\n",
      "group_size_2 * homeowner_0        -0.7156      0.361     -1.981      0.048      -1.423      -0.008\n",
      "group_size_3 * homeowner_0        -0.5987      0.372     -1.611      0.107      -1.327       0.130\n",
      "homeowner_0 * married_couple_0     0.2124      0.035      6.065      0.000       0.144       0.281\n",
      "==================================================================================================\n",
      "Model Parameter Estimates:\n",
      "                                        0         1\n",
      "const                           0.439563 -0.925506\n",
      "group_size_1                    1.088485  0.801493\n",
      "group_size_2                    0.957293  0.728103\n",
      "group_size_3                    0.343931  0.527471\n",
      "homeowner_0                     0.800157  0.542297\n",
      "married_couple_0               -0.215748 -0.188178\n",
      "group_size_1 * homeowner_0     -1.505554 -0.983441\n",
      "group_size_2 * homeowner_0     -1.164638 -0.715556\n",
      "group_size_3 * homeowner_0     -0.654639 -0.598700\n",
      "homeowner_0 * married_couple_0  0.212483  0.212433\n",
      "Model Log-Likelihood Value = -591774.333631724\n",
      "Number of Free Parameters = 20\n",
      "\n",
      "Deviance Chi-Square Test for Model: Intercept + group_size + homeowner + married_couple + group_size * homeowner + homeowner * married_couple\n",
      "Chi-Square Statistic =  70.8423\n",
      "  Degreee of Freedom =  2\n",
      "        Significance =  4.1379954837122215e-16\n",
      "          Importance =  15.3832\n",
      "  Aliased parameters =  ['group_size_4', 'homeowner_1', 'married_couple_1', 'group_size_1 * homeowner_1', 'group_size_2 * homeowner_1', 'group_size_3 * homeowner_1', 'group_size_4 * homeowner_0', 'group_size_4 * homeowner_1', 'homeowner_0 * married_couple_1', 'homeowner_1 * married_couple_0', 'homeowner_1 * married_couple_1']\n",
      "\n",
      "Sixteen possible value combinations of the three features:\n",
      "    group_size  homeowner  married_couple\n",
      "0            1          0               0\n",
      "1            1          0               1\n",
      "2            1          1               0\n",
      "3            1          1               1\n",
      "4            2          0               0\n",
      "5            2          0               1\n",
      "6            2          1               0\n",
      "7            2          1               1\n",
      "8            3          0               0\n",
      "9            3          0               1\n",
      "10           3          1               0\n",
      "11           3          1               1\n",
      "12           4          0               0\n",
      "13           4          0               1\n",
      "14           4          1               0\n",
      "15           4          1               1\n",
      "\n",
      "e) The predicted probabilities for A = 0, 1, 2 based on the multinomial logistic model.\n",
      "           0         1         2\n",
      "0   0.259651  0.589175  0.151174\n",
      "1   0.260092  0.592106  0.147802\n",
      "2   0.183602  0.682030  0.134368\n",
      "3   0.154023  0.709918  0.136059\n",
      "4   0.221936  0.621105  0.156959\n",
      "5   0.222321  0.624216  0.153463\n",
      "6   0.202510  0.659773  0.137718\n",
      "7   0.170552  0.689450  0.139999\n",
      "8   0.239570  0.604616  0.155814\n",
      "9   0.239992  0.607660  0.152348\n",
      "10  0.301140  0.531297  0.167563\n",
      "11  0.259017  0.567017  0.173966\n",
      "12  0.194485  0.669686  0.135829\n",
      "13  0.194692  0.672592  0.132716\n",
      "14  0.387719  0.484974  0.127306\n",
      "15  0.339172  0.526404  0.134424\n",
      "\n",
      "f) Values of group_size, homeowner and married_couple that maximaize the odss value Prob(A=1)/Prob(A=0):\n",
      "[1 1 1]\n",
      "The maximum odd value: 4.609168549460521\n",
      "\n",
      "The odds ratio for group_size = 3 versus group_size = 1, and A = 2 versus A = 0: 0.7603152041174503\n",
      "\n",
      "The odds ratio for homeowner = 1 versus homeowner = 0, and A = 0 versus A = 1: 2.225890499033005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Intercept + group_size + homeowner\n",
    "design_X = design_X.join(homeowner)\n",
    "INDS012, LLK_012, DF_012, full_params012 = build_mnlogit (design_X, y)\n",
    "test_dev_012 = round(2 * (LLK_012 - LLK_01), 4)\n",
    "test_DF_012 = DF_012 - DF_01\n",
    "test_Pvalue_012 = scipy.stats.chi2.sf(test_dev_012, test_DF_012)\n",
    "test_importance_012 = round(-np.log10(test_Pvalue_012), 4)\n",
    "test_alias_012 = find_alias(design_X, INDS012)\n",
    "print('Deviance Chi-Square Test for Model: ' + 'Intercept + group_size + homeowner')\n",
    "print('Chi-Square Statistic = ', test_dev_012)\n",
    "print('  Degreee of Freedom = ', test_DF_012)\n",
    "print('        Significance = ', test_Pvalue_012)\n",
    "print('          Importance = ', test_importance_012)\n",
    "print('  Aliased parameters = ', test_alias_012)\n",
    "print()\n",
    "\n",
    "# Intercept + group_size + homeowner + married_couple\n",
    "design_X = design_X.join(married_couple)\n",
    "INDS0123, LLK_0123, DF_0123, full_params0123 = build_mnlogit (design_X, y)\n",
    "test_dev_0123 = round(2 * (LLK_0123 - LLK_012), 4)\n",
    "test_DF_0123 = DF_0123 - DF_012\n",
    "test_Pvalue_0123 = scipy.stats.chi2.sf(test_dev_0123, test_DF_0123)\n",
    "test_importance_0123 = round(-np.log10(test_Pvalue_0123), 4)\n",
    "test_alias_0123 = find_alias(design_X, INDS0123)\n",
    "print('Deviance Chi-Square Test for Model: ' + 'Intercept + group_size + homeowner + married_couple')\n",
    "print('Chi-Square Statistic = ', test_dev_0123)\n",
    "print('  Degreee of Freedom = ', test_DF_0123)\n",
    "print('        Significance = ', test_Pvalue_0123)\n",
    "print('          Importance = ', test_importance_0123)\n",
    "print('  Aliased parameters = ', test_alias_0123)\n",
    "print()\n",
    "\n",
    "# Intercept + group_size + homeowner + married_couple + group_size * homeowner\n",
    "design_X = design_X.join(group_size_homeowner)\n",
    "INDS01234, LLK_01234, DF_01234, full_params01234 = build_mnlogit (design_X, y)\n",
    "test_dev_01234 = round(2 * (LLK_01234 - LLK_0123), 4)\n",
    "test_DF_01234 = DF_01234 - DF_0123\n",
    "test_Pvalue_01234 = scipy.stats.chi2.sf(test_dev_01234, test_DF_01234)\n",
    "test_importance_01234 = round(-np.log10(test_Pvalue_01234), 4)\n",
    "test_alias_01234 = find_alias(design_X, INDS01234)\n",
    "print('Deviance Chi-Square Test for Model: ' + 'Intercept + group_size + homeowner + married_couple + group_size * homeowner')\n",
    "print('Chi-Square Statistic = ', test_dev_01234)\n",
    "print('  Degreee of Freedom = ', test_DF_01234)\n",
    "print('        Significance = ', test_Pvalue_01234)\n",
    "print('          Importance = ', test_importance_01234)\n",
    "print('  Aliased parameters = ', test_alias_01234)\n",
    "print()\n",
    "\n",
    "# Intercept + group_size + homeowner + married_couple + group_size * homeowner + homeowner * married_couple\n",
    "design_X = design_X.join(homeowner_married_couple)\n",
    "\n",
    "# Number of all parameters\n",
    "n_full_param = design_X.shape[1]\n",
    "\n",
    "# Number of target categories\n",
    "y_category = y.cat.categories\n",
    "n_y_cat = len(y_category)\n",
    "\n",
    "# Find the non-redundant columns in the design matrix fullX\n",
    "reduced_form_012345, INDS012345 = sympy.Matrix(design_X.values).rref()\n",
    "\n",
    "# These are the column numbers of the non-redundant columns\n",
    "print('Column Numbers of the Non-redundant Columns:')\n",
    "print(INDS012345)\n",
    "\n",
    "# Extract only the non-redundant columns for modeling\n",
    "X = design_X.iloc[:, list(INDS012345)]\n",
    "\n",
    "# The number of free parameters\n",
    "DF_012345 = len(INDS012345) * (n_y_cat - 1)\n",
    "\n",
    "# Build a multionomial logistic model\n",
    "logit = st.MNLogit(y, X)\n",
    "fit = logit.fit(method='newton', full_output = True, maxiter = 100, tol = 1e-8)\n",
    "fit_params = fit.params\n",
    "LLK_012345 = logit.loglike(fit_params.values)\n",
    "\n",
    "print(fit.summary())\n",
    "print(\"Model Parameter Estimates:\\n\", fit_params)\n",
    "print(\"Model Log-Likelihood Value =\", LLK_012345)\n",
    "print(\"Number of Free Parameters =\", DF_012345)\n",
    "print()\n",
    "\n",
    "# Recreat the estimates of the full parameters\n",
    "work_params = pd.DataFrame(np.zeros(shape = (n_full_param, (n_y_cat - 1))))\n",
    "work_params = work_params.set_index(keys = design_X.columns)\n",
    "full_params = pd.merge(work_params, fit_params, how = \"left\", left_index = True, right_index = True)\n",
    "full_params = full_params.drop(columns = '0_x').fillna(0.0)\n",
    "\n",
    "# Calculate the statistics of the full model\n",
    "test_dev_012345 = round(2 * (LLK_012345 - LLK_01234), 4)\n",
    "test_DF_012345 = DF_012345 - DF_01234\n",
    "test_Pvalue_012345 = scipy.stats.chi2.sf(test_dev_012345, test_DF_012345)\n",
    "test_importance_012345 = round(-np.log10(test_Pvalue_012345), 4)\n",
    "test_alias_012345 = find_alias(design_X, INDS012345)\n",
    "print('Deviance Chi-Square Test for Model: ' +'Intercept + group_size + homeowner + married_couple + group_size * homeowner + homeowner * married_couple')\n",
    "print('Chi-Square Statistic = ', test_dev_012345)\n",
    "print('  Degreee of Freedom = ', test_DF_012345)\n",
    "print('        Significance = ', test_Pvalue_012345)\n",
    "print('          Importance = ', test_importance_012345)\n",
    "print('  Aliased parameters = ', test_alias_012345)\n",
    "print()\n",
    "\n",
    "'''\n",
    "For each of the sixteen possible value combinations of the three features, \n",
    "calculate the predicted probabilities for A = 0, 1, 2 based on the multinomial logistic model.  \n",
    "'''\n",
    "# Sixteen combination of group_size, homeowner & married_couple\n",
    "df_ghm = pd.DataFrame({'group_size': [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "                       'homeowner': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "                       'married_couple': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "print(\"Sixteen possible value combinations of the three features:\")    \n",
    "print(df_ghm)\n",
    "print()\n",
    "\n",
    "# Specify nominal features as categorical predictors\n",
    "ghm_features = ['group_size', 'homeowner', 'married_couple']\n",
    "df_ghm = df_ghm[ghm_features].astype('category')\n",
    "df_ghm = pd.get_dummies(df_ghm)\n",
    "\n",
    "group_size_ghm = df_ghm.iloc[:, 0:4]\n",
    "homeowner_ghm = df_ghm.iloc[:, 4:6]\n",
    "married_couple_ghm = df_ghm.iloc[:, 6:]\n",
    "    \n",
    "# Create columns for the group_size * homeowner interaction effect\n",
    "group_size_homeowner_ghm = create_interaction(group_size_ghm, homeowner_ghm)\n",
    "\n",
    "# Create columns for the homeowner * married_couple\n",
    "homeowner_married_couple_ghm = create_interaction(homeowner_ghm, married_couple_ghm)\n",
    "\n",
    "design_X_ghm = df_ghm.join(group_size_homeowner_ghm)\n",
    "design_X_ghm = design_X_ghm.join(homeowner_married_couple_ghm)\n",
    "design_X_ghm = st.add_constant(design_X_ghm, prepend=True)\n",
    "\n",
    "# Extract only the non-redundant columns for modeling\n",
    "X_ghm = design_X_ghm.iloc[:, list(INDS012345)]\n",
    "\n",
    "# Predict the sixteen combinations of the three features\n",
    "pred_proba = fit.predict(X_ghm)\n",
    "\n",
    "print('The predicted probabilities for A = 0, 1, 2 based on the multinomial logistic model.')\n",
    "print(pred_proba)\n",
    "print()\n",
    "\n",
    "'''\n",
    "What values of group_size, homeowner, and married_couple \n",
    "will maximize the odds value Prob(A=1) / Prob(A = 0)?  \n",
    "What is that maximum odd value?\n",
    "'''\n",
    "df_combination = pd.DataFrame({'group_size': [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "                               'homeowner': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "                               'married_couple': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "odds_1_0 = list(pred_proba.iloc[:, 1] / pred_proba.iloc[:, 0])\n",
    "max_odds_1_0 = max(odds_1_0)\n",
    "max_odds_1_0_idx = odds_1_0.index(max_odds_1_0)\n",
    "print('Values of group_size, homeowner and married_couple that maximaize the odss value Prob(A=1)/Prob(A=0):')\n",
    "print(df_combination.iloc[max_odds_1_0_idx, :].values)\n",
    "print('The maximum odd value:', np.exp(fit_params.iloc[0,0] + fit_params.iloc[1,0]))\n",
    "print()\n",
    "\n",
    "'''\n",
    "The odds ratio for group_size = 3 versus group_size = 1,and A = 2 versus A = 0.  Mathematically, \n",
    "the odds ratio is (Prob(A=2)/Prob(A=0) | group_size = 3) / ((Prob(A=2)/Prob(A=0) | group_size = 1).\n",
    "'''\n",
    "group_size_3 = fit_params.iloc[3, 1]\n",
    "group_size_1 = fit_params.iloc[1, 1]\n",
    "odds_ratio_A2_A0_g3_g1 = np.exp(group_size_3 - group_size_1)\n",
    "print('The odds ratio for group_size = 3 versus group_size = 1, and A = 2 versus A = 0:', odds_ratio_A2_A0_g3_g1)\n",
    "print()\n",
    "\n",
    "'''\n",
    "The odds ratio for homeowner = 1 versus homeowner = 0, and A = 0 versus A = 1? \n",
    "Mathematically, the odds ratio is (Prob(A=0)/Prob(A=1) | homeowner = 1) / ((Prob(A=0)/Prob(A=1) | homeowner = 0).\n",
    "'''\n",
    "odds_ratio_A0_A1_h1_h0 = np.exp(fit_params.iloc[4,0])\n",
    "print('The odds ratio for homeowner = 1 versus homeowner = 0, and A = 0 versus A = 1:', odds_ratio_A0_A1_h1_h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the below functions are written by my instructor Dr. Ming Long Lam\n",
    "# Define a function to visualize the percent of a particular target category by a nominal predictor\n",
    "def RowWithColumn (\n",
    "   rowVar,          # Row variable\n",
    "   columnVar,       # Column predictor\n",
    "   show = 'ROW'):   # Show ROW fraction, COLUMN fraction, or BOTH table\n",
    "\n",
    "   countTable = pd.crosstab(index = rowVar, columns = columnVar, margins = False, dropna = True)\n",
    "   countTable['Total'] = countTable.sum(1)\n",
    "   print(\"Frequency Table: \\n\", countTable)\n",
    "   print( )\n",
    "   \n",
    "   rowFraction = None\n",
    "   if (show == 'ROW'):\n",
    "       rowFraction = countTable.div(countTable['Total'], axis='index')\n",
    "       print(\"Row Fraction Table: \\n\", rowFraction)\n",
    "       print( )\n",
    "       \n",
    "   return countTable, rowFraction\n",
    "\n",
    "\n",
    "# Define a function that calculate the Cramer's V\n",
    "def cramers_v (\n",
    "    x_cat,           # input categorical feature\n",
    "    y_cat,           # input categorical target variable\n",
    "    debug = 'N'     # debugging flag (Y/N) \n",
    "    ):\n",
    "\n",
    "    obs_count = pd.crosstab(index = x_cat, columns = y_cat, margins = False, dropna = True)\n",
    "    col_tot = obs_count.sum(axis = 1)\n",
    "    row_tot = obs_count.sum(axis = 0)\n",
    "    tot = np.sum(row_tot)\n",
    "    exp_count = np.outer(col_tot, (row_tot / tot))\n",
    "\n",
    "    if (debug == 'Y'):\n",
    "        print('Observed Count:\\n', obs_count)\n",
    "        print('Column Total:\\n', col_tot)\n",
    "        print('Row Total:\\n', row_tot)\n",
    "        print('Overall Total:\\n', tot)\n",
    "        print('Expected Count:\\n', exp_count)\n",
    "        print('\\n')\n",
    "       \n",
    "    chi_sq_stat = ((obs_count - exp_count)**2 / exp_count).to_numpy().sum()\n",
    "    \n",
    "    cramerV = chi_sq_stat / tot\n",
    "    if (col_tot.size > row_tot.size):\n",
    "        cramerV = cramerV / (row_tot.size - 1.0)\n",
    "    else:\n",
    "        cramerV = cramerV / (col_tot.size - 1.0)\n",
    "    cramerV = np.sqrt(cramerV)\n",
    "\n",
    "    return cramerV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loat the dataset\n",
    "purchases = pd.read_csv(\"Purchase_Likelihood.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency counts and the Class Probabilities of the target variable:\n",
      "col_0   Count  Class Probability\n",
      "A                               \n",
      "0      143691           0.215996\n",
      "1      426067           0.640462\n",
      "2       95491           0.143542\n",
      "Total  665249           1.000000\n",
      "\n",
      "The crosstabulation table of the target variable by the feature group_size:\n",
      "Frequency Table: \n",
      " group_size       1      2     3    4   Total\n",
      "A                                           \n",
      "0           115460  25728  2282  221  143691\n",
      "1           329552  91065  5069  381  426067\n",
      "2            74293  19600  1505   93   95491\n",
      "\n",
      "Row Fraction Table: \n",
      " group_size         1         2         3         4  Total\n",
      "A                                                        \n",
      "0           0.803530  0.179051  0.015881  0.001538    1.0\n",
      "1           0.773475  0.213734  0.011897  0.000894    1.0\n",
      "2           0.778010  0.205255  0.015761  0.000974    1.0\n",
      "\n",
      "The crosstabulation table of the target variable by the feature homeowner:\n",
      "Frequency Table: \n",
      " homeowner       0       1   Total\n",
      "A                                \n",
      "0           78659   65032  143691\n",
      "1          183130  242937  426067\n",
      "2           46734   48757   95491\n",
      "\n",
      "Row Fraction Table: \n",
      " homeowner         0         1  Total\n",
      "A                                   \n",
      "0          0.547418  0.452582    1.0\n",
      "1          0.429815  0.570185    1.0\n",
      "2          0.489407  0.510593    1.0\n",
      "\n",
      "The crosstabulation table of the target variable by the feature married_couple:\n",
      "Frequency Table: \n",
      " married_couple       0      1   Total\n",
      "A                                    \n",
      "0               117110  26581  143691\n",
      "1               333272  92795  426067\n",
      "2                75310  20181   95491\n",
      "\n",
      "Row Fraction Table: \n",
      " married_couple         0         1  Total\n",
      "A                                        \n",
      "0               0.815013  0.184987    1.0\n",
      "1               0.782206  0.217794    1.0\n",
      "2               0.788661  0.211339    1.0\n",
      "\n",
      "Cramer’s V statistics:\n",
      "                      Test Cramer's V\n",
      "homeowner       Chi-square  0.0970864\n",
      "married_couple  Chi-square  0.0324216\n",
      "group_size      Chi-square   0.027102\n",
      "\n",
      "The predicted probabilities for A = 0, 1, 2 based on the Naïve Bayes model:\n",
      "    group_size  homeowner  married_couple Prob(A = 0) Prob(A = 1) Prob(A = 2)\n",
      "0            1          0               0    0.269722    0.580133    0.150145\n",
      "1            1          0               1    0.232789    0.614219    0.152992\n",
      "2            1          1               0    0.194038    0.669659    0.136303\n",
      "3            1          1               1    0.164935    0.698278    0.136787\n",
      "4            2          0               0    0.231143    0.616518    0.152338\n",
      "5            2          0               1    0.198016    0.647907    0.154078\n",
      "6            2          1               0    0.163628    0.700288    0.136085\n",
      "7            2          1               1    0.138274    0.725955    0.135771\n",
      "8            3          0               0    0.308219    0.515924    0.175856\n",
      "9            3          0               1    0.268311    0.550951    0.180738\n",
      "10           3          1               0    0.226972    0.609612    0.163416\n",
      "11           3          1               1     0.19437     0.64041    0.165221\n",
      "12           4          0               0     0.37549     0.48781      0.1367\n",
      "13           4          0               1    0.330743    0.527098    0.142158\n",
      "14           4          1               0    0.282173    0.588196    0.129631\n",
      "15           4          1               1     0.24393    0.623766    0.132304\n",
      "\n",
      "Values of group_size, homeowner, and married_couple will maximize the odds value Prob(A=1) / Prob(A = 0)\n",
      "[2 1 1]\n",
      "Maximum odd value: 5.250112589270714\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The frequency counts and the Class Probabilities of the target variable.\n",
    "'''\n",
    "count_table_A = pd.crosstab(index=purchases['A'], columns=['Count'], margins=True)\n",
    "count_table_A.drop(['All'], axis=1, inplace=True)\n",
    "count_table_A.rename(index={'All': 'Total'}, inplace=True)\n",
    "count_table_A['Class Probability'] = count_table_A.div(count_table_A.loc['Total', ], axis='columns')\n",
    "print('The frequency counts and the Class Probabilities of the target variable:')\n",
    "print(count_table_A)\n",
    "print()\n",
    "\n",
    "'''\n",
    "The crosstabulation table of the target variable by the feature group_size.  \n",
    "The table contains the frequency counts.\n",
    "'''\n",
    "print('The crosstabulation table of the target variable by the feature group_size:')\n",
    "count_table_group, count_table_group_fraction = RowWithColumn(purchases['A'], purchases['group_size'])\n",
    "\n",
    "'''\n",
    "The crosstabulation table of the target variable by the feature homeowner.  \n",
    "The table contains the frequency counts.\n",
    "'''\n",
    "print('The crosstabulation table of the target variable by the feature homeowner:')\n",
    "count_table_homeowner, count_table_homeowner_fraction = RowWithColumn(purchases['A'], purchases['homeowner'])\n",
    "\n",
    "'''\n",
    "Tthe crosstabulation table of the target variable by the feature married_couple.  \n",
    "The table contains the frequency counts.\n",
    "'''\n",
    "print('The crosstabulation table of the target variable by the feature married_couple:')\n",
    "count_table_married_couple, count_table_married_couple_fraction = RowWithColumn(purchases['A'], purchases['married_couple'])\n",
    "\n",
    "'''\n",
    "Calculate the Cramer’s V statistics for the above three crosstabulations tables.  \n",
    "Based on these Cramer’s V statistics, show which feature has the largest association with the target A.\n",
    "'''\n",
    "cat_pred = ['group_size', 'homeowner', 'married_couple']\n",
    "cramerv_table = pd.DataFrame(index = cat_pred, columns = ['Test', \"Cramer's V\"])\n",
    "for pred in cat_pred:\n",
    "    cramerV = cramers_v(purchases[pred], purchases['A'])\n",
    "    cramerv_table.loc[pred] = ['Chi-square', cramerV]\n",
    "cramerv_table = cramerv_table.sort_values(\"Cramer's V\", axis = 0, ascending = False)\n",
    "print(\"Cramer’s V statistics:\")\n",
    "print(cramerv_table)\n",
    "print()\n",
    "\n",
    "'''\n",
    "For each of the sixteen possible value combinations of the three features, \n",
    "calculate the predicted probabilities for A = 0, 1, 2 based on the Naïve Bayes model. \n",
    "'''\n",
    "df_proba = pd.DataFrame({'group_size': [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "                         'homeowner': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "                         'married_couple': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "df_proba['Prob(A = 0)'] = None\n",
    "df_proba['Prob(A = 1)'] = None\n",
    "df_proba['Prob(A = 2)'] = None\n",
    "\n",
    "# A function that calculates the probability of the categories of a target variable\n",
    "def naive_bayes(df_a, df_g, df_h, df_m, g, h, m):\n",
    "    # Array that stores the probilities given A = 0 or A = 1 or A = 2\n",
    "    p_arr = np.array([None, None, None])\n",
    "    for i in range(3):\n",
    "        p = df_a.iloc[i, 1] * df_g.iloc[i, g] * df_h.iloc[i, h] * df_m.iloc[i, m]\n",
    "        p_arr[i] = p\n",
    "    p_arr = p_arr/np.sum(p_arr)\n",
    "    return p_arr\n",
    "    \n",
    "\n",
    "# Loop through the rows of the dataframe\n",
    "for i in range(df_proba.shape[0]):\n",
    "    g = df_proba.iloc[i, 0] - 1 # Retrieve the group category\n",
    "    h = df_proba.iloc[i, 1]     # Retrieve the homeowner category\n",
    "    m = df_proba.iloc[i, 2]     # Retrieve the married_couple category\n",
    "    \n",
    "    p_arr = naive_bayes(count_table_A, count_table_group_fraction, count_table_homeowner_fraction, count_table_married_couple_fraction, g, h, m)\n",
    "    \n",
    "    df_proba.iloc[i, 3] = p_arr[0]    # Assign the probability of A = 0\n",
    "    df_proba.iloc[i, 4] = p_arr[1]    # Assign the probability of A = 1\n",
    "    df_proba.iloc[i, 5] = p_arr[2]    # Assign the probability of A = 2\n",
    "\n",
    "print('The predicted probabilities for A = 0, 1, 2 based on the Naïve Bayes model:')\n",
    "print(df_proba)\n",
    "print()\n",
    "          \n",
    "\n",
    "'''          \n",
    "Based on your model, calculate what values of group_size, homeowner, \n",
    "and married_couple will maximize the odds value Prob(A=1) / Prob(A = 0) and Whatthat maximum odd value is.         \n",
    "'''         \n",
    "odds = list(df_proba.iloc[:, 4]/df_proba.iloc[:, 3])\n",
    "max_odds = max(odds)\n",
    "max_odds_idx = odds.index(max_odds)\n",
    "print('Values of group_size, homeowner, and married_couple will maximize the odds value Prob(A=1) / Prob(A = 0)')\n",
    "print(df_proba.iloc[max_odds_idx, 0:3].values)\n",
    "print('Maximum odd value:', max_odds)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "X = purchases.iloc[:, 0:3].astype('category')\n",
    "y = purchases.iloc[:, 3].astype('category')\n",
    "mnb.fit(X, y)\n",
    "\n",
    "test= pd.DataFrame({'group_size': [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4],\n",
    "                         'homeowner': [0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
    "                         'married_couple': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]})\n",
    "pred_proba = mnb.predict_proba(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
