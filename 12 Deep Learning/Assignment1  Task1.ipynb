{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1 \n",
    "### Christopher Hong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train_samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train_samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a subset of 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of classes and their distribution\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indices of class labels of 0, 1, 2\n",
    "ind = np.argwhere(y_train.squeeze() < 3).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[ind]\n",
    "y_train = y_train[ind]\n",
    "assert(x_train.shape[0] == len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=uint8), array([5000, 5000, 5000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indices of class labels of 0, 1, 2\n",
    "ind = np.argwhere(y_test.squeeze() < 3).squeeze()\n",
    "x_test = x_test[ind]\n",
    "y_test = y_test[ind]\n",
    "assert(x_test.shape[0] == len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1000, 1000, 1000]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and vectorize class labels to binary class matrices \n",
    "y_train = np.asarray(to_categorical(y_train)).astype('float32')\n",
    "y_test = np.asarray(to_categorical(y_test)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.astype('float32') / 255, x_test.astype('float32') / 255\n",
    "x_train, x_test = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting aside a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(x_train.shape[0] * 0.2)\n",
    "x_val, partial_x_train = x_train[:val_size], x_train[val_size:]\n",
    "y_val, partial_y_train = y_train[:val_size], y_train[val_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model = Sequential()\n",
    "cifar_model.add(Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "cifar_model.add(Dense(64, activation='relu'))\n",
    "cifar_model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using Adam\n",
    "cifar_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_history = cifar_model.fit(partial_x_train, \n",
    "                                partial_y_train,\n",
    "                                epochs=100,\n",
    "                                batch_size=512,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the training and validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss)+1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de3hU1bk/8O9LCJAAcgveuCR4qQjhHmOtqIhIgSNSwQs5oKIiaou1Yk8PrdZab+2p8kOt1iPejsUoUloVWxXEW7VWIQhBAUHkolHUEO4kSELe3x/v7Mxksmcyk8zOJLO/n+eZZ2ZfZu+1ZyfrXWvttdcWVQUREflXq2QngIiIkouBgIjI5xgIiIh8joGAiMjnGAiIiHyOgYCIyOcYCMgTIpImIvtFpHci100mETlBRBLe31pERonI1pDpDSJyRizrNmBfj4nIrxr6fUpNrZOdAGoeRGR/yGQmgO8AHA5MX6OqhfFsT1UPA+iQ6HX9QFVPSsR2RGQ6gKmqOiJk29MTsW1KLQwEBABQ1ZqMOFDinK6qyyKtLyKtVbWqKdJGRN5i0xDFRETuFJHnRORZEdkHYKqInCYi74vIbhHZLiIPiEh6YP3WIqIikhOYfjqw/BUR2Sci/xaRPvGuG1g+VkQ2isgeEfmjiPxLRKZFSHcsabxGRDaJyC4ReSDku2kiMldEykTkMwBjovw+t4jIgrB5D4nI/wt8ni4i6wPH81mgtB5pWyUiMiLwOVNE5gfSthbAMJf9bg5sd62InB+YPwDAgwDOCDS77Qj5bW8L+f61gWMvE5EXROSYWH6beH5nJz0iskxEdorI1yLyi5D9/Drwm+wVkSIROTbSfsgjqsoXX7VeALYCGBU2704AhwCMhxUgMgCcAuBUWM3yOAAbAcwMrN8agALICUw/DWAHgDwA6QCeA/B0A9Y9EsA+ABMCy2YBqAQwLcKxxJLGFwF0ApADYKdz7ABmAlgLoCeAbgD+af8yrvs5DsB+AO1Dtv0tgLzA9PjAOgJgJIAKAAMDy0YB2BqyrRIAIwKf7wXwFoAuALIBrAtb92IAxwTOyX8G0nBUYNl0AG+FpfNpALcFPo8OpHEwgHYA/gTgjVh+mzh/504AvgFwA4C2AI4AkB9Y9ksAxQBODBzDYABdk/0/4LcXawQUj3dV9SVVrVbVClVdoaofqGqVqm4GMA/AWVG+v0hVi1S1EkAh7J8+3nXPA7BaVV8MLJsLCxquYkzj71R1j6puhWW6zr4uBjBXVUtUtQzA76PsZzOAj2EBCgDOBbBbVYsCy19S1c1q3gDwOgDXC8JhLgZwp6ruUtVtsFJ+6H4Xqur2wDl5BhbE82LYLgBMAfCYqq5W1YMAZgM4S0R6hqwT6beppZ7f+XwAX6jq/ar6naruVdXlgWXTAfxKVT8NHMNqVd0ZY/opQRgIKB5fhE6ISF8R+Uegqr8XwO0AsqJ8/+uQz+WIfoE40rrHhqZDVRVWgnYVYxpj2heAbVHSCwDPACgIfP5PWABz0nGeiHwQaBrZDSuNR/utHMdES4OITBOR4kCTzG4AfWPcLmDHV7M9Vd0LYBeAHiHrxHTO6vmdewHYFCENvQB8FmN6ySMMBBSP8K6Tj8BKwSeo6hEAboU1fXhpO6ypBgAgIoLaGVe4xqRxOyyjctTXvfU5AKMCJeoJsMAAEckAsAjA72DNNp0BLI0xHV9HSoOIHAfgYQDXAegW2O4nIdutr6vrV7DmJmd7HWFNUF/GkK5w0X7nLwAcH+F70ZZRE2EgoMboCGAPgAMicjKAa5pgn38HMFRExotIa1i7c3eP0rgQwM9EpIeIdAPw39FWVtVvALwL4EkAG1T108CitgDaACgFcFhEzgNwThxp+JWIdBa7z2JmyLIOsMy+FBYTp8NqBI5vAPQMvWgb5lkAV4nIQBFpCwtU76hqxBpWFNF+58UAeovITBFpIyJHiEh+YNljAO4UkePFDBaRrg3YPzUCAwE1xk0ALoddvH0EViL2VCCzvQTA/wNQBitNroLd95DoND4Ma8v/CMAKWKm+Ps/ALv4+E5Lm3QBuBPA87ILrhbCAFovfwGomWwG8AuDPIdtdA+ABAMsD6/QF8EHId18D8CmAb0QktInH+f6rsCac5wPf7w27btAQEX9nVd0Du2YyCXZxeiOC1w/uAfAC7HfeC7u20K6BaaAGEmtiJWqZRCQN1sRxoaq+k+z0ELVErBFQiyMiY0SkU6A549cAqmClYiJqAAYCaomGA9gM6zY6BsCPVDVS0xAR1YNNQ0REPscaARGRz7W4QeeysrI0Jycn2ckgImpRVq5cuUNVXbtat7hAkJOTg6KiomQng4ioRRGRiHfGs2mIiMjnGAiIiHyOgYCIyOda3DUCN5WVlSgpKcHBgweTnRSKol27dujZsyfS0yMNfUNEyZASgaCkpAQdO3ZETk4ObDBKam5UFWVlZSgpKUGfPn3q/wIRNZmUaBo6ePAgunXrxiDQjIkIunXrxlob+V5hIZCTA7RqZe+FhfV9w3spUSMAwCDQAvAckd8VFgIzZgDl5Ta9bZtNA8CUho77mgApUSMgImoJbr45GAQc5eXA1KnJrR0wECRAWVkZBg8ejMGDB+Poo49Gjx49aqYPHToU0zauuOIKbNiwIeo6Dz30EAqbQz2SiOLiNAdti/KwU6d2kIx/8RY36FxeXp6G31m8fv16nHzyyTFvo7DQIvPnnwO9ewN33ZW4atltt92GDh064Oc//3mt+aoKVUWrVv6OvfGeK6KWLrw5qD5paUB1NdA18Jy2nTsTk0+JyEpVzXNb5rtcyTkp27YBqt5G4U2bNiE3NxfXXnsthg4diu3bt2PGjBnIy8tD//79cfvtt9esO3z4cKxevRpVVVXo3LkzZs+ejUGDBuG0007Dt99+CwC45ZZbcN9999WsP3v2bOTn5+Okk07Ce++9BwA4cOAAJk2ahEGDBqGgoAB5eXlYvXp1nbT95je/wSmnnFKTPqdAsHHjRowcORKDBg3C0KFDsXXrVgDA3XffjQEDBmDQoEG4+eabE/9jEaUAtwvBbs1B0Rw+bHlTWZm9vM6nAB8GgkhtdF7lbevWrcNVV12FVatWoUePHvj973+PoqIiFBcX47XXXsO6devqfGfPnj0466yzUFxcjNNOOw1PPPGE67ZVFcuXL8c999xTE1T++Mc/4uijj0ZxcTFmz56NVatWuX73hhtuwIoVK/DRRx9hz549ePXVVwEABQUFuPHGG1FcXIz33nsPRx55JF566SW88sorWL58OYqLi3HTTTcl6NchSh2RCpnRmoPi4WU+5btA8Pnn8c1vrOOPPx6nnHJKzfSzzz6LoUOHYujQoVi/fr1rIMjIyMDYsWMBAMOGDasplYebOHFinXXeffddTJ48GQAwaNAg9O/f3/W7r7/+OvLz8zFo0CC8/fbbWLt2LXbt2oUdO3Zg/PjxAOwGsMzMTCxbtgxXXnklMjIyAABdu/LZ4tQyedF109nm1Knuhcy0NPfvdesGZGbGty+v8infBYLeveOb31jt27ev+fzpp5/i/vvvxxtvvIE1a9ZgzJgxrv3q27RpU/M5LS0NVVVVrttu27ZtnXViueZTXl6OmTNn4vnnn8eaNWtw5ZVX1qTDrYunqrLrJ7V4biX2Sy8FRICsLHu1alX7c33BInSbkRw+bPsIlZkJ3H8/MG8ekJ1tyyMFjFBe5VO+CwR33VU3Cmdm2nyv7d27Fx07dsQRRxyB7du3Y8mSJQnfx/Dhw7Fw4UIAwEcffeRa46ioqECrVq2QlZWFffv24a9//SsAoEuXLsjKysJLL70EwG7UKy8vx+jRo/H444+joqICALBz586Ep5soFqEl+kgZdqR1Lr+8bondKTeFtseHt807wcJtH261ADeqwWCQnW0BYMoUe23daheHn3oqeg3By3zKd4FgypTaUTj0pHht6NCh6NevH3Jzc3H11Vfj9NNPT/g+rr/+enz55ZcYOHAg5syZg9zcXHTq1KnWOt26dcPll1+O3NxcXHDBBTj11FNrlhUWFmLOnDkYOHAghg8fjtLSUpx33nkYM2YM8vLyMHjwYMydOzfh6SaqT3iJPlKGfeml7uscPtyw/TrBwm0f8W4nO9syfrf8Jjxv6tbNXs7njAzbryf3GzjdGlvKa9iwYRpu3bp1deb5VWVlpVZUVKiq6saNGzUnJ0crKyuTnKogniv/ePpp1exsVRF7f/rpxm3HstKW/RJp2PFnZtbeTmZm/L8ngCKNkK/6rkaQ6vbv34/TTz8dgwYNwqRJk/DII4+gdeuUGUmEmjmnySS8ZB6p+2N9F29jaYNvbjIzrQTvpiFt/E3S0zFShGiuL9YIWjaeq5YpltK9W8k1/OV81ynhi0Qv6XpRE0hLc993Il7O8SWqFK8aOZ3x1i4QpUaQ9Iw93hcDQcvGc9XyRMvUQgOEk8HG0jwST7BI5Cs0Mw5Ne7du9gr9HE+wcMvkE9U0Ful3yM6ObzsMBNRs8Fy1HLFkxl6Uqp2Mtb51omXYznRoBt+QzDha7cWZbkwmH2saeI2AiJqMWxt/NKrepCNal8zMTODpp4EdO+ylCsyfX7sn4Pz5Nt9Zp7o6cm+daJzundH20ZDtxpsGz3s6RooQzfXFGkHLxnPlvXibJKKVehv7SvT2vC59pzKwRuCtESNG1Lk57L777sOPf/zjqN/r0KEDAOCrr77ChRdeGHHb4aOthrvvvvtQHlKEGjduHHbv3h1L0inFRLt7NpZeOYko4ael1S41Z2dHXz/Wm9aj9cGnxmEgSICCggIsWLCg1rwFCxagoKAgpu8fe+yxWLRoUYP3Hx4IXn75ZXTu3LnB26Pmq77ulm5dDZ3M3S0oxDsyZn0yM+0O2dCmGLe7+UPvsp0/v/5g0FR3//tWpKpCc301x6ahHTt2aFZWlh48eFBVVbds2aK9evXS6upq3bdvn44cOVKHDBmiubm5+sILL9R8r3379jXr9+/fX1VVy8vL9ZJLLtEBAwboxRdfrPn5+bpixQpVVb322mt12LBh2q9fP7311ltVVfX+++/X9PR0zc3N1REjRqiqanZ2tpaWlqqq6pw5c7R///7av39/nTt3bs3++vbtq9OnT9d+/frpueeeq+Xl5XWOa/HixZqfn6+DBw/Wc845R7/++mtVVd23b59OmzZNc3NzdcCAAbpo0SJVVX3llVd0yJAhOnDgQB05cqTrb5Xsc9VcRerBEtoUEstFw3iaYmK5IBu+/nXX1f1eLBdN62uuinZRms1BiQE/9Rq64QbVs85K7OuGG+r/kceNG1eTyf/ud7/Tn//856pqd/ru2bNHVVVLS0v1+OOP1+rqalV1DwRz5szRK664QlVVi4uLNS0trSYQlJWVqapqVVWVnnXWWVpcXKyqtTP+0OmioiLNzc3V/fv36759+7Rfv3764Ycf6pYtWzQtLU1XrVqlqqoXXXSRzp8/v84x7dy5syatjz76qM6aNUtVVX/xi1/oDSE/ys6dO/Xbb7/Vnj176ubNm2ulNZzfA4Fbhlhf/3sns4/WjdCr7pZumXyiukWG/y6J6ndP7qIFAjYNJUho81Bos5Cq4le/+hUGDhyIUaNG4csvv8Q333wTcTv//Oc/MXXqVADAwIEDMXDgwJplCxcuxNChQzFkyBCsXbvWdUC5UO+++y4uuOACtG/fHh06dMDEiRPxzjvvAAD69OmDwYMHA4g81HVJSQl++MMfYsCAAbjnnnuwdu1aAMCyZcvwk5/8pGa9Ll264P3338eZZ56JPn36APDPUNXxDGscabz6G26I3jzj3EUaaQhip8knUXffhjfbaFjPmNCB0hLVZp/MMcAISLmxBwIP8GpyP/rRjzBr1ix8+OGHqKiowNChQwHYIG6lpaVYuXIl0tPTkZOT4zr0dCi3IZ+3bNmCe++9FytWrECXLl0wbdq0erdjhQB3zhDWgA1j7YwsGur666/HrFmzcP755+Ott97CbbfdVrPd8DS6zUt14Y8gdDLkqVODQwyEPmYw0lABsbTRO49VjZTZRzrVIvFdAM7OTuyjW+PhjMZJTY81ggTp0KEDRowYgSuvvLLWReI9e/bgyCOPRHp6Ot58801sq6fYduaZZ9Y8oP7jjz/GmjVrANgQ1u3bt0enTp3wzTff4JVXXqn5TseOHbFv3z7Xbb3wwgsoLy/HgQMH8Pzzz+OMM86I+Zj27NmDHj16AACeeuqpmvmjR4/Ggw8+WDO9a9cunHbaaXj77bexZcsWAP4YqjrahVm3xww2psTuBJN4HmQiUrvXTn1xWoS9cvyKgSCBCgoKUFxcXPOEMACYMmUKioqKkJeXh8LCQvTt2zfqNq677jrs378fAwcOxB/+8Afk5+cDsKeNDRkyBP3798eVV15ZawjrGTNmYOzYsTj77LNrbWvo0KGYNm0a8vPzceqpp2L69OkYMmRIzMdz22234aKLLsIZZ5yBrKysmvm33HILdu3ahdzcXAwaNAhvvvkmunfvjnnz5mHixIkYNGgQLrnkkpj301LF87SoaE+qqk96OrB/v9U2MjIiD2gWrndv9xuioq1P/iTRmg+ao7y8PA3vV79+/XqcfPLJSUoRxSOVzlVOTvyl/FiaakKblbp2BfbtAw4dCi7PzLSAUFYWeRuZmZHb2MObtOpbn1KDiKxU1Ty3ZawREDVQvE01gAWBaE002dm1h0Xo0KF2EACCGXi0vvnRMnVemKVwDATkC9F69zT0geahGSoQ+x2yqu4PLne7aSpS89POnXUz83jGvvGi5w+1YJH6lTbXV6T7CJz+7tR8VVdXJ+w+gnj6srv1UQ8dnbJNm/j6r0fat9tNYdH658dyDIkagpgIqX5D2ebNm7W0tJTBoBmrrq7W0tLSmhvOYhUpc63vgSahGnKjVehNWl7sO9aMnDdaUaJECwQpcbG4srISJSUl9farp+Rq164devbsifT09JjWd7uoWR+3fvCtWsXXl96RmRn7vp0B0cIl4sKsMyaQcy9Bsvr5U8sW7WJxSgQCSk0N6ZUD1M1oG7KdtDTg8OHY1xex9nY3zMipOWAgoBapoSV5oHYJPd6aRbx344bvj6g5Slr3UREZIyIbRGSTiMx2Wd5bRN4UkVUiskZExnmZHmq+3HruNOYGp9DeNvX17klPD/bdb0gQ4BDJ1NJ5FghEJA3AQwDGAugHoEBE+oWtdguAhao6BMBkAH/yKj2UPKGZfFaWvUIz/EiDsY0bF72ffrTumqq193XzzZZZq9Z95OCTT1q//ezs2INArH32iVoCLwedywewSVU3A4CILAAwAUDokJkK4IjA504AvvIwPZQE4c0yoXfDOhl+Rob7YGwvv2yZrNO+7gxoGjqQGxC52cdtX0Dkwc2iDRnhNogcM39KFZ5dIxCRCwGMUdXpgelLAZyqqjND1jkGwFIAXQC0BzBKVVe6bGsGgBkA0Lt372H1DdxGzUdDL/g6YhkN07kYG8t+orXlR0or2/8pFSTrGoFbxT086hQA+D9V7QlgHID5IlInTao6T1XzVDWve/fuHiSVGivS3bnxDMzmxinJR7vb17lLNpY7e6Olx23ICLb/pxZV4NNPG94JIVV5GQhKAPQKme6Juk0/VwFYCACq+m8A7QBkgVoUtzb+K66w9vlE/MM5D2apTywXl6OtwzF4Ut/99wPf+569U5CXgWAFgBNFpI+ItIFdDF4cts7nAM4BABE5GRYISj1ME3nAbVz+ysroo2PGK5aaRX2DwMVSuucYPN5TBc4/Hzj3XDsf770X3z0bkWzfDjz4IFBV5b78zTeBn/8caNcO+PWvgZKSxu8zZUS65TgRL1hzz0YAnwG4OTDvdgDnBz73A/AvAMUAVgMYXd823YaYoOSK54Hp9Y3Bk5bW+CEZ6nsIPHkrwuOqa/zrX3ZOe/UKnt8RI1T372/cfqdNs2397Gd1l23bptq9u2rfvqrFxaoZGaoXXNC4/cVrzx7VNWvqzl+xQvXEE1U/+cTb/SPVxxqi5Ij3gekitb/rNobOdddxbJ1kOXSo8dv44x/tnD3wQOR1fvxj1XbtLGMsLbXvtGplweDAAVtnyxbVyZNVZ8+Obb87d9o2u3e3/T/6aHBZWZlqXp5qx47BzPb3v7f1XnyxQYcZt48/Vj3hBCvobNtWe9m111paRo1S9XK4NAYCSpjQzD+emoBbqT6WUTxZkvfe3r2q55xjo7COHm0Zc0lJ3fWqq1U//VR161bLXCsray9/8EE7zx07Wqa8fn3dbRw6pJqVpXrxxbXnFxZaMDj7bNU77rASO6DaurXqV1/VXnf5cttXqPvus/WLiuwY0tMtk7/lFktPq1a1M/1Dh1Rzc61Wsndv7L9VQ/ztb6odOgSD1B/+EFxWVaV61FHBWvLChd6lg4GAImrscM6Rmn/iHdqZGue771QHD7aMLx5lZar5+VZSveIK1e99z85XRobq888H1ztwwJpSQs9perqVYh94QPV//sfmTZig+vnn9jeQl1e3lvH3v2vEkvj8+ZZhA6oXXqj6+uv2+e67g+scPmzNO4DqokU2r7ra5n3/+za9a5fqSScF03nhhaoffVR3f//6l+3v+ONV33orvt8tVn/6k6UhP9+Ca36+6pAhweVvv23LCwttfo8e3gUmBgKqJVqp3pl2K6HH0/zTXEv1O3fGt35TjmxeWqr63HOW2YWnYfny6E03r70WPAd/+lNs+/vmG9WBAy1ov/BCcP66dZZhiajee6+VyPPybPrXv1Z97DHVuXNVZ80KZsqA6vnnW0BSVf3LX2zeb39be58FBapduwbXczuON94ITo8YodqnT/A3+etfbbtdu6oeeaT9Zm++afP+7/+C39u0SfXGG+16QDRvvWWBALAmGre/j9273X/7BQtUL7lEddw41TPOUL3pJivhO1assGA5bpxqRYXNmzvX9uXUln76U9W2bS3zf+89W/Zf/xU9zQ3FQEA1Yi3VhwaFeJqAmusDU6qr7R9MRHXevPrXP3jQMsGsLNXOnVVPPtmaT2bOtAzno4/qZthlZapXXaV60UXWRBGPzZutDdmttLxokc0/5RTVDRvcv3/99VaKHzvWSrn/+Ef9+xwzxr6zZEndZQcOqE6apDVNPZmZkdvTN260ZeGZ+5Qp1rSzbJlN79tn27nmmvrT5njmGUvD0qV2DvPy7Hdatcoy2YICy4w7d1YtL499u+HHetNN9rt16qT6m99YrWL1atVLL7VjuP762t+prLS/jW7dVIcNs9oIYMdcVWXXP44/3pqeQi+ef/WV/Q3eeqv9/fTsabUox1VX2f68uHDMQEA1GvKQllhfzbn55447LI09etj7Y49FXnfhQiuFAtbePHOmZYqnnmptvc7xHn+86kMPWUby2muqxx5r/8SdO2tNCfmPf7R/7sGDbVuhJUbHqlWqRx+t2qWL6jHHWOnS4WR+xx5ryzMzVR95pHZNpbpatXdv29++fdbE0L696j33qD7+uB3Prl2197lhg6Xx9tsj/w6HD6v+6lcWBFeujO13DrVzp303Lc1+h6eftn3+85+xb6OiwjLbCy8M1nqcQH777TbdqpV7T6F4FRcHm7+cwlL79hZ4unSpHeiWLdNazVOqqnfdZfOmTrUL3Wlpqu++W3c/I0faNv/9b1v/z38OLvvmG7u+cvXVdb/39deNOz4GAqoR7wXeWGsNzan5J5xTHb/sMis1jhlj6X788brrPvqorTtokJVCw1VVWdPJE09YYACsFAlYM0lRkZUG77gjGBC6dbOmFsBKuKGWL7cSd69etl0nrR98YMvfeMOm//d/rY151Ki6gWz1apvnHM+XX1p3xNDzdMoptWswN95oQWv79sb9tvXZvVt1/HhLwxFHWMAKr0nVZ9YsS6sTEA8etPmHDlmADW1qSYRVq1SnT7eeRTt3Wu0KUF28OLjONddYsHB6OTnuvDP4m991l/v2H3vMlp99ttVqwoP0NddYc1Foxr91qxVCHnqo4cfFQEA1ElkjaGjmv3dvw9reS0utCj9nTt1le/a4N5u8+KKldeLEYC+XiopgMLj77mBa3n7b/jFHj67bI8ZNdbWV+AoKrNkpPFPYt88unFZXW+aXm2sXY0PT0bevZY5ffGHz9u61wOL0qvnhD60t3GljPnzYgkp2drCEevvtdiyhGUdVlTVJbN0a7FHjBKEDByxIXXJJ/ceYCIcPW1MIEP/FbFXL5J2/uXvvrb1syxbVZ59NSDIjOnTIgnlBgU1XVloPoPCeT465cy0zd6v9qVpwSU+34xk7tu7yTz4JXo9Rtb+f8eMt8Gzd2vDjYCCgGtEe5B5rbaExTUBLl9rFyalTI2e25eWWcfzkJ6pPPmkl3t//3kqUgLVrh998dNVVVqUOfSRyZaX1HunXL1iKdFRU2D82EOxVkpVlGXV4CS1RnAudTz1l07/+tU2/+mrt9f77v6254/nn1bVk+fLLNt/pKz9smOppp0Xeb1WVlZyzs+24H3/cvv/22wk7tJhs3NjwexXOPNMuEHvd1TMSpwawf3+wN9Nf/tLw7U2YoFGbKCdMsOM9cMC6nwLW1NcYDAQU0x238fYmUrXSXnGxewk/PLNescLaXI8+2rY1aVLdC4wffmjtykDt9njASkUPP1z3n/DgwWDzzMSJwflPPGHzQrtBhqquthJmq1Z2fJ07R74YmwjV1dZ+f9xxdpytW9vFyHAlJbasbVv7DcJ7slRXW1NPTo6ViAELlNE47ev33KM6dKhq//5N2yOqsUpKrOksWd56S2tqVdde694sFI+lS63QsWOH+/J33gme1x49rKmysTf8MRD4VLSMvb5SfazdP+fNs+39x38Emze+/DJY2v7BD6wk/MknVp3OybGeE05b+Nix1gb76KPWbp2ebu3AS5dakFm/3vpYOxfdnGr55MnBNDjNP+ecY+/Llllw6N3bMsz6MrylSy1zdHq3eGnxYktj585WAyktdV/vsstsvVmz3Jc77dY/+IG9x5JJjh1rtSagcW3NfnT4sGXI48ZZU91FF3m7v+rq4HUlEdX332/8NhkIUpxbph1LN9F4unpWVwfbqUONH2+ZWkaGNd385Cd28bNtW+v54PS+adXKMr7QEmZ9Q0oAABXvSURBVPe8eXUD1MUXRy4lOa6+2krKTnoKCqyGs3ev7a9/f7uOAFhJuDlxSvNuF45Dbdigeu65FlQjbScvz7Zzwgmxle4/+sjOQ4cOdk2F4nPTTcG/Uy/vAHYsXGj7uu66xGyPgSAFxdKMU98rdOyfaDZtsjboY46p3Vf7u+8sU7n2WtXPPrNucU4p/9NPbZ3KSvuDnjjRmobCrV1rpZ1t2yLfZBRuyRLbz4svWvNTaN/0F14IBp6zz26ezR/r11uJvLFpc+7SjVRrcDNnTuw3nFFtRUUa8RqVFw4ftppfQ++PCMdAkGLiuSmsMTWC6mprZ+/QwUr4gDXzOJx2U6cN3hmLxuvM99Ah69d96aV2Jy4QvBu1utp6/QB2p2Yqq662JjWvu4CSqa62i+6XXZbslDRMtEDg5TOLySNu4//HK9LY/I8/DsyZA+zbZ689e4ARI4AnngBOPRVYsACYONHWXbIEaN0aGDnSpkWAE05oXLpikZ4OTJgAPP+8PUP46KOBM88MpuGZZ4CVK4HTTvM+LckkAkyfnuxU+IeIPTshLS3ZKUk8Lx9MQx5p6OMfnUc5Rnry1s6dwA032B/6qFHAZZfZeq+/DvTpA1x0EfD3vwP799v6S5ZYZnvEEQ0/loaaNMmC1D/+AVx8ce1/zm7dgNGjmz5NlPoyMoA2bZKdisRjIGghQp8J3KoBZy07G5g/354adt99VmL+299qr/Pgg8CBA8CzzwJPPgk88ABw9dXB/U2eDFRUAC+9BHz7LfDhh8nLcM89F+jYMZguImo4Ng21AM4zgZ3mILfH+olYy7/z7sjMtFL9hAlWcr700uDyhx8GioqA/v2tlH///cD48UBurns6Tj8d6NHDmoecbfzwh4k7zni0bWvH8+67wPe/n5w0EKUK1ghagEjXBNLSLOPv3duewXrggJX6wx++PnGiPSN26VLb1jvv2APmO3YE/vM/ge++Ax591JqGfvnLyOlo1Qq45BLglVeA556zJpihQ7077vr86U8WyJwmLyJqoEhXkZvry0+9hup7DoCI9aC5+mqbzs2tO/jWoUN2s5eIPfgj1Esv2fdmzrSbZc46q/40LV8e3H9TjVVDRI0H9hpqOQoLrdS+bVvdZp5wPXsC48YBy5YBV15pbfd5edbkM2CAlZYXLgReew343/8Fpk6t/f3zzgN+/GO7NgBYz6D65OUBxx0HbN6cvGYhIkosBoJmIFLmHy0ItG1r1wreftsu7E6bBnz5JVBQYL19HJ06Wdv/Nde4b+eee6ypqGNHuwBbHxFrTrr7bvbMIUoVotFym2YoLy9Pi4qKkp2MRoun5B+ubVtr1+/Rw64JnH12cFlVFfD000C7dsHSe329jA4dsqCSkRHb/isqgHXrgGHDYk8zESWXiKxU1Ty3ZawRNKGGlPzdZGXZRd3p0y0ohGrd2moH8Yi3X3RGBoMAUSphIGgi4V1AG1IRE7Hun488YiV+IqJEYPfRJtLYYSG6dLHhH556ikGAiBKLgaCJNGRYiOxsa+9XtT7+V1yR+HQREbFpqIn07m3XBiJxrhl06GAXfPfvT83BrYio+WGNoIncdZcN9+CmTRvr/aMKnHQS8IMfMAgQUdNhIPCYM1jcpZdab5tu3YLLxo0Dbr8dqKy0PvkVFUBxsQ33TETUVBgIGqmiwjLyUE7m7/Ty2bbNSvtlZba+c8PX734HjB1ry5YutdE8q6o4iBoRNS1eI2iE6mqgXz9g926gb19g0yZgx47o9wiUl9vonYMGAQMH2ja6d7eB3IYMsXVYIyCipsRA0Aj33ANs3Wqf338/OL++ewQOHQIuv9w+t2plY/a8+ipw8KD1FDrqKE+SS0Tkik1DDVRYaEM/N1RBQfDz2LFWk1i8mM1CRNT0WCNooJtvrnttIBZt2tiY/kcfHZw3erQ1J1VWslmIiJoeawQNFO2egEiys22o5z//ufb8rCzglFPsMwMBETU11gga6Nhjga++irzcuWDcurU9G+DDD6Nv78ILgU8/DV4wJiJqKqwRNND48XXnOY9MTE+3G8R27bLuoJMm1b+9WbPsYS+xDgVNRJQongYCERkjIhtEZJOIzHZZPldEVgdeG0Vkt5fpSQTnHoFHHrGMv2vX4POB588Hfvtby/zPOw9YscK+E0tzT1oa0Lmzp0knInLlWdOQiKQBeAjAuQBKAKwQkcWqus5ZR1VvDFn/egDNumHEbSjpgwctAEyZYvPeeMPm//vf9qhIwB4QQ0TUXHlZI8gHsElVN6vqIQALAEyIsn4BgGc9TE+DqAI/+5kN/Tx1at2hpMvLrQeR49RTrXT/7rvABx/YjWYs6RNRc+ZlIOgB4IuQ6ZLAvDpEJBtAHwBvRFg+Q0SKRKSotLQ04QmNxMnI77/fHg0ZSegQ0+3b2wXfd94Bli9nLyAiav68DATiMi/SPbeTASxS1cNuC1V1nqrmqWpe9+7dE5bAaD75BDj9dBs2oj69e9eeHj7cagTffstAQETNn5eBoARAr5DpngAidbicjGbWLFRYaM1C1dXR18vMtCGmQw0fHvxefr436SMiShQvA8EKACeKSB8RaQPL7BeHryQiJwHoAuDfHqYlJqGjht59d/3PBMjOBubNC14odpx+ur23a2cDyxERNWee9RpS1SoRmQlgCYA0AE+o6loRuR1Akao6QaEAwALVhjzOPXHCewRVV0euDWRkAA8/HBw4LtzRRwMnnggceaTdU0BE1JxJkvPfuOXl5WmR0y8zgXJyYhs2IjvbmoLCawHhVq8G2rYFTj45IckjImoUEVmpqq6d2TnEBKwWEMvD5UWCw07XZ/DgRiWJiKjJ+H6IiTvuAI44AujSpf51w3sHERGlAl8HgjvuAG691R4Es3Nn9PZ8t95BRESpwLeB4M47LQhcdhnw2WfARRfVfr5At272csYRcusdRESUCnx5jWDJEnu62PDhwFtvWWm/Vy/gjDPsjuC//Q244IJkp5KIqGn4MhCsXWvvK1cCFRX2+fPPgdJSa/750Y+SlzYioqbmy6ahsjJ7d4KAo6LCmoDEbXAMIqIUVW8gCNwZ3C5kOkNEcrxMlNecQOAmlm6kRESpJJYawV8AhN5jezgwr8XasSNyDyF2ESUiv4klELQOPE8AABD43Ma7JHmvrAzo08cuEodiF1Ei8qNYAkGpiJzvTIjIBAA7vEuS98rKbOiHefOsayi7iBKRn8XSa+haAIUi8mBgugTAZd4lyXtlZTY89JQpzPiJiOoNBKr6GYDvi0gH2CB1+7xPlndULRB065bslBARNQ+x9Bq6W0Q6q+p+Vd0nIl1E5M6mSJwXysvtsZMMBEREJpZrBGNVdbczoaq7AIzzLknecrqOMhAQEZlYAkGaiLR1JkQkA0DbKOs3azsCl7kZCIiITCwXi58G8LqIPBmYvgLAU94lyVusERAR1RbLxeI/iMgaAKMACIBXAWR7nTCvMBAQEdUW61hDX8PuLp4E4BwA6z1LkcecQJCVldx0EBE1FxFrBCLyPQCTYQ+XLwPwHKz76NlNlDZPOIGga9fkpoOIqLmI1jT0CYB3AIxX1U0AICI3NkmqPFRWBnTqBLT25QDcRER1RWsamgRrEnpTRB4VkXNg1whatB07eH2AiChUxECgqs+r6iUA+gJ4C8CNAI4SkYdFZHQTpS/heFcxEVFt9V4sVtUDqlqoqucB6AlgNYDZnqfMIwwERES1xfWEMlXdqaqPqOpIrxLkNQYCIqLafPeoyq+/BhYvBlq1AnJygMLCZKeIiCi5fNV35qmnaj+neNs2YMYM+8zhqInIr3xVI7jllrrzysuBm29u+rQQETUXvgoEJSXu8/nAeiLyM18FgqOOcp/PB9YTkZ/5KhBMnlx3Hh9YT0R+56tAkJtr7z168IH1REQOX/Uacgac27jRagJEROSzGsGOHUC7dgwCREShfBUIeFcxEVFdDARERD7HQEBE5HOeBgIRGSMiG0Rkk4i4jlgqIheLyDoRWSsiz3iZHgYCIqK6POs1JCJpAB4CcC6AEgArRGSxqq4LWedEAL8EcLqq7hKRI71KD2CBgM8qJiKqzcsaQT6ATaq6WVUPAVgAYELYOlcDeEhVdwGAqn7rVWKqq1kjICJy42Ug6AHgi5DpksC8UN8D8D0R+ZeIvC8iY7xKzJ49FgwYCIiIavPyhjK35xury/5PBDAC9vSzd0QkV1V319qQyAwAMwCgdwMHBnJuJmMgICKqzcsaQQmAXiHTPQF85bLOi6paqapbAGyABYZaVHWequapal737t0blBgGAiIid14GghUAThSRPiLSBsBkAIvD1nkBwNkAICJZsKaizV4khoGAiMidZ4FAVasAzASwBMB6AAtVda2I3C4i5wdWWwKgTETWAXgTwH+papkX6WEgICJy5+mgc6r6MoCXw+bdGvJZAcwKvDy1Y4e9s/soEVFtvrmzeMAA4LrrgE6dkp0SIqLmxTfDUI8aZS8iIqrNNzUCIiJyx0BARORzDARERD7HQEBE5HMMBEREPsdAQETkcwwEREQ+x0BARORzDARERD7HQEBE5HMMBEREPsdAQETkcwwEREQ+x0BARORzDARERD7HQEBE5HMMBEREPsdAQETkcwwEREQ+x0BARORzDARERD7HQEBE5HMMBEREPsdAQETkcwwEREQ+x0BARORzDARERD7HQEBE5HMMBEREPsdAQETkcwwEREQ+x0BARORzDARERD7HQEBE5HMMBEREPsdAQETkc54GAhEZIyIbRGSTiMx2WT5NREpFZHXgNd3L9BARUV2tvdqwiKQBeAjAuQBKAKwQkcWqui5s1edUdaZX6SAioui8rBHkA9ikqptV9RCABQAmeLg/IiJqAC8DQQ8AX4RMlwTmhZskImtEZJGI9HLbkIjMEJEiESkqLS31Iq1ERL7lZSAQl3kaNv0SgBxVHQhgGYCn3DakqvNUNU9V87p3757gZBIR+ZuXgaAEQGgJvyeAr0JXUNUyVf0uMPkogGEepoeIiFx4GQhWADhRRPqISBsAkwEsDl1BRI4JmTwfwHoP00NERC486zWkqlUiMhPAEgBpAJ5Q1bUicjuAIlVdDOCnInI+gCoAOwFM8yo9RETkTlTDm+2bt7y8PC0qKkp2MoiIWhQRWamqeW7LeGcxEZHPMRAQEfkcAwERkc8xEBAR+RwDARGRzzEQEBH5HAMBEZHPMRAQEfkcAwERkc8xEBAR+RwDARGRzzEQEBH5HAMBEZHPMRAQEfkcAwERkc8xEBAR+ZwvAkFhIZCTA7RqZe+FhclOERFR8+HZoyqbi8JCYMYMoLzcprdts2kAmDIleekiImouUr5GcPPNwSDgKC+3+URE5INA8Pnn8c0nIvKblA8EvXvHN5+IyG9SPhDcdReQmVl7XmamzSciIh8EgilTgHnzgOxsQMTe583jhWIiIkfK9xoCLNNnxk9E5C7lawRERBQdAwERkc8xEBAR+RwDARGRzzEQEBH5nKhqstMQFxEpBbAtjq9kAdjhUXKaMz8etx+PGfDncfvxmIHGHXe2qnZ3W9DiAkG8RKRIVfOSnY6m5sfj9uMxA/48bj8eM+DdcbNpiIjI5xgIiIh8zg+BYF6yE5AkfjxuPx4z4M/j9uMxAx4dd8pfIyAiouj8UCMgIqIoGAiIiHwupQOBiIwRkQ0isklEZic7PV4QkV4i8qaIrBeRtSJyQ2B+VxF5TUQ+Dbx3SXZaE01E0kRklYj8PTDdR0Q+CBzzcyLSJtlpTDQR6Swii0Tkk8A5P80n5/rGwN/3xyLyrIi0S7XzLSJPiMi3IvJxyDzXcyvmgUDetkZEhjZm3ykbCEQkDcBDAMYC6AegQET6JTdVnqgCcJOqngzg+wB+EjjO2QBeV9UTAbwemE41NwBYHzL9PwDmBo55F4CrkpIqb90P4FVV7QtgEOz4U/pci0gPAD8FkKequQDSAExG6p3v/wMwJmxepHM7FsCJgdcMAA83ZscpGwgA5APYpKqbVfUQgAUAJiQ5TQmnqttV9cPA532wjKEH7FifCqz2FIAfJSeF3hCRngD+A8BjgWkBMBLAosAqqXjMRwA4E8DjAKCqh1R1N1L8XAe0BpAhIq0BZALYjhQ736r6TwA7w2ZHOrcTAPxZzfsAOovIMQ3ddyoHgh4AvgiZLgnMS1kikgNgCIAPABylqtsBCxYAjkxeyjxxH4BfAKgOTHcDsFtVqwLTqXi+jwNQCuDJQJPYYyLSHil+rlX1SwD3AvgcFgD2AFiJ1D/fQORzm9D8LZUDgbjMS9m+siLSAcBfAfxMVfcmOz1eEpHzAHyrqitDZ7usmmrnuzWAoQAeVtUhAA4gxZqB3ATaxScA6APgWADtYU0j4VLtfEeT0L/3VA4EJQB6hUz3BPBVktLiKRFJhwWBQlX9W2D2N05VMfD+bbLS54HTAZwvIlthTX4jYTWEzoGmAyA1z3cJgBJV/SAwvQgWGFL5XAPAKABbVLVUVSsB/A3AD5D65xuIfG4Tmr+lciBYAeDEQM+CNrCLS4uTnKaEC7SNPw5gvar+v5BFiwFcHvh8OYAXmzptXlHVX6pqT1XNgZ3XN1R1CoA3AVwYWC2ljhkAVPVrAF+IyEmBWecAWIcUPtcBnwP4vohkBv7eneNO6fMdEOncLgZwWaD30PcB7HGakBpEVVP2BWAcgI0APgNwc7LT49ExDodVCdcAWB14jYO1mb8O4NPAe9dkp9Wj4x8B4O+Bz8cBWA5gE4C/AGib7PR5cLyDARQFzvcLALr44VwD+C2ATwB8DGA+gLapdr4BPAu7BlIJK/FfFencwpqGHgrkbR/BelQ1eN8cYoKIyOdSuWmIiIhiwEBARORzDARERD7HQEBE5HMMBEREPsdAQBQgIodFZHXIK2F37YpITuiokkTNSev6VyHyjQpVHZzsRBA1NdYIiOohIltF5H9EZHngdUJgfraIvB4YD/51EekdmH+UiDwvIsWB1w8Cm0oTkUcD4+ovFZGMwPo/FZF1ge0sSNJhko8xEBAFZYQ1DV0SsmyvquYDeBA2rhECn/+sqgMBFAJ4IDD/AQBvq+og2FhAawPzTwTwkKr2B7AbwKTA/NkAhgS2c61XB0cUCe8sJgoQkf2q2sFl/lYAI1V1c2CAv69VtZuI7ABwjKpWBuZvV9UsESkF0FNVvwvZRg6A19QeMAIR+W8A6ap6p4i8CmA/bMiIF1R1v8eHSlQLawREsdEInyOt4+a7kM+HEbxG9x+wcWOGAVgZMqImUZNgICCKzSUh7/8OfH4PNvopAEwB8G7g8+sArgNqnqt8RKSNikgrAL1U9U3Yg3Y6A6hTKyHyEkseREEZIrI6ZPpVVXW6kLYVkQ9ghaeCwLyfAnhCRP4L9uSwKwLzbwAwT0SugpX8r4ONKukmDcDTItIJNqLkXLXHTxI1GV4jIKpH4BpBnqruSHZaiLzApiEiIp9jjYCIyOdYIyAi8jkGAiIin2MgICLyOQYCIiKfYyAgIvK5/w+aKR8XAn1iuAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(cifar_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out the best # of epochs using EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 1.0011 - accuracy: 0.5178 - val_loss: 0.8711 - val_accuracy: 0.6393\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.8361 - accuracy: 0.6562 - val_loss: 0.7945 - val_accuracy: 0.6763\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.7860 - accuracy: 0.6767 - val_loss: 0.7683 - val_accuracy: 0.6807\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.7525 - accuracy: 0.6902 - val_loss: 0.7203 - val_accuracy: 0.7180\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.7305 - accuracy: 0.7013 - val_loss: 0.6944 - val_accuracy: 0.7237\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.6992 - accuracy: 0.7218 - val_loss: 0.7011 - val_accuracy: 0.7080\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6807 - accuracy: 0.7278 - val_loss: 0.6693 - val_accuracy: 0.7243\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6632 - accuracy: 0.7368 - val_loss: 0.6601 - val_accuracy: 0.7310\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.6605 - accuracy: 0.7317 - val_loss: 0.6620 - val_accuracy: 0.7303\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6491 - accuracy: 0.7381 - val_loss: 0.6423 - val_accuracy: 0.7417\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.6334 - accuracy: 0.7417 - val_loss: 0.6316 - val_accuracy: 0.7383\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6204 - accuracy: 0.7487 - val_loss: 0.6637 - val_accuracy: 0.7233\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6132 - accuracy: 0.7507 - val_loss: 0.6074 - val_accuracy: 0.7557\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 0s 22us/step - loss: 0.5917 - accuracy: 0.7633 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5828 - accuracy: 0.7656 - val_loss: 0.6240 - val_accuracy: 0.7313\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.6033 - accuracy: 0.7538 - val_loss: 0.6842 - val_accuracy: 0.7077\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5877 - accuracy: 0.7603 - val_loss: 0.6230 - val_accuracy: 0.7443\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5671 - accuracy: 0.7717 - val_loss: 0.5901 - val_accuracy: 0.7613\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.5461 - accuracy: 0.7812 - val_loss: 0.5792 - val_accuracy: 0.7663\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5472 - accuracy: 0.7804 - val_loss: 0.5851 - val_accuracy: 0.7610\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 0s 22us/step - loss: 0.5519 - accuracy: 0.7778 - val_loss: 0.6195 - val_accuracy: 0.7513\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5400 - accuracy: 0.7804 - val_loss: 0.6145 - val_accuracy: 0.7480\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5286 - accuracy: 0.7869 - val_loss: 0.5701 - val_accuracy: 0.7720\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.5217 - accuracy: 0.7863 - val_loss: 0.6136 - val_accuracy: 0.7507\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5354 - accuracy: 0.7840 - val_loss: 0.5969 - val_accuracy: 0.7590\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.5045 - accuracy: 0.7972 - val_loss: 0.5638 - val_accuracy: 0.7767\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4956 - accuracy: 0.8017 - val_loss: 0.6110 - val_accuracy: 0.7450\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4866 - accuracy: 0.8055 - val_loss: 0.5597 - val_accuracy: 0.7683\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4880 - accuracy: 0.8048 - val_loss: 0.5763 - val_accuracy: 0.7703\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 0s 22us/step - loss: 0.4902 - accuracy: 0.8031 - val_loss: 0.7093 - val_accuracy: 0.7050\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 0s 23us/step - loss: 0.5180 - accuracy: 0.7910 - val_loss: 0.5559 - val_accuracy: 0.7817\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4783 - accuracy: 0.8075 - val_loss: 0.5507 - val_accuracy: 0.7803\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4764 - accuracy: 0.8084 - val_loss: 0.5508 - val_accuracy: 0.7780\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4784 - accuracy: 0.8059 - val_loss: 0.5594 - val_accuracy: 0.7783\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.4625 - accuracy: 0.8146 - val_loss: 0.5704 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4524 - accuracy: 0.8202 - val_loss: 0.5436 - val_accuracy: 0.7867\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4443 - accuracy: 0.8241 - val_loss: 0.6116 - val_accuracy: 0.7523\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4519 - accuracy: 0.8204 - val_loss: 0.5638 - val_accuracy: 0.7803\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4422 - accuracy: 0.8275 - val_loss: 0.5613 - val_accuracy: 0.7773\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4302 - accuracy: 0.8293 - val_loss: 0.5561 - val_accuracy: 0.7830\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 0.4226 - accuracy: 0.8335 - val_loss: 0.6072 - val_accuracy: 0.7667\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4316 - accuracy: 0.8253 - val_loss: 0.5535 - val_accuracy: 0.7863\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4328 - accuracy: 0.8292 - val_loss: 0.5681 - val_accuracy: 0.7753\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4199 - accuracy: 0.8341 - val_loss: 0.5419 - val_accuracy: 0.7883\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4146 - accuracy: 0.8382 - val_loss: 0.5496 - val_accuracy: 0.7850\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4103 - accuracy: 0.8390 - val_loss: 0.5606 - val_accuracy: 0.7873\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4157 - accuracy: 0.8364 - val_loss: 0.5559 - val_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4110 - accuracy: 0.8382 - val_loss: 0.5472 - val_accuracy: 0.7910\n",
      "Epoch 49/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4119 - accuracy: 0.8367 - val_loss: 0.5578 - val_accuracy: 0.7867\n",
      "Epoch 50/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4134 - accuracy: 0.8389 - val_loss: 0.5460 - val_accuracy: 0.7857\n",
      "Epoch 51/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4006 - accuracy: 0.8425 - val_loss: 0.5423 - val_accuracy: 0.7873\n",
      "Epoch 52/100\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3948 - accuracy: 0.8434 - val_loss: 0.5501 - val_accuracy: 0.7937\n",
      "Epoch 53/100\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 0.3891 - accuracy: 0.8484 - val_loss: 0.5650 - val_accuracy: 0.7830\n",
      "Epoch 54/100\n",
      "12000/12000 [==============================] - 0s 17us/step - loss: 0.3881 - accuracy: 0.8462 - val_loss: 0.5658 - val_accuracy: 0.7797\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "cifar_model = Sequential()\n",
    "cifar_model.add(Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "cifar_model.add(Dense(64, activation='relu'))\n",
    "cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "cifar_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cifar_history = cifar_model.fit(partial_x_train, \n",
    "                                partial_y_train,\n",
    "                                epochs=100,\n",
    "                                batch_size=512,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 1.0058 - accuracy: 0.5210\n",
      "Epoch 2/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.8099 - accuracy: 0.6609\n",
      "Epoch 3/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.7621 - accuracy: 0.6874\n",
      "Epoch 4/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.7437 - accuracy: 0.6926\n",
      "Epoch 5/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.7135 - accuracy: 0.7094\n",
      "Epoch 6/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6951 - accuracy: 0.7159\n",
      "Epoch 7/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6767 - accuracy: 0.7239\n",
      "Epoch 8/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.6626 - accuracy: 0.7334\n",
      "Epoch 9/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6556 - accuracy: 0.7335\n",
      "Epoch 10/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6500 - accuracy: 0.7361\n",
      "Epoch 11/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6346 - accuracy: 0.7445\n",
      "Epoch 12/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6253 - accuracy: 0.7439\n",
      "Epoch 13/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6103 - accuracy: 0.7534\n",
      "Epoch 14/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.5979 - accuracy: 0.7595\n",
      "Epoch 15/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5910 - accuracy: 0.7626\n",
      "Epoch 16/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.6040 - accuracy: 0.7557\n",
      "Epoch 17/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.5779 - accuracy: 0.7675\n",
      "Epoch 18/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.5688 - accuracy: 0.7735\n",
      "Epoch 19/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.5601 - accuracy: 0.7747\n",
      "Epoch 20/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5596 - accuracy: 0.7741\n",
      "Epoch 21/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5461 - accuracy: 0.7826\n",
      "Epoch 22/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5442 - accuracy: 0.7827\n",
      "Epoch 23/44\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.5351 - accuracy: 0.7865\n",
      "Epoch 24/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5252 - accuracy: 0.7910\n",
      "Epoch 25/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.5139 - accuracy: 0.7949\n",
      "Epoch 26/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5016 - accuracy: 0.7997\n",
      "Epoch 27/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4969 - accuracy: 0.8045\n",
      "Epoch 28/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5008 - accuracy: 0.8019\n",
      "Epoch 29/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.5047 - accuracy: 0.7976\n",
      "Epoch 30/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.4899 - accuracy: 0.8039\n",
      "Epoch 31/44\n",
      "15000/15000 [==============================] - 0s 18us/step - loss: 0.4808 - accuracy: 0.8091\n",
      "Epoch 32/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.4726 - accuracy: 0.8155\n",
      "Epoch 33/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4765 - accuracy: 0.8117\n",
      "Epoch 34/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4601 - accuracy: 0.8209\n",
      "Epoch 35/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4764 - accuracy: 0.8131\n",
      "Epoch 36/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.4827 - accuracy: 0.8081\n",
      "Epoch 37/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4611 - accuracy: 0.8185\n",
      "Epoch 38/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4470 - accuracy: 0.8263\n",
      "Epoch 39/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4509 - accuracy: 0.8197\n",
      "Epoch 40/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4384 - accuracy: 0.8281\n",
      "Epoch 41/44\n",
      "15000/15000 [==============================] - 0s 18us/step - loss: 0.4370 - accuracy: 0.8276\n",
      "Epoch 42/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4304 - accuracy: 0.8295\n",
      "Epoch 43/44\n",
      "15000/15000 [==============================] - 0s 16us/step - loss: 0.4326 - accuracy: 0.8280\n",
      "Epoch 44/44\n",
      "15000/15000 [==============================] - 0s 17us/step - loss: 0.4320 - accuracy: 0.8299\n",
      "3000/3000 [==============================] - 0s 72us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5244605533281962, 0.7903333306312561]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "cifar_model = Sequential()\n",
    "cifar_model.add(Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "cifar_model.add(Dense(64, activation='relu'))\n",
    "cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "cifar_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cifar_history = cifar_model.fit(x_train, \n",
    "                                y_train,\n",
    "                                epochs=44,\n",
    "                                batch_size=512)\n",
    "\n",
    "cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized serach CV for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification model with given hyperperameters\n",
    "def build_model(learning_rate=1e-3, n_hidden=1, n_neurons=64, input_shape=3072):   \n",
    "    model = Sequential()\n",
    "    for layer in range(n_hidden):\n",
    "        if layer == 0:\n",
    "            model.add(Dense(n_neurons, activation='relu', input_shape=(input_shape,)))\n",
    "        else:\n",
    "            model.add(Dense(n_neurons, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras classifier\n",
    "keras_clf = KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 10244.5490 - accuracy: 0.3383 - val_loss: 6.2688 - val_accuracy: 0.3340\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 2.6647 - accuracy: 0.3311 - val_loss: 3.9739 - val_accuracy: 0.3437\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 1.1227 - accuracy: 0.3410 - val_loss: 1.6649 - val_accuracy: 0.3340\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 1.1253 - accuracy: 0.3405 - val_loss: 1.6898 - val_accuracy: 0.3340\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 1.1223 - accuracy: 0.3301 - val_loss: 1.6530 - val_accuracy: 0.3233\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.1099 - accuracy: 0.3315 - val_loss: 1.6527 - val_accuracy: 0.3430\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.1098 - accuracy: 0.3299 - val_loss: 1.6549 - val_accuracy: 0.3233\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 1.1182 - accuracy: 0.3251 - val_loss: 1.6548 - val_accuracy: 0.3430\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1064 - accuracy: 0.3433 - val_loss: 1.6630 - val_accuracy: 0.3340\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.1097 - accuracy: 0.3313 - val_loss: 1.6600 - val_accuracy: 0.3340\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1043 - accuracy: 0.3364 - val_loss: 1.6570 - val_accuracy: 0.3430\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 1.1050 - accuracy: 0.3306 - val_loss: 1.6780 - val_accuracy: 0.3340\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 1.1112 - accuracy: 0.3316 - val_loss: 1.6752 - val_accuracy: 0.3233\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 1.1044 - accuracy: 0.3325 - val_loss: 1.6582 - val_accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 1.1110 - accuracy: 0.3327 - val_loss: 1.6536 - val_accuracy: 0.3430\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 1.1069 - accuracy: 0.3281 - val_loss: 1.6644 - val_accuracy: 0.3430\n",
      "4000/4000 [==============================] - 0s 31us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 91us/step - loss: 18921.1137 - accuracy: 0.3371 - val_loss: 1.1773 - val_accuracy: 0.3340\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 27.0864 - accuracy: 0.3340 - val_loss: 1.0999 - val_accuracy: 0.3427\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 1.1041 - accuracy: 0.3339 - val_loss: 1.1030 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1045 - accuracy: 0.3228 - val_loss: 1.1120 - val_accuracy: 0.3233\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.1049 - accuracy: 0.3279 - val_loss: 1.1021 - val_accuracy: 0.3233\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 1.1031 - accuracy: 0.3296 - val_loss: 1.1121 - val_accuracy: 0.3233\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1017 - accuracy: 0.3316 - val_loss: 1.1043 - val_accuracy: 0.3233\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 1.1041 - accuracy: 0.3310 - val_loss: 1.0990 - val_accuracy: 0.3427\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 89us/step - loss: 1.1020 - accuracy: 0.3300 - val_loss: 1.1012 - val_accuracy: 0.3427\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 1.1074 - accuracy: 0.3307 - val_loss: 1.1020 - val_accuracy: 0.3340\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 1.1065 - accuracy: 0.3251 - val_loss: 1.1066 - val_accuracy: 0.3233\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1011 - accuracy: 0.3436 - val_loss: 1.0996 - val_accuracy: 0.3233\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 1.1021 - accuracy: 0.3343 - val_loss: 1.0993 - val_accuracy: 0.3233\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 1.1031 - accuracy: 0.3384 - val_loss: 1.1014 - val_accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 1.1050 - accuracy: 0.3325 - val_loss: 1.0993 - val_accuracy: 0.3427\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1031 - accuracy: 0.3347 - val_loss: 1.1061 - val_accuracy: 0.3340\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.1063 - accuracy: 0.3365 - val_loss: 1.1055 - val_accuracy: 0.3427\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 1.1059 - accuracy: 0.3381 - val_loss: 1.1134 - val_accuracy: 0.3340\n",
      "4000/4000 [==============================] - 0s 28us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 90us/step - loss: 10705.7316 - accuracy: 0.3491 - val_loss: 106.7527 - val_accuracy: 0.3337\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 20.0993 - accuracy: 0.3666 - val_loss: 2.0362 - val_accuracy: 0.3273\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 94.6620 - accuracy: 0.3811 - val_loss: 1.1358 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 1.1031 - accuracy: 0.3408 - val_loss: 1.0989 - val_accuracy: 0.3427\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.0990 - accuracy: 0.3358 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 1.0990 - accuracy: 0.3319 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 1.0991 - accuracy: 0.3345 - val_loss: 1.0991 - val_accuracy: 0.3340\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.0999 - accuracy: 0.3260 - val_loss: 1.1005 - val_accuracy: 0.3340\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0996 - accuracy: 0.3264 - val_loss: 1.0989 - val_accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 1.0992 - accuracy: 0.3383 - val_loss: 1.0991 - val_accuracy: 0.3233\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.0995 - accuracy: 0.3187 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 1.0992 - accuracy: 0.3347 - val_loss: 1.0984 - val_accuracy: 0.3340\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.0990 - accuracy: 0.3344 - val_loss: 1.0993 - val_accuracy: 0.3340\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 1.0996 - accuracy: 0.3235 - val_loss: 1.0995 - val_accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.0991 - accuracy: 0.3374 - val_loss: 1.0986 - val_accuracy: 0.3427\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 1.0993 - accuracy: 0.3293 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.0993 - accuracy: 0.3405 - val_loss: 1.0991 - val_accuracy: 0.3427\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.1002 - accuracy: 0.3330 - val_loss: 1.0986 - val_accuracy: 0.3427\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 1.0993 - accuracy: 0.3364 - val_loss: 1.0986 - val_accuracy: 0.3427\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 1.0995 - accuracy: 0.3324 - val_loss: 1.1002 - val_accuracy: 0.3233\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 78us/step - loss: 1.0995 - accuracy: 0.3296 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 78us/step - loss: 1.1004 - accuracy: 0.3256 - val_loss: 1.0993 - val_accuracy: 0.3427\n",
      "4000/4000 [==============================] - 0s 22us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.9381 - accuracy: 0.5683 - val_loss: 0.8370 - val_accuracy: 0.6433\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.8014 - accuracy: 0.6687 - val_loss: 0.7590 - val_accuracy: 0.6940\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.7536 - accuracy: 0.6944 - val_loss: 0.7195 - val_accuracy: 0.7120\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.7237 - accuracy: 0.7076 - val_loss: 0.6995 - val_accuracy: 0.7190\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.6988 - accuracy: 0.7258 - val_loss: 0.6924 - val_accuracy: 0.7197\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.6856 - accuracy: 0.7269 - val_loss: 0.6816 - val_accuracy: 0.7233\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6650 - accuracy: 0.7319 - val_loss: 0.6430 - val_accuracy: 0.7380\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6366 - accuracy: 0.7481 - val_loss: 0.6370 - val_accuracy: 0.7417\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6195 - accuracy: 0.7527 - val_loss: 0.6166 - val_accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.6099 - accuracy: 0.7607 - val_loss: 0.6288 - val_accuracy: 0.7377\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.6076 - accuracy: 0.7576 - val_loss: 0.5990 - val_accuracy: 0.7563\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.5725 - accuracy: 0.7782 - val_loss: 0.6187 - val_accuracy: 0.7437\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.5612 - accuracy: 0.7821 - val_loss: 0.5795 - val_accuracy: 0.7693\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5482 - accuracy: 0.7850 - val_loss: 0.5697 - val_accuracy: 0.7673\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5306 - accuracy: 0.7952 - val_loss: 0.5611 - val_accuracy: 0.7670\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5277 - accuracy: 0.7941 - val_loss: 0.5621 - val_accuracy: 0.7597\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.5150 - accuracy: 0.8016 - val_loss: 0.5571 - val_accuracy: 0.7687\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4972 - accuracy: 0.8084 - val_loss: 0.5476 - val_accuracy: 0.7657\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4856 - accuracy: 0.8125 - val_loss: 0.5409 - val_accuracy: 0.7753\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4810 - accuracy: 0.8169 - val_loss: 0.5358 - val_accuracy: 0.7810\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4763 - accuracy: 0.8167 - val_loss: 0.5554 - val_accuracy: 0.7693\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4788 - accuracy: 0.8117 - val_loss: 0.5522 - val_accuracy: 0.7790\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4513 - accuracy: 0.8267 - val_loss: 0.5329 - val_accuracy: 0.7840\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4468 - accuracy: 0.8288 - val_loss: 0.5738 - val_accuracy: 0.7713\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.4456 - accuracy: 0.8305 - val_loss: 0.5554 - val_accuracy: 0.7583\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.4360 - accuracy: 0.8301 - val_loss: 0.5384 - val_accuracy: 0.7683\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.4193 - accuracy: 0.8432 - val_loss: 0.5165 - val_accuracy: 0.7960\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4169 - accuracy: 0.8430 - val_loss: 0.5228 - val_accuracy: 0.7910\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.4034 - accuracy: 0.8522 - val_loss: 0.5268 - val_accuracy: 0.7863\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3943 - accuracy: 0.8524 - val_loss: 0.5320 - val_accuracy: 0.7863\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.3920 - accuracy: 0.8547 - val_loss: 0.5909 - val_accuracy: 0.7700\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.3887 - accuracy: 0.8543 - val_loss: 0.5144 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3755 - accuracy: 0.8585 - val_loss: 0.5208 - val_accuracy: 0.7877\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.3692 - accuracy: 0.8643 - val_loss: 0.5126 - val_accuracy: 0.7897\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3559 - accuracy: 0.8694 - val_loss: 0.5290 - val_accuracy: 0.7873\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3513 - accuracy: 0.8723 - val_loss: 0.5161 - val_accuracy: 0.7953\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3513 - accuracy: 0.8715 - val_loss: 0.4995 - val_accuracy: 0.7977\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3580 - accuracy: 0.8662 - val_loss: 0.5252 - val_accuracy: 0.7857\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3570 - accuracy: 0.8641 - val_loss: 0.4982 - val_accuracy: 0.8010\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3322 - accuracy: 0.8767 - val_loss: 0.5198 - val_accuracy: 0.7877\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3290 - accuracy: 0.8796 - val_loss: 0.4971 - val_accuracy: 0.7980\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3395 - accuracy: 0.8725 - val_loss: 0.4966 - val_accuracy: 0.8020\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3119 - accuracy: 0.8846 - val_loss: 0.5459 - val_accuracy: 0.7780\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3083 - accuracy: 0.8882 - val_loss: 0.5013 - val_accuracy: 0.7957\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2954 - accuracy: 0.8950 - val_loss: 0.5392 - val_accuracy: 0.7873\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3107 - accuracy: 0.8856 - val_loss: 0.5158 - val_accuracy: 0.7870\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2955 - accuracy: 0.8942 - val_loss: 0.5036 - val_accuracy: 0.8017\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.2940 - accuracy: 0.8947 - val_loss: 0.5376 - val_accuracy: 0.7873\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2866 - accuracy: 0.8967 - val_loss: 0.5124 - val_accuracy: 0.7897\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2750 - accuracy: 0.9022 - val_loss: 0.5123 - val_accuracy: 0.7903\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.2667 - accuracy: 0.9078 - val_loss: 0.5159 - val_accuracy: 0.7967\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.2729 - accuracy: 0.8990 - val_loss: 0.5972 - val_accuracy: 0.7607\n",
      "4000/4000 [==============================] - 0s 17us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.9334 - accuracy: 0.5724 - val_loss: 0.8289 - val_accuracy: 0.6550\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 38us/step - loss: 0.8112 - accuracy: 0.6578 - val_loss: 0.7613 - val_accuracy: 0.6900\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.7595 - accuracy: 0.6914 - val_loss: 0.7257 - val_accuracy: 0.7037\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.7357 - accuracy: 0.7001 - val_loss: 0.7134 - val_accuracy: 0.7017\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.7028 - accuracy: 0.7221 - val_loss: 0.6822 - val_accuracy: 0.7210\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6748 - accuracy: 0.7361 - val_loss: 0.6747 - val_accuracy: 0.7253\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6612 - accuracy: 0.7402 - val_loss: 0.6486 - val_accuracy: 0.7357\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6343 - accuracy: 0.7531 - val_loss: 0.6406 - val_accuracy: 0.7360\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.6146 - accuracy: 0.7607 - val_loss: 0.6245 - val_accuracy: 0.7387\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.5988 - accuracy: 0.7650 - val_loss: 0.6163 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6004 - accuracy: 0.7630 - val_loss: 0.6017 - val_accuracy: 0.7503\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5707 - accuracy: 0.7771 - val_loss: 0.5885 - val_accuracy: 0.7550\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5538 - accuracy: 0.7875 - val_loss: 0.5809 - val_accuracy: 0.7587\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5399 - accuracy: 0.7914 - val_loss: 0.6126 - val_accuracy: 0.7437\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5379 - accuracy: 0.7933 - val_loss: 0.5736 - val_accuracy: 0.7593\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5266 - accuracy: 0.7970 - val_loss: 0.5816 - val_accuracy: 0.7620\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5151 - accuracy: 0.8000 - val_loss: 0.5832 - val_accuracy: 0.7607\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.5091 - accuracy: 0.8054 - val_loss: 0.5990 - val_accuracy: 0.7583\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4951 - accuracy: 0.8080 - val_loss: 0.5640 - val_accuracy: 0.7657\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4769 - accuracy: 0.8196 - val_loss: 0.5555 - val_accuracy: 0.7733\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4831 - accuracy: 0.8126 - val_loss: 0.5440 - val_accuracy: 0.7700\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4636 - accuracy: 0.8209 - val_loss: 0.5523 - val_accuracy: 0.7743\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4495 - accuracy: 0.8267 - val_loss: 0.5335 - val_accuracy: 0.7843\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4458 - accuracy: 0.8264 - val_loss: 0.5593 - val_accuracy: 0.7700\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4410 - accuracy: 0.8314 - val_loss: 0.5563 - val_accuracy: 0.7740\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4351 - accuracy: 0.8326 - val_loss: 0.5411 - val_accuracy: 0.7803\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4219 - accuracy: 0.8396 - val_loss: 0.5296 - val_accuracy: 0.7867\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4090 - accuracy: 0.8466 - val_loss: 0.5292 - val_accuracy: 0.7857\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - accuracy: 0.8436 - val_loss: 0.5175 - val_accuracy: 0.7930\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3958 - accuracy: 0.8526 - val_loss: 0.5460 - val_accuracy: 0.7787\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3875 - accuracy: 0.8539 - val_loss: 0.5125 - val_accuracy: 0.7917\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3756 - accuracy: 0.8589 - val_loss: 0.5223 - val_accuracy: 0.7907\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3723 - accuracy: 0.8561 - val_loss: 0.5155 - val_accuracy: 0.7940\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3733 - accuracy: 0.8606 - val_loss: 0.5318 - val_accuracy: 0.7827\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3762 - accuracy: 0.8581 - val_loss: 0.5341 - val_accuracy: 0.7810\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3540 - accuracy: 0.8719 - val_loss: 0.5057 - val_accuracy: 0.7937\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3501 - accuracy: 0.8714 - val_loss: 0.5486 - val_accuracy: 0.7787\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3652 - accuracy: 0.8611 - val_loss: 0.5406 - val_accuracy: 0.7880\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.3372 - accuracy: 0.8750 - val_loss: 0.5132 - val_accuracy: 0.7950\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3294 - accuracy: 0.8765 - val_loss: 0.5127 - val_accuracy: 0.7957\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3210 - accuracy: 0.8809 - val_loss: 0.5057 - val_accuracy: 0.7950\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3244 - accuracy: 0.8788 - val_loss: 0.5162 - val_accuracy: 0.7933\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3042 - accuracy: 0.8913 - val_loss: 0.5124 - val_accuracy: 0.8013\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.2987 - accuracy: 0.8886 - val_loss: 0.5135 - val_accuracy: 0.7923\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3014 - accuracy: 0.8942 - val_loss: 0.5247 - val_accuracy: 0.7927\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2917 - accuracy: 0.8945 - val_loss: 0.5233 - val_accuracy: 0.7960\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2906 - accuracy: 0.8956 - val_loss: 0.5082 - val_accuracy: 0.7977\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.2797 - accuracy: 0.9016 - val_loss: 0.5264 - val_accuracy: 0.7980\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2692 - accuracy: 0.9060 - val_loss: 0.5383 - val_accuracy: 0.7823\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.2939 - accuracy: 0.8869 - val_loss: 0.5722 - val_accuracy: 0.7850\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2771 - accuracy: 0.8971 - val_loss: 0.5116 - val_accuracy: 0.8010\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 46us/step - loss: 0.9301 - accuracy: 0.5764 - val_loss: 0.8186 - val_accuracy: 0.6533\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.7830 - accuracy: 0.6844 - val_loss: 0.7468 - val_accuracy: 0.7047\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.7447 - accuracy: 0.6966 - val_loss: 0.7167 - val_accuracy: 0.7050\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.7060 - accuracy: 0.7160 - val_loss: 0.6879 - val_accuracy: 0.7280\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6834 - accuracy: 0.7303 - val_loss: 0.6833 - val_accuracy: 0.7107\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6626 - accuracy: 0.7355 - val_loss: 0.6581 - val_accuracy: 0.7257\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6413 - accuracy: 0.7420 - val_loss: 0.6493 - val_accuracy: 0.7373\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6321 - accuracy: 0.7454 - val_loss: 0.6408 - val_accuracy: 0.7320\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6037 - accuracy: 0.7610 - val_loss: 0.6197 - val_accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5885 - accuracy: 0.7675 - val_loss: 0.6245 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5920 - accuracy: 0.7604 - val_loss: 0.6089 - val_accuracy: 0.7457\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5557 - accuracy: 0.7801 - val_loss: 0.5866 - val_accuracy: 0.7647\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5658 - accuracy: 0.7760 - val_loss: 0.6011 - val_accuracy: 0.7547\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5382 - accuracy: 0.7911 - val_loss: 0.5858 - val_accuracy: 0.7607\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5269 - accuracy: 0.7950 - val_loss: 0.5715 - val_accuracy: 0.7637\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.5102 - accuracy: 0.8029 - val_loss: 0.5830 - val_accuracy: 0.7570\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.5157 - accuracy: 0.7951 - val_loss: 0.6013 - val_accuracy: 0.7447\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4974 - accuracy: 0.8050 - val_loss: 0.5560 - val_accuracy: 0.7683\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.4928 - accuracy: 0.8079 - val_loss: 0.5580 - val_accuracy: 0.7680\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4845 - accuracy: 0.8099 - val_loss: 0.5726 - val_accuracy: 0.7673\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 30us/step - loss: 0.4786 - accuracy: 0.8099 - val_loss: 0.5759 - val_accuracy: 0.7603\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4663 - accuracy: 0.8166 - val_loss: 0.5644 - val_accuracy: 0.7693\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4543 - accuracy: 0.8234 - val_loss: 0.5438 - val_accuracy: 0.7750\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4444 - accuracy: 0.8314 - val_loss: 0.5561 - val_accuracy: 0.7717\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4421 - accuracy: 0.8260 - val_loss: 0.5790 - val_accuracy: 0.7577\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4404 - accuracy: 0.8257 - val_loss: 0.5495 - val_accuracy: 0.7710\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4214 - accuracy: 0.8371 - val_loss: 0.5322 - val_accuracy: 0.7817\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4200 - accuracy: 0.8394 - val_loss: 0.5476 - val_accuracy: 0.7820\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4094 - accuracy: 0.8409 - val_loss: 0.5862 - val_accuracy: 0.7630\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4065 - accuracy: 0.8404 - val_loss: 0.5365 - val_accuracy: 0.7790\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4017 - accuracy: 0.8436 - val_loss: 0.5286 - val_accuracy: 0.7847\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3970 - accuracy: 0.8460 - val_loss: 0.5223 - val_accuracy: 0.7880\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.3819 - accuracy: 0.8510 - val_loss: 0.5365 - val_accuracy: 0.7823\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.3729 - accuracy: 0.8579 - val_loss: 0.5272 - val_accuracy: 0.7877\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3698 - accuracy: 0.8560 - val_loss: 0.5262 - val_accuracy: 0.7917\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3663 - accuracy: 0.8605 - val_loss: 0.5299 - val_accuracy: 0.7863\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.3536 - accuracy: 0.8636 - val_loss: 0.5240 - val_accuracy: 0.7877\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 45us/step - loss: 0.3512 - accuracy: 0.8661 - val_loss: 0.5301 - val_accuracy: 0.7883\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3456 - accuracy: 0.8690 - val_loss: 0.5185 - val_accuracy: 0.7983\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3415 - accuracy: 0.8695 - val_loss: 0.5204 - val_accuracy: 0.7910\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3379 - accuracy: 0.8686 - val_loss: 0.5363 - val_accuracy: 0.7813\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3275 - accuracy: 0.8760 - val_loss: 0.5344 - val_accuracy: 0.7870\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3317 - accuracy: 0.8748 - val_loss: 0.5142 - val_accuracy: 0.8003\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3231 - accuracy: 0.8780 - val_loss: 0.5171 - val_accuracy: 0.7957\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3070 - accuracy: 0.8876 - val_loss: 0.5257 - val_accuracy: 0.7967\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3146 - accuracy: 0.8805 - val_loss: 0.5333 - val_accuracy: 0.7910\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3041 - accuracy: 0.8870 - val_loss: 0.5360 - val_accuracy: 0.7903\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2882 - accuracy: 0.8964 - val_loss: 0.5183 - val_accuracy: 0.7990\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2884 - accuracy: 0.8944 - val_loss: 0.5332 - val_accuracy: 0.7897\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 29us/step - loss: 0.2832 - accuracy: 0.8950 - val_loss: 0.5156 - val_accuracy: 0.7993\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2729 - accuracy: 0.9029 - val_loss: 0.5209 - val_accuracy: 0.7970\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2785 - accuracy: 0.8947 - val_loss: 0.5237 - val_accuracy: 0.7960\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2796 - accuracy: 0.8959 - val_loss: 0.5313 - val_accuracy: 0.7927\n",
      "4000/4000 [==============================] - 0s 35us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.9888 - accuracy: 0.5468 - val_loss: 0.8520 - val_accuracy: 0.6640\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.8083 - accuracy: 0.6643 - val_loss: 0.7371 - val_accuracy: 0.6990\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.7471 - accuracy: 0.6896 - val_loss: 0.7151 - val_accuracy: 0.7060\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.7039 - accuracy: 0.7074 - val_loss: 0.6803 - val_accuracy: 0.7173\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6866 - accuracy: 0.7201 - val_loss: 0.6552 - val_accuracy: 0.7320\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6477 - accuracy: 0.7410 - val_loss: 0.6584 - val_accuracy: 0.7197\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6228 - accuracy: 0.7481 - val_loss: 0.6145 - val_accuracy: 0.7473\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6021 - accuracy: 0.7584 - val_loss: 0.6168 - val_accuracy: 0.7390\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5778 - accuracy: 0.7721 - val_loss: 0.6207 - val_accuracy: 0.7453\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5631 - accuracy: 0.7725 - val_loss: 0.5696 - val_accuracy: 0.7597\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5477 - accuracy: 0.7776 - val_loss: 0.5890 - val_accuracy: 0.7520\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5213 - accuracy: 0.7931 - val_loss: 0.5856 - val_accuracy: 0.7553\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4966 - accuracy: 0.8026 - val_loss: 0.5410 - val_accuracy: 0.7730\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4769 - accuracy: 0.8104 - val_loss: 0.5751 - val_accuracy: 0.7620\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4797 - accuracy: 0.8116 - val_loss: 0.5510 - val_accuracy: 0.7677\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4593 - accuracy: 0.8211 - val_loss: 0.5261 - val_accuracy: 0.7840\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4345 - accuracy: 0.8292 - val_loss: 0.5491 - val_accuracy: 0.7690\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4325 - accuracy: 0.8324 - val_loss: 0.5184 - val_accuracy: 0.7870\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4052 - accuracy: 0.8435 - val_loss: 0.5138 - val_accuracy: 0.7843\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4000 - accuracy: 0.8478 - val_loss: 0.5436 - val_accuracy: 0.7757\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3845 - accuracy: 0.8489 - val_loss: 0.5317 - val_accuracy: 0.7833\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3592 - accuracy: 0.8627 - val_loss: 0.5177 - val_accuracy: 0.7907\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3466 - accuracy: 0.8681 - val_loss: 0.5610 - val_accuracy: 0.7717\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3400 - accuracy: 0.8745 - val_loss: 0.5101 - val_accuracy: 0.7923\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3434 - accuracy: 0.8658 - val_loss: 0.5433 - val_accuracy: 0.7810\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3428 - accuracy: 0.8704 - val_loss: 0.5164 - val_accuracy: 0.7973\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3098 - accuracy: 0.8832 - val_loss: 0.6000 - val_accuracy: 0.7673\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2950 - accuracy: 0.8926 - val_loss: 0.5222 - val_accuracy: 0.7983\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2732 - accuracy: 0.8995 - val_loss: 0.5151 - val_accuracy: 0.7993\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2646 - accuracy: 0.9010 - val_loss: 0.5611 - val_accuracy: 0.7820\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2800 - accuracy: 0.8949 - val_loss: 0.5292 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2576 - accuracy: 0.9041 - val_loss: 0.5592 - val_accuracy: 0.7903\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2609 - accuracy: 0.9041 - val_loss: 0.5483 - val_accuracy: 0.7940\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2576 - accuracy: 0.9009 - val_loss: 0.5308 - val_accuracy: 0.7970\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.9493 - accuracy: 0.5709 - val_loss: 0.8040 - val_accuracy: 0.6730\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.7808 - accuracy: 0.6729 - val_loss: 0.7344 - val_accuracy: 0.6933\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.7212 - accuracy: 0.7021 - val_loss: 0.6878 - val_accuracy: 0.7170\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6890 - accuracy: 0.7214 - val_loss: 0.6803 - val_accuracy: 0.7177\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6490 - accuracy: 0.7456 - val_loss: 0.6365 - val_accuracy: 0.7420\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6312 - accuracy: 0.7477 - val_loss: 0.6619 - val_accuracy: 0.7230\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6211 - accuracy: 0.7454 - val_loss: 0.6424 - val_accuracy: 0.7387\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6023 - accuracy: 0.7601 - val_loss: 0.6109 - val_accuracy: 0.7520\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5657 - accuracy: 0.7784 - val_loss: 0.5835 - val_accuracy: 0.7607\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5621 - accuracy: 0.7765 - val_loss: 0.5750 - val_accuracy: 0.7680\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5298 - accuracy: 0.7925 - val_loss: 0.5698 - val_accuracy: 0.7600\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.5076 - accuracy: 0.8029 - val_loss: 0.5515 - val_accuracy: 0.7750\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4978 - accuracy: 0.8062 - val_loss: 0.5481 - val_accuracy: 0.7780\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4884 - accuracy: 0.8051 - val_loss: 0.6109 - val_accuracy: 0.7460\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4751 - accuracy: 0.8127 - val_loss: 0.5472 - val_accuracy: 0.7753\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4479 - accuracy: 0.8280 - val_loss: 0.5457 - val_accuracy: 0.7810\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4373 - accuracy: 0.8261 - val_loss: 0.5364 - val_accuracy: 0.7880\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4230 - accuracy: 0.8388 - val_loss: 0.5469 - val_accuracy: 0.7780\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4022 - accuracy: 0.8462 - val_loss: 0.5298 - val_accuracy: 0.7853\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3993 - accuracy: 0.8459 - val_loss: 0.5973 - val_accuracy: 0.7620\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4092 - accuracy: 0.8445 - val_loss: 0.5491 - val_accuracy: 0.7797\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3767 - accuracy: 0.8586 - val_loss: 0.5220 - val_accuracy: 0.7953\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3432 - accuracy: 0.8724 - val_loss: 0.5480 - val_accuracy: 0.7837\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3554 - accuracy: 0.8609 - val_loss: 0.5445 - val_accuracy: 0.7887\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3495 - accuracy: 0.8646 - val_loss: 0.5379 - val_accuracy: 0.7863\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3521 - accuracy: 0.8608 - val_loss: 0.5932 - val_accuracy: 0.7693\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3852 - accuracy: 0.8450 - val_loss: 0.5650 - val_accuracy: 0.7677\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3315 - accuracy: 0.8708 - val_loss: 0.5593 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2939 - accuracy: 0.8896 - val_loss: 0.5749 - val_accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2828 - accuracy: 0.8967 - val_loss: 0.5512 - val_accuracy: 0.7933\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2889 - accuracy: 0.8889 - val_loss: 0.5414 - val_accuracy: 0.7897\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2651 - accuracy: 0.9040 - val_loss: 0.5277 - val_accuracy: 0.8067\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.9587 - accuracy: 0.5639 - val_loss: 0.8273 - val_accuracy: 0.6427\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.7723 - accuracy: 0.6861 - val_loss: 0.7317 - val_accuracy: 0.6900\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.7155 - accuracy: 0.7081 - val_loss: 0.7440 - val_accuracy: 0.6827\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.7032 - accuracy: 0.7117 - val_loss: 0.6610 - val_accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.6594 - accuracy: 0.7286 - val_loss: 0.6473 - val_accuracy: 0.7363\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6371 - accuracy: 0.7436 - val_loss: 0.6288 - val_accuracy: 0.7383\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.6060 - accuracy: 0.7548 - val_loss: 0.6330 - val_accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5905 - accuracy: 0.7594 - val_loss: 0.6156 - val_accuracy: 0.7427\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5737 - accuracy: 0.7650 - val_loss: 0.6059 - val_accuracy: 0.7453\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5558 - accuracy: 0.7757 - val_loss: 0.5887 - val_accuracy: 0.7510\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5409 - accuracy: 0.7835 - val_loss: 0.5622 - val_accuracy: 0.7757\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.5097 - accuracy: 0.7966 - val_loss: 0.5883 - val_accuracy: 0.7537\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4943 - accuracy: 0.8052 - val_loss: 0.5361 - val_accuracy: 0.7837\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4760 - accuracy: 0.8101 - val_loss: 0.5667 - val_accuracy: 0.7740\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4754 - accuracy: 0.8109 - val_loss: 0.5416 - val_accuracy: 0.7817\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4792 - accuracy: 0.8056 - val_loss: 0.5264 - val_accuracy: 0.7940\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.4427 - accuracy: 0.8249 - val_loss: 0.5333 - val_accuracy: 0.7803\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4280 - accuracy: 0.8306 - val_loss: 0.5364 - val_accuracy: 0.7787\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4071 - accuracy: 0.8396 - val_loss: 0.5184 - val_accuracy: 0.7847\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3914 - accuracy: 0.8487 - val_loss: 0.5340 - val_accuracy: 0.7817\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3822 - accuracy: 0.8496 - val_loss: 0.5184 - val_accuracy: 0.7917\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3782 - accuracy: 0.8566 - val_loss: 0.5273 - val_accuracy: 0.7873\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3613 - accuracy: 0.8615 - val_loss: 0.5421 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3529 - accuracy: 0.8641 - val_loss: 0.5176 - val_accuracy: 0.7997\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3423 - accuracy: 0.8699 - val_loss: 0.5038 - val_accuracy: 0.7980\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3468 - accuracy: 0.8676 - val_loss: 0.4943 - val_accuracy: 0.8030\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.3362 - accuracy: 0.8686 - val_loss: 0.5281 - val_accuracy: 0.7900\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3193 - accuracy: 0.8771 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3100 - accuracy: 0.8851 - val_loss: 0.5319 - val_accuracy: 0.7897\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2925 - accuracy: 0.8891 - val_loss: 0.5100 - val_accuracy: 0.8040\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.3023 - accuracy: 0.8816 - val_loss: 0.5219 - val_accuracy: 0.7987\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2775 - accuracy: 0.8949 - val_loss: 0.5561 - val_accuracy: 0.7793\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2612 - accuracy: 0.9006 - val_loss: 0.5212 - val_accuracy: 0.7990\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2347 - accuracy: 0.9103 - val_loss: 0.5461 - val_accuracy: 0.7963\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 31us/step - loss: 0.2333 - accuracy: 0.9125 - val_loss: 0.5846 - val_accuracy: 0.7880\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2351 - accuracy: 0.9130 - val_loss: 0.5369 - val_accuracy: 0.7943\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 1.0682 - accuracy: 0.5221 - val_loss: 0.7779 - val_accuracy: 0.6753\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.7999 - accuracy: 0.6562 - val_loss: 0.7328 - val_accuracy: 0.6937\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.7180 - accuracy: 0.7029 - val_loss: 0.6800 - val_accuracy: 0.7210\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.6730 - accuracy: 0.7219 - val_loss: 0.6563 - val_accuracy: 0.7300\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.6594 - accuracy: 0.7290 - val_loss: 0.6504 - val_accuracy: 0.7297\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.6380 - accuracy: 0.7370 - val_loss: 0.6150 - val_accuracy: 0.7463\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.6101 - accuracy: 0.7533 - val_loss: 0.7613 - val_accuracy: 0.6837\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5989 - accuracy: 0.7542 - val_loss: 0.6151 - val_accuracy: 0.7493\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.5933 - accuracy: 0.7541 - val_loss: 0.6888 - val_accuracy: 0.7047\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5949 - accuracy: 0.7588 - val_loss: 0.6497 - val_accuracy: 0.7417\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.5909 - accuracy: 0.7601 - val_loss: 0.6526 - val_accuracy: 0.7367\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5664 - accuracy: 0.7724 - val_loss: 0.7031 - val_accuracy: 0.7253\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5393 - accuracy: 0.7811 - val_loss: 0.6304 - val_accuracy: 0.7407\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.5029 - accuracy: 0.8015 - val_loss: 0.6252 - val_accuracy: 0.7383\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4982 - accuracy: 0.8027 - val_loss: 0.5671 - val_accuracy: 0.7657\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4784 - accuracy: 0.8061 - val_loss: 0.5731 - val_accuracy: 0.7707\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4828 - accuracy: 0.8050 - val_loss: 0.5742 - val_accuracy: 0.7687\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4510 - accuracy: 0.8231 - val_loss: 0.6650 - val_accuracy: 0.7453\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.5025 - accuracy: 0.7924 - val_loss: 0.5858 - val_accuracy: 0.7630\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.4247 - accuracy: 0.8294 - val_loss: 0.5774 - val_accuracy: 0.7800\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4345 - accuracy: 0.8245 - val_loss: 0.5656 - val_accuracy: 0.7780\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3932 - accuracy: 0.8439 - val_loss: 0.6013 - val_accuracy: 0.7623\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.4101 - accuracy: 0.8355 - val_loss: 0.6219 - val_accuracy: 0.7563\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3989 - accuracy: 0.8421 - val_loss: 0.6040 - val_accuracy: 0.7757\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.3926 - accuracy: 0.8418 - val_loss: 0.5962 - val_accuracy: 0.7770\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3956 - accuracy: 0.8416 - val_loss: 0.6012 - val_accuracy: 0.7787\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3629 - accuracy: 0.8549 - val_loss: 0.5812 - val_accuracy: 0.7800\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3309 - accuracy: 0.8670 - val_loss: 0.6048 - val_accuracy: 0.7683\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3485 - accuracy: 0.8609 - val_loss: 0.6338 - val_accuracy: 0.7720\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3253 - accuracy: 0.8724 - val_loss: 0.6625 - val_accuracy: 0.7600\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3399 - accuracy: 0.8643 - val_loss: 0.6497 - val_accuracy: 0.7717\n",
      "4000/4000 [==============================] - 0s 20us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 1.0619 - accuracy: 0.5316 - val_loss: 0.8460 - val_accuracy: 0.6417\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.7869 - accuracy: 0.6593 - val_loss: 0.7123 - val_accuracy: 0.7157\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.7263 - accuracy: 0.6945 - val_loss: 0.6631 - val_accuracy: 0.7297\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.6979 - accuracy: 0.7132 - val_loss: 0.6975 - val_accuracy: 0.6953\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.6638 - accuracy: 0.7270 - val_loss: 0.6294 - val_accuracy: 0.7437\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.6265 - accuracy: 0.7445 - val_loss: 0.6474 - val_accuracy: 0.7240\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.6229 - accuracy: 0.7455 - val_loss: 0.5992 - val_accuracy: 0.7597\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5781 - accuracy: 0.7669 - val_loss: 0.5842 - val_accuracy: 0.7627\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5717 - accuracy: 0.7653 - val_loss: 0.5944 - val_accuracy: 0.7547\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.5535 - accuracy: 0.7706 - val_loss: 0.6144 - val_accuracy: 0.7477\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.5361 - accuracy: 0.7826 - val_loss: 0.5959 - val_accuracy: 0.7573\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.5273 - accuracy: 0.7872 - val_loss: 0.5946 - val_accuracy: 0.7753\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4998 - accuracy: 0.7947 - val_loss: 0.5826 - val_accuracy: 0.7677\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4892 - accuracy: 0.8018 - val_loss: 0.5755 - val_accuracy: 0.7697\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4821 - accuracy: 0.8033 - val_loss: 0.5629 - val_accuracy: 0.7740\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4502 - accuracy: 0.8170 - val_loss: 0.5766 - val_accuracy: 0.7783\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.4743 - accuracy: 0.8046 - val_loss: 0.5657 - val_accuracy: 0.7840\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4239 - accuracy: 0.8289 - val_loss: 0.6047 - val_accuracy: 0.7770\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.4181 - accuracy: 0.8275 - val_loss: 0.6211 - val_accuracy: 0.7637\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4086 - accuracy: 0.8350 - val_loss: 0.6291 - val_accuracy: 0.7473\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.4091 - accuracy: 0.8319 - val_loss: 0.5541 - val_accuracy: 0.7917\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3862 - accuracy: 0.8431 - val_loss: 0.5923 - val_accuracy: 0.7917\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3861 - accuracy: 0.8411 - val_loss: 0.6107 - val_accuracy: 0.7830\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3657 - accuracy: 0.8497 - val_loss: 0.5759 - val_accuracy: 0.7903\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3436 - accuracy: 0.8609 - val_loss: 0.5981 - val_accuracy: 0.7810\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.3621 - accuracy: 0.8524 - val_loss: 0.6364 - val_accuracy: 0.7623\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 0.3224 - accuracy: 0.8715 - val_loss: 0.6688 - val_accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3588 - accuracy: 0.8546 - val_loss: 0.6046 - val_accuracy: 0.7863\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3092 - accuracy: 0.8745 - val_loss: 0.6671 - val_accuracy: 0.7830\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3116 - accuracy: 0.8710 - val_loss: 0.6457 - val_accuracy: 0.7793\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3030 - accuracy: 0.8785 - val_loss: 0.6571 - val_accuracy: 0.7763\n",
      "4000/4000 [==============================] - 0s 22us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 1.0819 - accuracy: 0.5197 - val_loss: 0.8193 - val_accuracy: 0.6543\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.7812 - accuracy: 0.6668 - val_loss: 0.7526 - val_accuracy: 0.6873\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.7174 - accuracy: 0.7056 - val_loss: 0.6716 - val_accuracy: 0.7240\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.6782 - accuracy: 0.7175 - val_loss: 0.8922 - val_accuracy: 0.5977\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.6648 - accuracy: 0.7261 - val_loss: 0.6424 - val_accuracy: 0.7340\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.6347 - accuracy: 0.7312 - val_loss: 0.6440 - val_accuracy: 0.7323\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.5986 - accuracy: 0.7526 - val_loss: 0.6430 - val_accuracy: 0.7307\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.5967 - accuracy: 0.7525 - val_loss: 0.6609 - val_accuracy: 0.7187\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.5853 - accuracy: 0.7595 - val_loss: 0.6523 - val_accuracy: 0.7310\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.5549 - accuracy: 0.7744 - val_loss: 0.6368 - val_accuracy: 0.7257\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.5219 - accuracy: 0.7906 - val_loss: 0.7313 - val_accuracy: 0.7173\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.5392 - accuracy: 0.7820 - val_loss: 0.6104 - val_accuracy: 0.7507\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.5164 - accuracy: 0.7872 - val_loss: 0.6174 - val_accuracy: 0.7423\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4994 - accuracy: 0.7958 - val_loss: 0.5780 - val_accuracy: 0.7687\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4867 - accuracy: 0.8048 - val_loss: 0.6043 - val_accuracy: 0.7600\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 0.4662 - accuracy: 0.8177 - val_loss: 0.5916 - val_accuracy: 0.7563\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4706 - accuracy: 0.8070 - val_loss: 0.5872 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.4332 - accuracy: 0.8249 - val_loss: 0.5854 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4509 - accuracy: 0.8199 - val_loss: 0.6508 - val_accuracy: 0.7570\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4341 - accuracy: 0.8234 - val_loss: 0.5669 - val_accuracy: 0.7743\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4154 - accuracy: 0.8326 - val_loss: 0.6231 - val_accuracy: 0.7707\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.4006 - accuracy: 0.8379 - val_loss: 0.5904 - val_accuracy: 0.7643\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3985 - accuracy: 0.8371 - val_loss: 0.6249 - val_accuracy: 0.7600\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3809 - accuracy: 0.8440 - val_loss: 0.5784 - val_accuracy: 0.7773\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3603 - accuracy: 0.8575 - val_loss: 0.6358 - val_accuracy: 0.7570\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3515 - accuracy: 0.8602 - val_loss: 0.6389 - val_accuracy: 0.7803\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3483 - accuracy: 0.8560 - val_loss: 0.6585 - val_accuracy: 0.7620\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3324 - accuracy: 0.8662 - val_loss: 0.6625 - val_accuracy: 0.7743\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3275 - accuracy: 0.8655 - val_loss: 0.6545 - val_accuracy: 0.7597\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3208 - accuracy: 0.8679 - val_loss: 0.6653 - val_accuracy: 0.7743\n",
      "4000/4000 [==============================] - 0s 21us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 1.9241 - accuracy: 0.3671 - val_loss: 1.1321 - val_accuracy: 0.4690\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.9761 - accuracy: 0.5360 - val_loss: 0.9347 - val_accuracy: 0.5883\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.8384 - accuracy: 0.6391 - val_loss: 0.8117 - val_accuracy: 0.6473\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.7822 - accuracy: 0.6701 - val_loss: 0.7580 - val_accuracy: 0.6710\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.7387 - accuracy: 0.6980 - val_loss: 0.6946 - val_accuracy: 0.7157\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.7306 - accuracy: 0.7001 - val_loss: 0.7406 - val_accuracy: 0.6840\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.7255 - accuracy: 0.6980 - val_loss: 0.7601 - val_accuracy: 0.6637\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6982 - accuracy: 0.7091 - val_loss: 0.7061 - val_accuracy: 0.7017\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.6642 - accuracy: 0.7245 - val_loss: 0.7006 - val_accuracy: 0.7030\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.6461 - accuracy: 0.7351 - val_loss: 0.6477 - val_accuracy: 0.7310\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.6468 - accuracy: 0.7322 - val_loss: 0.6494 - val_accuracy: 0.7357\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6076 - accuracy: 0.7534 - val_loss: 0.6642 - val_accuracy: 0.7320\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5816 - accuracy: 0.7648 - val_loss: 0.6029 - val_accuracy: 0.7507\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5613 - accuracy: 0.7722 - val_loss: 0.6196 - val_accuracy: 0.7383\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.5727 - accuracy: 0.7623 - val_loss: 0.6286 - val_accuracy: 0.7413\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.5500 - accuracy: 0.7756 - val_loss: 0.5959 - val_accuracy: 0.7540\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5411 - accuracy: 0.7785 - val_loss: 0.5728 - val_accuracy: 0.7763\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5238 - accuracy: 0.7866 - val_loss: 0.5624 - val_accuracy: 0.7757\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4822 - accuracy: 0.8056 - val_loss: 0.6186 - val_accuracy: 0.7567\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4873 - accuracy: 0.8073 - val_loss: 0.5931 - val_accuracy: 0.7497\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4768 - accuracy: 0.8084 - val_loss: 0.5491 - val_accuracy: 0.7837\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4557 - accuracy: 0.8194 - val_loss: 0.5532 - val_accuracy: 0.7763\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4431 - accuracy: 0.8234 - val_loss: 0.5717 - val_accuracy: 0.7683\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4260 - accuracy: 0.8321 - val_loss: 0.5721 - val_accuracy: 0.7717\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4638 - accuracy: 0.8100 - val_loss: 0.7502 - val_accuracy: 0.6997\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4752 - accuracy: 0.8094 - val_loss: 0.5916 - val_accuracy: 0.7670\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4301 - accuracy: 0.8238 - val_loss: 0.6506 - val_accuracy: 0.7323\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4438 - accuracy: 0.8210 - val_loss: 0.5869 - val_accuracy: 0.7607\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4145 - accuracy: 0.8340 - val_loss: 0.5859 - val_accuracy: 0.7743\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3709 - accuracy: 0.8494 - val_loss: 0.5840 - val_accuracy: 0.7790\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3574 - accuracy: 0.8566 - val_loss: 0.5888 - val_accuracy: 0.7723\n",
      "4000/4000 [==============================] - 0s 16us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 1.8380 - accuracy: 0.3405 - val_loss: 1.1000 - val_accuracy: 0.3473\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 1.0514 - accuracy: 0.4619 - val_loss: 0.9475 - val_accuracy: 0.5633\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.8997 - accuracy: 0.5913 - val_loss: 0.8146 - val_accuracy: 0.6447\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.8032 - accuracy: 0.6611 - val_loss: 0.7704 - val_accuracy: 0.6707\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.7637 - accuracy: 0.6837 - val_loss: 0.7415 - val_accuracy: 0.6893\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.7347 - accuracy: 0.6977 - val_loss: 0.7074 - val_accuracy: 0.7037\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.7151 - accuracy: 0.7051 - val_loss: 0.7452 - val_accuracy: 0.6877\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.7058 - accuracy: 0.7113 - val_loss: 0.6715 - val_accuracy: 0.7217\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.6723 - accuracy: 0.7236 - val_loss: 0.7009 - val_accuracy: 0.7033\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.6474 - accuracy: 0.7374 - val_loss: 0.6802 - val_accuracy: 0.7173\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.6391 - accuracy: 0.7380 - val_loss: 0.6450 - val_accuracy: 0.7370\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.6259 - accuracy: 0.7466 - val_loss: 0.6691 - val_accuracy: 0.7260\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.6190 - accuracy: 0.7508 - val_loss: 0.6706 - val_accuracy: 0.7267\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5731 - accuracy: 0.7709 - val_loss: 0.6528 - val_accuracy: 0.7360\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5574 - accuracy: 0.7731 - val_loss: 0.5935 - val_accuracy: 0.7653\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5704 - accuracy: 0.7696 - val_loss: 0.6130 - val_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5388 - accuracy: 0.7822 - val_loss: 0.6272 - val_accuracy: 0.7447\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5054 - accuracy: 0.7965 - val_loss: 0.5664 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.5133 - accuracy: 0.7934 - val_loss: 0.5968 - val_accuracy: 0.7677\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4995 - accuracy: 0.7999 - val_loss: 0.6251 - val_accuracy: 0.7470\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5041 - accuracy: 0.7918 - val_loss: 0.6486 - val_accuracy: 0.7300\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4996 - accuracy: 0.7993 - val_loss: 0.5993 - val_accuracy: 0.7587\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4933 - accuracy: 0.8014 - val_loss: 0.5844 - val_accuracy: 0.7650\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4736 - accuracy: 0.8064 - val_loss: 0.5856 - val_accuracy: 0.7680\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4568 - accuracy: 0.8136 - val_loss: 0.5837 - val_accuracy: 0.7807\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4429 - accuracy: 0.8230 - val_loss: 0.5941 - val_accuracy: 0.7743\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4270 - accuracy: 0.8281 - val_loss: 0.6464 - val_accuracy: 0.7727\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4159 - accuracy: 0.8294 - val_loss: 0.5906 - val_accuracy: 0.7740\n",
      "4000/4000 [==============================] - 0s 16us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 1.7246 - accuracy: 0.3536 - val_loss: 1.0716 - val_accuracy: 0.3503\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 1.0230 - accuracy: 0.4715 - val_loss: 0.9186 - val_accuracy: 0.5897\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.8697 - accuracy: 0.6115 - val_loss: 0.7921 - val_accuracy: 0.6620\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.7856 - accuracy: 0.6679 - val_loss: 0.7397 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.7413 - accuracy: 0.6890 - val_loss: 0.7313 - val_accuracy: 0.6923\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.7412 - accuracy: 0.6877 - val_loss: 0.7213 - val_accuracy: 0.7053\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6957 - accuracy: 0.7094 - val_loss: 0.6661 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6709 - accuracy: 0.7235 - val_loss: 0.6593 - val_accuracy: 0.7220\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6456 - accuracy: 0.7330 - val_loss: 0.6489 - val_accuracy: 0.7380\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6237 - accuracy: 0.7456 - val_loss: 0.6893 - val_accuracy: 0.7073\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.6494 - accuracy: 0.7321 - val_loss: 0.6204 - val_accuracy: 0.7457\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.6059 - accuracy: 0.7504 - val_loss: 0.6123 - val_accuracy: 0.7503\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5813 - accuracy: 0.7673 - val_loss: 0.6167 - val_accuracy: 0.7443\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.5695 - accuracy: 0.7665 - val_loss: 0.5893 - val_accuracy: 0.7560\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5652 - accuracy: 0.7695 - val_loss: 0.6434 - val_accuracy: 0.7363\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.5966 - accuracy: 0.7539 - val_loss: 0.6148 - val_accuracy: 0.7523\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.5382 - accuracy: 0.7800 - val_loss: 0.6426 - val_accuracy: 0.7297\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.5239 - accuracy: 0.7821 - val_loss: 0.5829 - val_accuracy: 0.7580\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.5078 - accuracy: 0.7926 - val_loss: 0.5647 - val_accuracy: 0.7763\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.5285 - accuracy: 0.7839 - val_loss: 0.6148 - val_accuracy: 0.7543\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4962 - accuracy: 0.7985 - val_loss: 0.5755 - val_accuracy: 0.7687\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4742 - accuracy: 0.8123 - val_loss: 0.5636 - val_accuracy: 0.7757\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4604 - accuracy: 0.8136 - val_loss: 0.5730 - val_accuracy: 0.7700\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4604 - accuracy: 0.8165 - val_loss: 0.6272 - val_accuracy: 0.7453\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4875 - accuracy: 0.8010 - val_loss: 0.5734 - val_accuracy: 0.7717\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4617 - accuracy: 0.8154 - val_loss: 0.5500 - val_accuracy: 0.7767\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4296 - accuracy: 0.8267 - val_loss: 0.6002 - val_accuracy: 0.7577\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4062 - accuracy: 0.8366 - val_loss: 0.6560 - val_accuracy: 0.7577\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4354 - accuracy: 0.8231 - val_loss: 0.6895 - val_accuracy: 0.7363\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4169 - accuracy: 0.8322 - val_loss: 0.6020 - val_accuracy: 0.7723\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.4125 - accuracy: 0.8330 - val_loss: 0.6699 - val_accuracy: 0.7387\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4133 - accuracy: 0.8325 - val_loss: 0.5850 - val_accuracy: 0.7793\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.3782 - accuracy: 0.8471 - val_loss: 0.6974 - val_accuracy: 0.7637\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4282 - accuracy: 0.8261 - val_loss: 0.6127 - val_accuracy: 0.7747\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3611 - accuracy: 0.8529 - val_loss: 0.5823 - val_accuracy: 0.7877\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 0.3525 - accuracy: 0.8587 - val_loss: 0.6256 - val_accuracy: 0.7613\n",
      "4000/4000 [==============================] - 0s 18us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 24356.8841 - accuracy: 0.3406 - val_loss: 28.4525 - val_accuracy: 0.3227\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 9.1725 - accuracy: 0.3251 - val_loss: 2.4160 - val_accuracy: 0.3233\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1044 - accuracy: 0.3302 - val_loss: 2.5479 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1003 - accuracy: 0.3321 - val_loss: 2.5822 - val_accuracy: 0.3233\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1018 - accuracy: 0.3326 - val_loss: 2.5851 - val_accuracy: 0.3430\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1003 - accuracy: 0.3252 - val_loss: 2.5879 - val_accuracy: 0.3233\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1010 - accuracy: 0.3270 - val_loss: 2.5865 - val_accuracy: 0.3340\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1011 - accuracy: 0.3347 - val_loss: 2.5899 - val_accuracy: 0.3233\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1009 - accuracy: 0.3372 - val_loss: 2.5939 - val_accuracy: 0.3430\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1020 - accuracy: 0.3350 - val_loss: 2.5980 - val_accuracy: 0.3430\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1062 - accuracy: 0.3332 - val_loss: 2.5872 - val_accuracy: 0.3430\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1006 - accuracy: 0.3271 - val_loss: 2.5870 - val_accuracy: 0.3430\n",
      "4000/4000 [==============================] - 0s 13us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 13560.6790 - accuracy: 0.3339 - val_loss: 232.6362 - val_accuracy: 0.3427\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 26.0772 - accuracy: 0.3339 - val_loss: 1.3666 - val_accuracy: 0.3233\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1037 - accuracy: 0.3467 - val_loss: 1.3905 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.0998 - accuracy: 0.3341 - val_loss: 1.3957 - val_accuracy: 0.3430\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 1.1021 - accuracy: 0.3351 - val_loss: 1.3980 - val_accuracy: 0.3430\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1053 - accuracy: 0.3389 - val_loss: 1.4008 - val_accuracy: 0.3233\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.0993 - accuracy: 0.3413 - val_loss: 1.4028 - val_accuracy: 0.3430\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1053 - accuracy: 0.3330 - val_loss: 1.3982 - val_accuracy: 0.3233\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1011 - accuracy: 0.3281 - val_loss: 1.4002 - val_accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1018 - accuracy: 0.3389 - val_loss: 1.4010 - val_accuracy: 0.3430\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1022 - accuracy: 0.3320 - val_loss: 1.4105 - val_accuracy: 0.3340\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.1037 - accuracy: 0.3334 - val_loss: 1.4027 - val_accuracy: 0.3430\n",
      "4000/4000 [==============================] - 0s 13us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 54us/step - loss: 20012.2577 - accuracy: 0.3307 - val_loss: 209.5493 - val_accuracy: 0.3317\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 142.9282 - accuracy: 0.3339 - val_loss: 35.7688 - val_accuracy: 0.3427\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 22.5326 - accuracy: 0.3458 - val_loss: 11.1678 - val_accuracy: 0.3523\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 6.7892 - accuracy: 0.4355 - val_loss: 6.2651 - val_accuracy: 0.4067\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 3.0344 - accuracy: 0.5014 - val_loss: 2.5259 - val_accuracy: 0.5300\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 1.3715 - accuracy: 0.5689 - val_loss: 1.6722 - val_accuracy: 0.5860\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.9664 - accuracy: 0.5830 - val_loss: 1.4328 - val_accuracy: 0.6567\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 44us/step - loss: 0.8244 - accuracy: 0.6500 - val_loss: 1.4023 - val_accuracy: 0.6593\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 43us/step - loss: 0.8174 - accuracy: 0.6439 - val_loss: 1.4801 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.7988 - accuracy: 0.6633 - val_loss: 1.4486 - val_accuracy: 0.6503\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.8179 - accuracy: 0.6465 - val_loss: 1.5556 - val_accuracy: 0.5980\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.8091 - accuracy: 0.6594 - val_loss: 1.3847 - val_accuracy: 0.6723\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7634 - accuracy: 0.6839 - val_loss: 1.3612 - val_accuracy: 0.6880\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.7444 - accuracy: 0.6902 - val_loss: 1.3442 - val_accuracy: 0.6897\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.7629 - accuracy: 0.6773 - val_loss: 1.3838 - val_accuracy: 0.6713\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 49us/step - loss: 0.7340 - accuracy: 0.6961 - val_loss: 1.4040 - val_accuracy: 0.6610\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7959 - accuracy: 0.6620 - val_loss: 1.3457 - val_accuracy: 0.6933\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7644 - accuracy: 0.6851 - val_loss: 1.3471 - val_accuracy: 0.6923\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.8172 - accuracy: 0.6551 - val_loss: 1.6721 - val_accuracy: 0.5280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.8244 - accuracy: 0.6494 - val_loss: 1.4391 - val_accuracy: 0.6147\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7511 - accuracy: 0.6846 - val_loss: 1.3669 - val_accuracy: 0.6607\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7365 - accuracy: 0.6951 - val_loss: 1.3304 - val_accuracy: 0.6877\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 39us/step - loss: 0.7549 - accuracy: 0.6861 - val_loss: 1.3711 - val_accuracy: 0.6823\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7601 - accuracy: 0.6829 - val_loss: 1.3559 - val_accuracy: 0.6823\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7257 - accuracy: 0.7030 - val_loss: 1.3121 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7332 - accuracy: 0.6974 - val_loss: 1.3644 - val_accuracy: 0.6610\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7241 - accuracy: 0.7056 - val_loss: 1.4296 - val_accuracy: 0.6690\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7569 - accuracy: 0.6844 - val_loss: 1.4042 - val_accuracy: 0.6687\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7285 - accuracy: 0.6990 - val_loss: 1.3022 - val_accuracy: 0.6940\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7026 - accuracy: 0.7121 - val_loss: 1.2957 - val_accuracy: 0.6987\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7072 - accuracy: 0.7025 - val_loss: 1.3028 - val_accuracy: 0.7043\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.7065 - accuracy: 0.7080 - val_loss: 1.3235 - val_accuracy: 0.7020\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.8234 - accuracy: 0.6660 - val_loss: 1.4761 - val_accuracy: 0.6593\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7736 - accuracy: 0.6876 - val_loss: 1.3547 - val_accuracy: 0.6820\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7114 - accuracy: 0.7060 - val_loss: 1.3022 - val_accuracy: 0.7013\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.6990 - accuracy: 0.7110 - val_loss: 1.3350 - val_accuracy: 0.6710\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7349 - accuracy: 0.6908 - val_loss: 1.5125 - val_accuracy: 0.6037\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7628 - accuracy: 0.6784 - val_loss: 1.3096 - val_accuracy: 0.7053\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7297 - accuracy: 0.6901 - val_loss: 1.4993 - val_accuracy: 0.5860\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.7446 - accuracy: 0.6889 - val_loss: 1.3848 - val_accuracy: 0.6330\n",
      "4000/4000 [==============================] - 0s 14us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 51us/step - loss: 0.9197 - accuracy: 0.5905 - val_loss: 0.7985 - val_accuracy: 0.6753\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.7829 - accuracy: 0.6736 - val_loss: 0.7382 - val_accuracy: 0.6950\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.7359 - accuracy: 0.6961 - val_loss: 0.7057 - val_accuracy: 0.7090\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.7159 - accuracy: 0.7015 - val_loss: 0.6796 - val_accuracy: 0.7177\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6780 - accuracy: 0.7256 - val_loss: 0.6694 - val_accuracy: 0.7210\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6536 - accuracy: 0.7345 - val_loss: 0.6378 - val_accuracy: 0.7313\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.6268 - accuracy: 0.7499 - val_loss: 0.6304 - val_accuracy: 0.7323\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6224 - accuracy: 0.7523 - val_loss: 0.6092 - val_accuracy: 0.7440\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5852 - accuracy: 0.7665 - val_loss: 0.6128 - val_accuracy: 0.7370\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5805 - accuracy: 0.7678 - val_loss: 0.6012 - val_accuracy: 0.7527\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5710 - accuracy: 0.7703 - val_loss: 0.5747 - val_accuracy: 0.7597\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5405 - accuracy: 0.7861 - val_loss: 0.5628 - val_accuracy: 0.7653\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5255 - accuracy: 0.7901 - val_loss: 0.5963 - val_accuracy: 0.7523\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5156 - accuracy: 0.7969 - val_loss: 0.5551 - val_accuracy: 0.7690\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4992 - accuracy: 0.8026 - val_loss: 0.5538 - val_accuracy: 0.7770\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4862 - accuracy: 0.8123 - val_loss: 0.5397 - val_accuracy: 0.7787\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4774 - accuracy: 0.8156 - val_loss: 0.5473 - val_accuracy: 0.7743\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 42us/step - loss: 0.4663 - accuracy: 0.8185 - val_loss: 0.5817 - val_accuracy: 0.7517\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4770 - accuracy: 0.8090 - val_loss: 0.5277 - val_accuracy: 0.7850\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.4406 - accuracy: 0.8282 - val_loss: 0.5407 - val_accuracy: 0.7767\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4540 - accuracy: 0.8240 - val_loss: 0.5645 - val_accuracy: 0.7670\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4369 - accuracy: 0.8266 - val_loss: 0.5191 - val_accuracy: 0.7890\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4178 - accuracy: 0.8379 - val_loss: 0.5217 - val_accuracy: 0.7913\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4158 - accuracy: 0.8382 - val_loss: 0.5312 - val_accuracy: 0.7823\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3941 - accuracy: 0.8460 - val_loss: 0.5592 - val_accuracy: 0.7757\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3906 - accuracy: 0.8516 - val_loss: 0.5506 - val_accuracy: 0.7777\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3902 - accuracy: 0.8478 - val_loss: 0.5219 - val_accuracy: 0.7887\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3617 - accuracy: 0.8597 - val_loss: 0.5179 - val_accuracy: 0.7867\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3582 - accuracy: 0.8641 - val_loss: 0.5223 - val_accuracy: 0.7870\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3590 - accuracy: 0.8621 - val_loss: 0.5174 - val_accuracy: 0.7900\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3518 - accuracy: 0.8636 - val_loss: 0.5110 - val_accuracy: 0.7943\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3314 - accuracy: 0.8734 - val_loss: 0.5453 - val_accuracy: 0.7757\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3333 - accuracy: 0.8712 - val_loss: 0.5254 - val_accuracy: 0.7973\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3370 - accuracy: 0.8706 - val_loss: 0.5302 - val_accuracy: 0.7930\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3276 - accuracy: 0.8770 - val_loss: 0.5353 - val_accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3121 - accuracy: 0.8795 - val_loss: 0.5019 - val_accuracy: 0.8047\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.2850 - accuracy: 0.8949 - val_loss: 0.5196 - val_accuracy: 0.7987\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3037 - accuracy: 0.8814 - val_loss: 0.5119 - val_accuracy: 0.7987\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2929 - accuracy: 0.8861 - val_loss: 0.5208 - val_accuracy: 0.7903\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2873 - accuracy: 0.8915 - val_loss: 0.5461 - val_accuracy: 0.7897\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2660 - accuracy: 0.8976 - val_loss: 0.5229 - val_accuracy: 0.7977\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2681 - accuracy: 0.9003 - val_loss: 0.5303 - val_accuracy: 0.7930\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.2454 - accuracy: 0.9136 - val_loss: 0.5545 - val_accuracy: 0.7840\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 37us/step - loss: 0.2520 - accuracy: 0.9076 - val_loss: 0.5241 - val_accuracy: 0.7950\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.2398 - accuracy: 0.9128 - val_loss: 0.5690 - val_accuracy: 0.7913\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2312 - accuracy: 0.9195 - val_loss: 0.5673 - val_accuracy: 0.7920\n",
      "4000/4000 [==============================] - 0s 14us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 50us/step - loss: 0.9185 - accuracy: 0.5962 - val_loss: 0.8050 - val_accuracy: 0.6600\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.7728 - accuracy: 0.6848 - val_loss: 0.7665 - val_accuracy: 0.6770\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.7305 - accuracy: 0.7025 - val_loss: 0.6981 - val_accuracy: 0.7207\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.7057 - accuracy: 0.7154 - val_loss: 0.6850 - val_accuracy: 0.7173\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6814 - accuracy: 0.7271 - val_loss: 0.6587 - val_accuracy: 0.7373\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6584 - accuracy: 0.7341 - val_loss: 0.6527 - val_accuracy: 0.7320\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.6330 - accuracy: 0.7456 - val_loss: 0.6241 - val_accuracy: 0.7437\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.6101 - accuracy: 0.7588 - val_loss: 0.6156 - val_accuracy: 0.7483\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5941 - accuracy: 0.7696 - val_loss: 0.5983 - val_accuracy: 0.7523\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 36us/step - loss: 0.5770 - accuracy: 0.7701 - val_loss: 0.5935 - val_accuracy: 0.7577\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.5569 - accuracy: 0.7822 - val_loss: 0.5997 - val_accuracy: 0.7497\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5429 - accuracy: 0.7874 - val_loss: 0.6011 - val_accuracy: 0.7480\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5436 - accuracy: 0.7860 - val_loss: 0.5811 - val_accuracy: 0.7607\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.5124 - accuracy: 0.8010 - val_loss: 0.5593 - val_accuracy: 0.7703\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.5056 - accuracy: 0.8005 - val_loss: 0.5605 - val_accuracy: 0.7747\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4827 - accuracy: 0.8139 - val_loss: 0.5604 - val_accuracy: 0.7663\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4720 - accuracy: 0.8179 - val_loss: 0.5653 - val_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4640 - accuracy: 0.8180 - val_loss: 0.5578 - val_accuracy: 0.7700\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.4535 - accuracy: 0.8242 - val_loss: 0.5676 - val_accuracy: 0.7593\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4372 - accuracy: 0.8349 - val_loss: 0.5727 - val_accuracy: 0.7677\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4360 - accuracy: 0.8270 - val_loss: 0.5921 - val_accuracy: 0.7560\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4144 - accuracy: 0.8389 - val_loss: 0.5478 - val_accuracy: 0.7807\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4112 - accuracy: 0.8397 - val_loss: 0.5518 - val_accuracy: 0.7750\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4044 - accuracy: 0.8451 - val_loss: 0.5458 - val_accuracy: 0.7827\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3955 - accuracy: 0.8479 - val_loss: 0.5465 - val_accuracy: 0.7807\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3793 - accuracy: 0.8550 - val_loss: 0.5115 - val_accuracy: 0.7960\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3580 - accuracy: 0.8676 - val_loss: 0.5174 - val_accuracy: 0.7907\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3581 - accuracy: 0.8652 - val_loss: 0.5173 - val_accuracy: 0.7947\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3527 - accuracy: 0.8666 - val_loss: 0.5125 - val_accuracy: 0.7997\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3410 - accuracy: 0.8673 - val_loss: 0.5583 - val_accuracy: 0.7780\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3370 - accuracy: 0.8684 - val_loss: 0.5355 - val_accuracy: 0.7847\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3354 - accuracy: 0.8717 - val_loss: 0.5847 - val_accuracy: 0.7683\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3161 - accuracy: 0.8844 - val_loss: 0.5280 - val_accuracy: 0.7930\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3069 - accuracy: 0.8849 - val_loss: 0.5129 - val_accuracy: 0.8003\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2953 - accuracy: 0.8900 - val_loss: 0.5785 - val_accuracy: 0.7773\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3224 - accuracy: 0.8756 - val_loss: 0.5402 - val_accuracy: 0.7927\n",
      "4000/4000 [==============================] - 0s 13us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.9288 - accuracy: 0.5918 - val_loss: 0.8163 - val_accuracy: 0.6630\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.7793 - accuracy: 0.6766 - val_loss: 0.7373 - val_accuracy: 0.6943\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.7226 - accuracy: 0.7096 - val_loss: 0.6979 - val_accuracy: 0.7053\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.6885 - accuracy: 0.7278 - val_loss: 0.6739 - val_accuracy: 0.7197\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6637 - accuracy: 0.7341 - val_loss: 0.6647 - val_accuracy: 0.7163\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.6389 - accuracy: 0.7415 - val_loss: 0.6656 - val_accuracy: 0.7263\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.6293 - accuracy: 0.7415 - val_loss: 0.6393 - val_accuracy: 0.7360\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5952 - accuracy: 0.7596 - val_loss: 0.6120 - val_accuracy: 0.7467\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5849 - accuracy: 0.7641 - val_loss: 0.5966 - val_accuracy: 0.7593\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5562 - accuracy: 0.7786 - val_loss: 0.5998 - val_accuracy: 0.7483\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5609 - accuracy: 0.7759 - val_loss: 0.5945 - val_accuracy: 0.7560\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.5388 - accuracy: 0.7878 - val_loss: 0.5935 - val_accuracy: 0.7550\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5236 - accuracy: 0.7941 - val_loss: 0.6062 - val_accuracy: 0.7450\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.5147 - accuracy: 0.7940 - val_loss: 0.5554 - val_accuracy: 0.7720\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.5022 - accuracy: 0.7977 - val_loss: 0.5873 - val_accuracy: 0.7563\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4889 - accuracy: 0.8090 - val_loss: 0.5464 - val_accuracy: 0.7693\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4778 - accuracy: 0.8127 - val_loss: 0.5866 - val_accuracy: 0.7497\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.4818 - accuracy: 0.8049 - val_loss: 0.5407 - val_accuracy: 0.7737\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4603 - accuracy: 0.8181 - val_loss: 0.5541 - val_accuracy: 0.7737\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4632 - accuracy: 0.8141 - val_loss: 0.5869 - val_accuracy: 0.7573\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4485 - accuracy: 0.8232 - val_loss: 0.5923 - val_accuracy: 0.7587\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4300 - accuracy: 0.8353 - val_loss: 0.5538 - val_accuracy: 0.7757\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.4361 - accuracy: 0.8288 - val_loss: 0.5229 - val_accuracy: 0.7857\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.4122 - accuracy: 0.8366 - val_loss: 0.5228 - val_accuracy: 0.7847\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3962 - accuracy: 0.8494 - val_loss: 0.5268 - val_accuracy: 0.7893\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3890 - accuracy: 0.8508 - val_loss: 0.5147 - val_accuracy: 0.7843\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3817 - accuracy: 0.8530 - val_loss: 0.5304 - val_accuracy: 0.7827\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3682 - accuracy: 0.8619 - val_loss: 0.5259 - val_accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3630 - accuracy: 0.8583 - val_loss: 0.5288 - val_accuracy: 0.7803\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3505 - accuracy: 0.8654 - val_loss: 0.5147 - val_accuracy: 0.8013\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3407 - accuracy: 0.8710 - val_loss: 0.5393 - val_accuracy: 0.7883\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3438 - accuracy: 0.8686 - val_loss: 0.5469 - val_accuracy: 0.7750\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.3383 - accuracy: 0.8691 - val_loss: 0.5140 - val_accuracy: 0.7937\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3216 - accuracy: 0.8806 - val_loss: 0.5256 - val_accuracy: 0.7937\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.3237 - accuracy: 0.8765 - val_loss: 0.5407 - val_accuracy: 0.7817\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3318 - accuracy: 0.8710 - val_loss: 0.5486 - val_accuracy: 0.7867\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.3103 - accuracy: 0.8814 - val_loss: 0.5332 - val_accuracy: 0.7927\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 35us/step - loss: 0.2945 - accuracy: 0.8881 - val_loss: 0.5215 - val_accuracy: 0.7957\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.2859 - accuracy: 0.8950 - val_loss: 0.5203 - val_accuracy: 0.8017\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.2874 - accuracy: 0.8949 - val_loss: 0.5859 - val_accuracy: 0.7803\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 34us/step - loss: 0.2736 - accuracy: 0.9013 - val_loss: 0.5236 - val_accuracy: 0.8020\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 33us/step - loss: 0.2724 - accuracy: 0.8997 - val_loss: 0.5288 - val_accuracy: 0.7987\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 32us/step - loss: 0.2548 - accuracy: 0.9060 - val_loss: 0.5507 - val_accuracy: 0.7930\n",
      "4000/4000 [==============================] - 0s 15us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.9452 - accuracy: 0.5660 - val_loss: 0.8191 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7945 - accuracy: 0.6779 - val_loss: 0.7512 - val_accuracy: 0.6990\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7492 - accuracy: 0.6990 - val_loss: 0.7232 - val_accuracy: 0.6983\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.7181 - accuracy: 0.7155 - val_loss: 0.7184 - val_accuracy: 0.7097\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.7027 - accuracy: 0.7092 - val_loss: 0.6754 - val_accuracy: 0.7243\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6671 - accuracy: 0.7411 - val_loss: 0.6621 - val_accuracy: 0.7317\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6480 - accuracy: 0.7446 - val_loss: 0.6402 - val_accuracy: 0.7410\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6318 - accuracy: 0.7495 - val_loss: 0.6301 - val_accuracy: 0.7470\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6100 - accuracy: 0.7604 - val_loss: 0.6130 - val_accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5991 - accuracy: 0.7615 - val_loss: 0.6029 - val_accuracy: 0.7563\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5778 - accuracy: 0.7779 - val_loss: 0.6022 - val_accuracy: 0.7523\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5625 - accuracy: 0.7846 - val_loss: 0.5996 - val_accuracy: 0.7560\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5560 - accuracy: 0.7814 - val_loss: 0.6031 - val_accuracy: 0.7553\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5408 - accuracy: 0.7904 - val_loss: 0.5912 - val_accuracy: 0.7577\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5312 - accuracy: 0.7960 - val_loss: 0.5671 - val_accuracy: 0.7730\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5119 - accuracy: 0.8073 - val_loss: 0.5871 - val_accuracy: 0.7560\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5092 - accuracy: 0.8051 - val_loss: 0.5519 - val_accuracy: 0.7813\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4949 - accuracy: 0.8115 - val_loss: 0.5536 - val_accuracy: 0.7707\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4867 - accuracy: 0.8120 - val_loss: 0.5460 - val_accuracy: 0.7703\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4776 - accuracy: 0.8164 - val_loss: 0.5340 - val_accuracy: 0.7767\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4606 - accuracy: 0.8270 - val_loss: 0.5433 - val_accuracy: 0.7747\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4534 - accuracy: 0.8310 - val_loss: 0.5419 - val_accuracy: 0.7767\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4530 - accuracy: 0.8239 - val_loss: 0.5401 - val_accuracy: 0.7757\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4376 - accuracy: 0.8359 - val_loss: 0.5196 - val_accuracy: 0.7900\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4372 - accuracy: 0.8346 - val_loss: 0.5390 - val_accuracy: 0.7793\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4288 - accuracy: 0.8363 - val_loss: 0.5312 - val_accuracy: 0.7853\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4129 - accuracy: 0.8459 - val_loss: 0.5212 - val_accuracy: 0.7853\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4014 - accuracy: 0.8515 - val_loss: 0.5212 - val_accuracy: 0.7860\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4001 - accuracy: 0.8495 - val_loss: 0.5082 - val_accuracy: 0.7963\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3907 - accuracy: 0.8518 - val_loss: 0.5062 - val_accuracy: 0.7913\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3766 - accuracy: 0.8614 - val_loss: 0.5077 - val_accuracy: 0.7990\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3756 - accuracy: 0.8593 - val_loss: 0.5348 - val_accuracy: 0.7827\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3817 - accuracy: 0.8550 - val_loss: 0.5519 - val_accuracy: 0.7767\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3659 - accuracy: 0.8626 - val_loss: 0.5304 - val_accuracy: 0.7863\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3569 - accuracy: 0.8668 - val_loss: 0.5180 - val_accuracy: 0.7923\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3501 - accuracy: 0.8711 - val_loss: 0.5007 - val_accuracy: 0.8003\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3395 - accuracy: 0.8769 - val_loss: 0.4973 - val_accuracy: 0.8023\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3405 - accuracy: 0.8749 - val_loss: 0.4951 - val_accuracy: 0.8003\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3215 - accuracy: 0.8827 - val_loss: 0.5346 - val_accuracy: 0.7820\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3188 - accuracy: 0.8861 - val_loss: 0.4997 - val_accuracy: 0.8037\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3072 - accuracy: 0.8905 - val_loss: 0.4951 - val_accuracy: 0.8057\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 0.3084 - accuracy: 0.8882 - val_loss: 0.5407 - val_accuracy: 0.7797\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3359 - accuracy: 0.8727 - val_loss: 0.5377 - val_accuracy: 0.7810\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3213 - accuracy: 0.8795 - val_loss: 0.5087 - val_accuracy: 0.7953\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2936 - accuracy: 0.8970 - val_loss: 0.5012 - val_accuracy: 0.8017\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 0.2810 - accuracy: 0.9005 - val_loss: 0.4978 - val_accuracy: 0.7977\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2782 - accuracy: 0.9006 - val_loss: 0.5015 - val_accuracy: 0.7993\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2728 - accuracy: 0.9076 - val_loss: 0.5020 - val_accuracy: 0.8043\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2708 - accuracy: 0.9045 - val_loss: 0.5224 - val_accuracy: 0.7993\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2708 - accuracy: 0.9019 - val_loss: 0.5209 - val_accuracy: 0.7977\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2532 - accuracy: 0.9143 - val_loss: 0.5154 - val_accuracy: 0.7983\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 41us/step - loss: 0.9717 - accuracy: 0.5461 - val_loss: 0.8482 - val_accuracy: 0.6650\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.8125 - accuracy: 0.6685 - val_loss: 0.7702 - val_accuracy: 0.6863\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7498 - accuracy: 0.7036 - val_loss: 0.7190 - val_accuracy: 0.7100\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7131 - accuracy: 0.7182 - val_loss: 0.7038 - val_accuracy: 0.7153\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6947 - accuracy: 0.7264 - val_loss: 0.6778 - val_accuracy: 0.7260\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6682 - accuracy: 0.7370 - val_loss: 0.6738 - val_accuracy: 0.7297\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6572 - accuracy: 0.7400 - val_loss: 0.6495 - val_accuracy: 0.7313\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6273 - accuracy: 0.7598 - val_loss: 0.6420 - val_accuracy: 0.7410\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 25us/step - loss: 0.6124 - accuracy: 0.7630 - val_loss: 0.6256 - val_accuracy: 0.7410\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6032 - accuracy: 0.7632 - val_loss: 0.6191 - val_accuracy: 0.7553\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5855 - accuracy: 0.7732 - val_loss: 0.6160 - val_accuracy: 0.7437\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5805 - accuracy: 0.7729 - val_loss: 0.5979 - val_accuracy: 0.7563\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 0.5566 - accuracy: 0.7879 - val_loss: 0.5828 - val_accuracy: 0.7567\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 0.5420 - accuracy: 0.7947 - val_loss: 0.5737 - val_accuracy: 0.7687\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5286 - accuracy: 0.7976 - val_loss: 0.5694 - val_accuracy: 0.7733\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5148 - accuracy: 0.8076 - val_loss: 0.5616 - val_accuracy: 0.7787\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5100 - accuracy: 0.8025 - val_loss: 0.5700 - val_accuracy: 0.7687\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4961 - accuracy: 0.8138 - val_loss: 0.5580 - val_accuracy: 0.7760\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4858 - accuracy: 0.8151 - val_loss: 0.5422 - val_accuracy: 0.7813\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4740 - accuracy: 0.8202 - val_loss: 0.5629 - val_accuracy: 0.7727\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4703 - accuracy: 0.8232 - val_loss: 0.5332 - val_accuracy: 0.7883\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4474 - accuracy: 0.8331 - val_loss: 0.5556 - val_accuracy: 0.7647\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4542 - accuracy: 0.8257 - val_loss: 0.5803 - val_accuracy: 0.7580\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4489 - accuracy: 0.8304 - val_loss: 0.5265 - val_accuracy: 0.7847\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4242 - accuracy: 0.8393 - val_loss: 0.5236 - val_accuracy: 0.7890\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4226 - accuracy: 0.8406 - val_loss: 0.5697 - val_accuracy: 0.7713\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4160 - accuracy: 0.8424 - val_loss: 0.5387 - val_accuracy: 0.7863\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4109 - accuracy: 0.8476 - val_loss: 0.5435 - val_accuracy: 0.7823\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3958 - accuracy: 0.8530 - val_loss: 0.5295 - val_accuracy: 0.7890\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3901 - accuracy: 0.8531 - val_loss: 0.5181 - val_accuracy: 0.7960\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3818 - accuracy: 0.8561 - val_loss: 0.5463 - val_accuracy: 0.7827\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3782 - accuracy: 0.8597 - val_loss: 0.5298 - val_accuracy: 0.7917\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3714 - accuracy: 0.8615 - val_loss: 0.5144 - val_accuracy: 0.7907\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3541 - accuracy: 0.8731 - val_loss: 0.5651 - val_accuracy: 0.7760\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3591 - accuracy: 0.8698 - val_loss: 0.5484 - val_accuracy: 0.7800\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3650 - accuracy: 0.8608 - val_loss: 0.5374 - val_accuracy: 0.7787\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3442 - accuracy: 0.8769 - val_loss: 0.5138 - val_accuracy: 0.7990\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3355 - accuracy: 0.8794 - val_loss: 0.5123 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3222 - accuracy: 0.8870 - val_loss: 0.5107 - val_accuracy: 0.7937\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 28us/step - loss: 0.3130 - accuracy: 0.8928 - val_loss: 0.5003 - val_accuracy: 0.8060\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3152 - accuracy: 0.8880 - val_loss: 0.5145 - val_accuracy: 0.7897\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3095 - accuracy: 0.8903 - val_loss: 0.5151 - val_accuracy: 0.8013\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2988 - accuracy: 0.8919 - val_loss: 0.5156 - val_accuracy: 0.8007\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2870 - accuracy: 0.9006 - val_loss: 0.4964 - val_accuracy: 0.8147\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2777 - accuracy: 0.9069 - val_loss: 0.4946 - val_accuracy: 0.8127\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2771 - accuracy: 0.9043 - val_loss: 0.5107 - val_accuracy: 0.8003\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2909 - accuracy: 0.8982 - val_loss: 0.5092 - val_accuracy: 0.8030\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2709 - accuracy: 0.9066 - val_loss: 0.5234 - val_accuracy: 0.8030\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2742 - accuracy: 0.9040 - val_loss: 0.5122 - val_accuracy: 0.8063\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2808 - accuracy: 0.8992 - val_loss: 0.5064 - val_accuracy: 0.8070\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2680 - accuracy: 0.9070 - val_loss: 0.5085 - val_accuracy: 0.8013\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2451 - accuracy: 0.9168 - val_loss: 0.5256 - val_accuracy: 0.7940\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.2446 - accuracy: 0.9200 - val_loss: 0.5117 - val_accuracy: 0.8020\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2327 - accuracy: 0.9262 - val_loss: 0.5245 - val_accuracy: 0.7967\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2413 - accuracy: 0.9166 - val_loss: 0.5269 - val_accuracy: 0.8047\n",
      "4000/4000 [==============================] - 0s 12us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 0s 40us/step - loss: 0.9819 - accuracy: 0.5175 - val_loss: 0.8474 - val_accuracy: 0.6657\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.8106 - accuracy: 0.6750 - val_loss: 0.7610 - val_accuracy: 0.6930\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7633 - accuracy: 0.6909 - val_loss: 0.7338 - val_accuracy: 0.7063\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.7184 - accuracy: 0.7141 - val_loss: 0.7100 - val_accuracy: 0.7087\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6922 - accuracy: 0.7249 - val_loss: 0.6765 - val_accuracy: 0.7217\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6680 - accuracy: 0.7351 - val_loss: 0.6581 - val_accuracy: 0.7313\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6533 - accuracy: 0.7409 - val_loss: 0.6688 - val_accuracy: 0.7193\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6270 - accuracy: 0.7479 - val_loss: 0.6308 - val_accuracy: 0.7390\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.6120 - accuracy: 0.7551 - val_loss: 0.6377 - val_accuracy: 0.7363\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.6060 - accuracy: 0.7566 - val_loss: 0.6174 - val_accuracy: 0.7423\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5749 - accuracy: 0.7745 - val_loss: 0.5986 - val_accuracy: 0.7550\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5620 - accuracy: 0.7780 - val_loss: 0.5863 - val_accuracy: 0.7637\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.5539 - accuracy: 0.7789 - val_loss: 0.5897 - val_accuracy: 0.7543\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5344 - accuracy: 0.7924 - val_loss: 0.5827 - val_accuracy: 0.7623\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 25us/step - loss: 0.5279 - accuracy: 0.7958 - val_loss: 0.5892 - val_accuracy: 0.7547\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5140 - accuracy: 0.7999 - val_loss: 0.5694 - val_accuracy: 0.7620\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.5074 - accuracy: 0.8014 - val_loss: 0.5639 - val_accuracy: 0.7653\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4975 - accuracy: 0.8043 - val_loss: 0.5566 - val_accuracy: 0.7687\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4859 - accuracy: 0.8110 - val_loss: 0.5460 - val_accuracy: 0.7780\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4711 - accuracy: 0.8185 - val_loss: 0.5700 - val_accuracy: 0.7647\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4851 - accuracy: 0.8075 - val_loss: 0.5720 - val_accuracy: 0.7660\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4668 - accuracy: 0.8200 - val_loss: 0.5662 - val_accuracy: 0.7667\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4570 - accuracy: 0.8256 - val_loss: 0.5443 - val_accuracy: 0.7810\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4402 - accuracy: 0.8321 - val_loss: 0.5369 - val_accuracy: 0.7810\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4276 - accuracy: 0.8367 - val_loss: 0.5305 - val_accuracy: 0.7833\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4332 - accuracy: 0.8310 - val_loss: 0.5282 - val_accuracy: 0.7800\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4290 - accuracy: 0.8303 - val_loss: 0.5228 - val_accuracy: 0.7857\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4165 - accuracy: 0.8411 - val_loss: 0.5344 - val_accuracy: 0.7823\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.4020 - accuracy: 0.8465 - val_loss: 0.5413 - val_accuracy: 0.7840\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3903 - accuracy: 0.8512 - val_loss: 0.5388 - val_accuracy: 0.7820\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.4011 - accuracy: 0.8439 - val_loss: 0.5319 - val_accuracy: 0.7860\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3937 - accuracy: 0.8487 - val_loss: 0.6052 - val_accuracy: 0.7577\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3825 - accuracy: 0.8531 - val_loss: 0.5236 - val_accuracy: 0.7903\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3659 - accuracy: 0.8633 - val_loss: 0.5168 - val_accuracy: 0.7897\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3695 - accuracy: 0.8590 - val_loss: 0.5091 - val_accuracy: 0.7967\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3502 - accuracy: 0.8725 - val_loss: 0.5107 - val_accuracy: 0.7970\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3435 - accuracy: 0.8736 - val_loss: 0.5079 - val_accuracy: 0.7970\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3366 - accuracy: 0.8776 - val_loss: 0.5186 - val_accuracy: 0.7920\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3379 - accuracy: 0.8756 - val_loss: 0.5197 - val_accuracy: 0.7913\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3272 - accuracy: 0.8816 - val_loss: 0.4989 - val_accuracy: 0.8007\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3243 - accuracy: 0.8796 - val_loss: 0.5012 - val_accuracy: 0.7993\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3110 - accuracy: 0.8903 - val_loss: 0.5200 - val_accuracy: 0.7913\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3132 - accuracy: 0.8849 - val_loss: 0.5121 - val_accuracy: 0.7960\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.3059 - accuracy: 0.8878 - val_loss: 0.5289 - val_accuracy: 0.7857\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2972 - accuracy: 0.8916 - val_loss: 0.5332 - val_accuracy: 0.7863\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3072 - accuracy: 0.8850 - val_loss: 0.5285 - val_accuracy: 0.7857\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3059 - accuracy: 0.8869 - val_loss: 0.5846 - val_accuracy: 0.7593\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3195 - accuracy: 0.8792 - val_loss: 0.5232 - val_accuracy: 0.7887\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 27us/step - loss: 0.3121 - accuracy: 0.8820 - val_loss: 0.5160 - val_accuracy: 0.7913\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 26us/step - loss: 0.2897 - accuracy: 0.8930 - val_loss: 0.5028 - val_accuracy: 0.8027\n",
      "4000/4000 [==============================] - 0s 10us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 109us/step - loss: 1100665.2546 - accuracy: 0.3422 - val_loss: 15020.5752 - val_accuracy: 0.3233\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 7927.1221 - accuracy: 0.3315 - val_loss: 1.1387 - val_accuracy: 0.3337\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.6069 - accuracy: 0.3271 - val_loss: 1.0987 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0988 - accuracy: 0.3338 - val_loss: 1.0985 - val_accuracy: 0.3340\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0988 - accuracy: 0.3288 - val_loss: 1.0987 - val_accuracy: 0.3233\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0990 - accuracy: 0.3321 - val_loss: 1.0987 - val_accuracy: 0.3233\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0989 - accuracy: 0.3298 - val_loss: 1.0989 - val_accuracy: 0.3340\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0988 - accuracy: 0.3281 - val_loss: 1.0989 - val_accuracy: 0.3340\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0988 - accuracy: 0.3324 - val_loss: 1.0986 - val_accuracy: 0.3340\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0991 - accuracy: 0.3304 - val_loss: 1.0987 - val_accuracy: 0.3340\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0990 - accuracy: 0.3285 - val_loss: 1.0992 - val_accuracy: 0.3340\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0996 - accuracy: 0.3309 - val_loss: 1.0985 - val_accuracy: 0.3427\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0989 - accuracy: 0.3304 - val_loss: 1.0985 - val_accuracy: 0.3340\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0992 - accuracy: 0.3340 - val_loss: 1.0991 - val_accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0997 - accuracy: 0.3279 - val_loss: 1.0989 - val_accuracy: 0.3233\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0989 - accuracy: 0.3269 - val_loss: 1.0987 - val_accuracy: 0.3233\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0994 - accuracy: 0.3295 - val_loss: 1.0983 - val_accuracy: 0.3427\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0990 - accuracy: 0.3369 - val_loss: 1.0991 - val_accuracy: 0.3233\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0990 - accuracy: 0.3271 - val_loss: 1.0984 - val_accuracy: 0.3427\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0993 - accuracy: 0.3261 - val_loss: 1.0989 - val_accuracy: 0.3340\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0991 - accuracy: 0.3347 - val_loss: 1.0997 - val_accuracy: 0.3233\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0992 - accuracy: 0.3340 - val_loss: 1.0987 - val_accuracy: 0.3340\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.0994 - accuracy: 0.3372 - val_loss: 1.0994 - val_accuracy: 0.3233\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.0993 - accuracy: 0.3395 - val_loss: 1.0986 - val_accuracy: 0.3427\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0993 - accuracy: 0.3349 - val_loss: 1.0996 - val_accuracy: 0.3340\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.1003 - accuracy: 0.3231 - val_loss: 1.0984 - val_accuracy: 0.3427\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.0994 - accuracy: 0.3250 - val_loss: 1.0997 - val_accuracy: 0.3340\n",
      "4000/4000 [==============================] - 0s 20us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 5858438.1383 - accuracy: 0.3343 - val_loss: 2762.4494 - val_accuracy: 0.3340\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 2760.7097 - accuracy: 0.3360 - val_loss: 1.1205 - val_accuracy: 0.3233\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 160.6939 - accuracy: 0.3350 - val_loss: 1.6071 - val_accuracy: 0.3340\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1925 - accuracy: 0.3327 - val_loss: 1.2644 - val_accuracy: 0.3427\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.1422 - accuracy: 0.3375 - val_loss: 1.1272 - val_accuracy: 0.3340\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 1.1124 - accuracy: 0.3335 - val_loss: 1.1289 - val_accuracy: 0.3340\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 110us/step - loss: 1.1187 - accuracy: 0.3326 - val_loss: 1.1473 - val_accuracy: 0.3427\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 93us/step - loss: 1.1187 - accuracy: 0.3371 - val_loss: 1.1016 - val_accuracy: 0.3340\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1094 - accuracy: 0.3349 - val_loss: 1.1105 - val_accuracy: 0.3340\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1151 - accuracy: 0.3434 - val_loss: 1.1399 - val_accuracy: 0.3233\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1278 - accuracy: 0.3401 - val_loss: 1.1298 - val_accuracy: 0.3233\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.1531 - accuracy: 0.3371 - val_loss: 1.1081 - val_accuracy: 0.3233\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.1361 - accuracy: 0.3326 - val_loss: 1.1051 - val_accuracy: 0.3233\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1149 - accuracy: 0.3310 - val_loss: 1.1560 - val_accuracy: 0.3427\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 1.1316 - accuracy: 0.3251 - val_loss: 1.1171 - val_accuracy: 0.3427\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1170 - accuracy: 0.3346 - val_loss: 1.1306 - val_accuracy: 0.3340\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.1273 - accuracy: 0.3275 - val_loss: 1.1676 - val_accuracy: 0.3233\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1162 - accuracy: 0.3344 - val_loss: 1.1053 - val_accuracy: 0.3340\n",
      "4000/4000 [==============================] - 0s 22us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 104us/step - loss: 3728275.2008 - accuracy: 0.3366 - val_loss: 416.0790 - val_accuracy: 0.3347\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 99.7095 - accuracy: 0.3426 - val_loss: 718.3301 - val_accuracy: 0.3343\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 2.5453 - accuracy: 0.3361 - val_loss: 845.1425 - val_accuracy: 0.3233\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.3733 - accuracy: 0.3375 - val_loss: 850.7975 - val_accuracy: 0.3343\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.2634 - accuracy: 0.3380 - val_loss: 851.0784 - val_accuracy: 0.3233\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 85us/step - loss: 1.1809 - accuracy: 0.3384 - val_loss: 850.8962 - val_accuracy: 0.3343\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 87us/step - loss: 1.1490 - accuracy: 0.3361 - val_loss: 851.0629 - val_accuracy: 0.3433\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.2775 - accuracy: 0.3338 - val_loss: 851.2667 - val_accuracy: 0.3233\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.2018 - accuracy: 0.3266 - val_loss: 851.3296 - val_accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 1.2618 - accuracy: 0.3391 - val_loss: 851.0820 - val_accuracy: 0.3343\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 1.2782 - accuracy: 0.3252 - val_loss: 851.0859 - val_accuracy: 0.3233\n",
      "4000/4000 [==============================] - 0s 21us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 418752.0578 - accuracy: 0.3428 - val_loss: 1.1459 - val_accuracy: 0.3427\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1712.1429 - accuracy: 0.3279 - val_loss: 1.4670 - val_accuracy: 0.3340\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1970 - accuracy: 0.3236 - val_loss: 1.1093 - val_accuracy: 0.3340\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1824 - accuracy: 0.3237 - val_loss: 1.1993 - val_accuracy: 0.3233\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1681 - accuracy: 0.3319 - val_loss: 1.1436 - val_accuracy: 0.3340\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.2646 - accuracy: 0.3319 - val_loss: 1.1138 - val_accuracy: 0.3427\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1785 - accuracy: 0.3436 - val_loss: 1.1643 - val_accuracy: 0.3233\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.2154 - accuracy: 0.3385 - val_loss: 1.1073 - val_accuracy: 0.3340\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1928 - accuracy: 0.3335 - val_loss: 1.1755 - val_accuracy: 0.3340\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1677 - accuracy: 0.3346 - val_loss: 1.1866 - val_accuracy: 0.3233\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1584 - accuracy: 0.3228 - val_loss: 1.1148 - val_accuracy: 0.3233\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1487 - accuracy: 0.3326 - val_loss: 1.3213 - val_accuracy: 0.3340\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1559 - accuracy: 0.3313 - val_loss: 1.3554 - val_accuracy: 0.3427\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1988 - accuracy: 0.3341 - val_loss: 1.2245 - val_accuracy: 0.3340\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.2436 - accuracy: 0.3343 - val_loss: 1.3516 - val_accuracy: 0.3233\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1638 - accuracy: 0.3313 - val_loss: 1.1569 - val_accuracy: 0.3427\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1937 - accuracy: 0.3364 - val_loss: 1.1391 - val_accuracy: 0.3340\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1319 - accuracy: 0.3384 - val_loss: 1.2891 - val_accuracy: 0.3427\n",
      "4000/4000 [==============================] - 0s 28us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 185us/step - loss: 1393585.6670 - accuracy: 0.3322 - val_loss: 8397.3619 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 455.7418 - accuracy: 0.3380 - val_loss: 7541.0140 - val_accuracy: 0.3337\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.3017 - accuracy: 0.3271 - val_loss: 7429.6487 - val_accuracy: 0.3430\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.1371 - accuracy: 0.3380 - val_loss: 7429.4957 - val_accuracy: 0.3430\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.1242 - accuracy: 0.3248 - val_loss: 7429.3568 - val_accuracy: 0.3430\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1346 - accuracy: 0.3226 - val_loss: 7429.2312 - val_accuracy: 0.3430\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1210 - accuracy: 0.3274 - val_loss: 7429.3312 - val_accuracy: 0.3337\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1345 - accuracy: 0.3282 - val_loss: 7429.5466 - val_accuracy: 0.3230\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1129 - accuracy: 0.3374 - val_loss: 7429.5326 - val_accuracy: 0.3233\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1341 - accuracy: 0.3326 - val_loss: 7429.1926 - val_accuracy: 0.3233\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 155us/step - loss: 1.1131 - accuracy: 0.3284 - val_loss: 7428.8211 - val_accuracy: 0.3430\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.1155 - accuracy: 0.3354 - val_loss: 7428.6569 - val_accuracy: 0.3337\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.1095 - accuracy: 0.3363 - val_loss: 7428.5545 - val_accuracy: 0.3337\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 1.1055 - accuracy: 0.3339 - val_loss: 7428.4803 - val_accuracy: 0.3430\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 166us/step - loss: 1.1160 - accuracy: 0.3319 - val_loss: 7428.3321 - val_accuracy: 0.3337\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.1101 - accuracy: 0.3307 - val_loss: 7428.3077 - val_accuracy: 0.3233\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 1.1106 - accuracy: 0.3220 - val_loss: 7428.0698 - val_accuracy: 0.3337\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 1.1077 - accuracy: 0.3331 - val_loss: 7428.0368 - val_accuracy: 0.3233\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1204 - accuracy: 0.3356 - val_loss: 7427.6953 - val_accuracy: 0.3233\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 1.1052 - accuracy: 0.3438 - val_loss: 7427.3210 - val_accuracy: 0.3233\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.1076 - accuracy: 0.3335 - val_loss: 7427.2331 - val_accuracy: 0.3233\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 1.1043 - accuracy: 0.3313 - val_loss: 7427.0333 - val_accuracy: 0.3337\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1173 - accuracy: 0.3345 - val_loss: 7426.9492 - val_accuracy: 0.3233\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1156 - accuracy: 0.3347 - val_loss: 7426.8378 - val_accuracy: 0.3233\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1119 - accuracy: 0.3274 - val_loss: 7426.5270 - val_accuracy: 0.3233\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1129 - accuracy: 0.3304 - val_loss: 7426.3341 - val_accuracy: 0.3233\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1104 - accuracy: 0.3381 - val_loss: 7426.0704 - val_accuracy: 0.3430\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1170 - accuracy: 0.3316 - val_loss: 7425.8700 - val_accuracy: 0.3430\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1124 - accuracy: 0.3356 - val_loss: 7425.5196 - val_accuracy: 0.3233\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1080 - accuracy: 0.3281 - val_loss: 7425.2444 - val_accuracy: 0.3337\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 1.1153 - accuracy: 0.3298 - val_loss: 7424.9176 - val_accuracy: 0.3430\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1155 - accuracy: 0.3313 - val_loss: 7424.6848 - val_accuracy: 0.3233\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1334 - accuracy: 0.3244 - val_loss: 7424.2413 - val_accuracy: 0.3233\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1144 - accuracy: 0.3402 - val_loss: 7423.5189 - val_accuracy: 0.3233\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1118 - accuracy: 0.3291 - val_loss: 7423.1515 - val_accuracy: 0.3233\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1099 - accuracy: 0.3366 - val_loss: 7422.9246 - val_accuracy: 0.3337\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1085 - accuracy: 0.3336 - val_loss: 7422.7559 - val_accuracy: 0.3337\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1278 - accuracy: 0.3291 - val_loss: 7422.3850 - val_accuracy: 0.3337\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1064 - accuracy: 0.3335 - val_loss: 7422.1820 - val_accuracy: 0.3233\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1091 - accuracy: 0.3266 - val_loss: 7421.9550 - val_accuracy: 0.3233\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1209 - accuracy: 0.3439 - val_loss: 7421.2768 - val_accuracy: 0.3233\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1171 - accuracy: 0.3372 - val_loss: 7420.3700 - val_accuracy: 0.3430\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1258 - accuracy: 0.3309 - val_loss: 7419.6532 - val_accuracy: 0.3430\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1138 - accuracy: 0.3295 - val_loss: 7419.3386 - val_accuracy: 0.3430\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1144 - accuracy: 0.3364 - val_loss: 7418.0751 - val_accuracy: 0.3337\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1178 - accuracy: 0.3447 - val_loss: 7417.5164 - val_accuracy: 0.3337\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 151us/step - loss: 1.1153 - accuracy: 0.3401 - val_loss: 7417.1588 - val_accuracy: 0.3430\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1266 - accuracy: 0.3294 - val_loss: 7416.2484 - val_accuracy: 0.3233\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1158 - accuracy: 0.3244 - val_loss: 7415.3858 - val_accuracy: 0.3337\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 1.1102 - accuracy: 0.3346 - val_loss: 7414.9110 - val_accuracy: 0.3337\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1109 - accuracy: 0.3205 - val_loss: 7414.5354 - val_accuracy: 0.3233\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1188 - accuracy: 0.3309 - val_loss: 7413.2588 - val_accuracy: 0.3337\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1111 - accuracy: 0.3400 - val_loss: 7412.5248 - val_accuracy: 0.3337\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 1.1118 - accuracy: 0.3351 - val_loss: 7412.0668 - val_accuracy: 0.3233\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 1.1157 - accuracy: 0.3363 - val_loss: 7410.6732 - val_accuracy: 0.3233\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 145us/step - loss: 1.1102 - accuracy: 0.3404 - val_loss: 7409.8113 - val_accuracy: 0.3337\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 1.1174 - accuracy: 0.3358 - val_loss: 7408.3737 - val_accuracy: 0.3233\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1094 - accuracy: 0.3346 - val_loss: 7407.8973 - val_accuracy: 0.3233\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1147 - accuracy: 0.3410 - val_loss: 7406.6456 - val_accuracy: 0.3430\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.1165 - accuracy: 0.3269 - val_loss: 7405.5948 - val_accuracy: 0.3430\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1236 - accuracy: 0.3295 - val_loss: 7403.9122 - val_accuracy: 0.3337\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 159us/step - loss: 1.1100 - accuracy: 0.3273 - val_loss: 7402.4239 - val_accuracy: 0.3337\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.1120 - accuracy: 0.3332 - val_loss: 7401.7050 - val_accuracy: 0.3337\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1074 - accuracy: 0.3331 - val_loss: 7400.9066 - val_accuracy: 0.3430\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1133 - accuracy: 0.3406 - val_loss: 7400.3489 - val_accuracy: 0.3430\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1115 - accuracy: 0.3304 - val_loss: 7399.5246 - val_accuracy: 0.3337\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 1.1076 - accuracy: 0.3281 - val_loss: 7399.0573 - val_accuracy: 0.3233\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.1115 - accuracy: 0.3332 - val_loss: 7398.2496 - val_accuracy: 0.3337\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1073 - accuracy: 0.3476 - val_loss: 7397.6423 - val_accuracy: 0.3430\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 147us/step - loss: 1.1129 - accuracy: 0.3265 - val_loss: 7396.3302 - val_accuracy: 0.3337\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1247 - accuracy: 0.3285 - val_loss: 7395.6521 - val_accuracy: 0.3337\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 1.1231 - accuracy: 0.3430 - val_loss: 7393.4428 - val_accuracy: 0.3233\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1078 - accuracy: 0.3351 - val_loss: 7391.7475 - val_accuracy: 0.3430\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 144us/step - loss: 1.1131 - accuracy: 0.3364 - val_loss: 7390.1373 - val_accuracy: 0.3233\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 146us/step - loss: 1.1173 - accuracy: 0.3243 - val_loss: 7388.1979 - val_accuracy: 0.3233\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.1154 - accuracy: 0.3309 - val_loss: 7386.7679 - val_accuracy: 0.3430\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 160us/step - loss: 1.1241 - accuracy: 0.3375 - val_loss: 7382.9620 - val_accuracy: 0.3430\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 1.1071 - accuracy: 0.3352 - val_loss: 7381.9488 - val_accuracy: 0.3233\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 1.1173 - accuracy: 0.3339 - val_loss: 7379.2723 - val_accuracy: 0.3337\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 161us/step - loss: 1.1089 - accuracy: 0.3304 - val_loss: 7378.4433 - val_accuracy: 0.3430\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.1167 - accuracy: 0.3249 - val_loss: 7376.9684 - val_accuracy: 0.3233\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 1.1092 - accuracy: 0.3290 - val_loss: 7374.6691 - val_accuracy: 0.3337\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 167us/step - loss: 1.1113 - accuracy: 0.3340 - val_loss: 7372.5176 - val_accuracy: 0.3430\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 163us/step - loss: 1.1170 - accuracy: 0.3270 - val_loss: 7371.0076 - val_accuracy: 0.3430\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.1167 - accuracy: 0.3380 - val_loss: 7367.4737 - val_accuracy: 0.3430\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1169 - accuracy: 0.3261 - val_loss: 7365.9113 - val_accuracy: 0.3233\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 141us/step - loss: 1.1314 - accuracy: 0.3288 - val_loss: 7362.3365 - val_accuracy: 0.3430\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.1244 - accuracy: 0.3350 - val_loss: 7358.2711 - val_accuracy: 0.3233\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 162us/step - loss: 1.1213 - accuracy: 0.3289 - val_loss: 7354.2994 - val_accuracy: 0.3233\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 156us/step - loss: 1.1174 - accuracy: 0.3319 - val_loss: 7347.6945 - val_accuracy: 0.3430\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 1.1115 - accuracy: 0.3310 - val_loss: 7345.2976 - val_accuracy: 0.3233\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 157us/step - loss: 1.1081 - accuracy: 0.3305 - val_loss: 7342.5746 - val_accuracy: 0.3337\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 1.1113 - accuracy: 0.3428 - val_loss: 7341.7245 - val_accuracy: 0.3233\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 1.1124 - accuracy: 0.3379 - val_loss: 7338.8353 - val_accuracy: 0.3233\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1114 - accuracy: 0.3347 - val_loss: 7336.6557 - val_accuracy: 0.3233\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 175us/step - loss: 1.1191 - accuracy: 0.3389 - val_loss: 7333.4108 - val_accuracy: 0.3233\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 170us/step - loss: 1.1105 - accuracy: 0.3385 - val_loss: 7326.6482 - val_accuracy: 0.3233\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 165us/step - loss: 1.1087 - accuracy: 0.3294 - val_loss: 7323.8975 - val_accuracy: 0.3337\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.1192 - accuracy: 0.3386 - val_loss: 7316.8703 - val_accuracy: 0.3337\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 1.1082 - accuracy: 0.3332 - val_loss: 7314.8503 - val_accuracy: 0.3233\n",
      "4000/4000 [==============================] - 0s 27us/step\n",
      "Train on 8000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 158us/step - loss: 1076668.3492 - accuracy: 0.3478 - val_loss: 9058.4966 - val_accuracy: 0.3427\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 4355.2197 - accuracy: 0.3352 - val_loss: 639.7342 - val_accuracy: 0.3340\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 142us/step - loss: 686.8165 - accuracy: 0.3420 - val_loss: 971.2815 - val_accuracy: 0.3427\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 182.3583 - accuracy: 0.3430 - val_loss: 4.3616 - val_accuracy: 0.3543\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 139us/step - loss: 1.9301 - accuracy: 0.3461 - val_loss: 1.1049 - val_accuracy: 0.4243\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 140us/step - loss: 1.0865 - accuracy: 0.3995 - val_loss: 1.0618 - val_accuracy: 0.4257\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 138us/step - loss: 1.0742 - accuracy: 0.4136 - val_loss: 1.0710 - val_accuracy: 0.4177\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 152us/step - loss: 1.0819 - accuracy: 0.3971 - val_loss: 1.0753 - val_accuracy: 0.4067\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.0754 - accuracy: 0.3945 - val_loss: 1.0710 - val_accuracy: 0.4090\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 1.0774 - accuracy: 0.4016 - val_loss: 1.0744 - val_accuracy: 0.3840\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 1.0753 - accuracy: 0.3943 - val_loss: 1.0712 - val_accuracy: 0.4037\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 150us/step - loss: 1.0744 - accuracy: 0.3870 - val_loss: 1.0722 - val_accuracy: 0.4067\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 149us/step - loss: 1.0754 - accuracy: 0.3899 - val_loss: 1.0726 - val_accuracy: 0.4050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 143us/step - loss: 1.0752 - accuracy: 0.3927 - val_loss: 1.0769 - val_accuracy: 0.3933\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 148us/step - loss: 1.0742 - accuracy: 0.4013 - val_loss: 1.0699 - val_accuracy: 0.4127\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 153us/step - loss: 1.0699 - accuracy: 0.4234 - val_loss: 1.0774 - val_accuracy: 0.4027\n",
      "4000/4000 [==============================] - 0s 31us/step\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 0s 37us/step - loss: 0.9162 - accuracy: 0.5862 - val_loss: 0.7841 - val_accuracy: 0.6900\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.7733 - accuracy: 0.6885 - val_loss: 0.7283 - val_accuracy: 0.6977\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.7153 - accuracy: 0.7147 - val_loss: 0.6954 - val_accuracy: 0.7093\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.6867 - accuracy: 0.7278 - val_loss: 0.6959 - val_accuracy: 0.7017\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.6680 - accuracy: 0.7308 - val_loss: 0.6414 - val_accuracy: 0.7420\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.6285 - accuracy: 0.7541 - val_loss: 0.6234 - val_accuracy: 0.7417\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.6096 - accuracy: 0.7563 - val_loss: 0.6004 - val_accuracy: 0.7593\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.5862 - accuracy: 0.7674 - val_loss: 0.5850 - val_accuracy: 0.7657\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.5652 - accuracy: 0.7793 - val_loss: 0.5843 - val_accuracy: 0.7637\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 0s 32us/step - loss: 0.5508 - accuracy: 0.7853 - val_loss: 0.5587 - val_accuracy: 0.7703\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5343 - accuracy: 0.7938 - val_loss: 0.5517 - val_accuracy: 0.7727\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.5195 - accuracy: 0.7953 - val_loss: 0.5915 - val_accuracy: 0.7550\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5356 - accuracy: 0.7843 - val_loss: 0.5512 - val_accuracy: 0.7683\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4955 - accuracy: 0.8057 - val_loss: 0.5297 - val_accuracy: 0.7853\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4943 - accuracy: 0.8060 - val_loss: 0.5588 - val_accuracy: 0.7670\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4732 - accuracy: 0.8163 - val_loss: 0.5202 - val_accuracy: 0.7887\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4573 - accuracy: 0.8251 - val_loss: 0.5097 - val_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4594 - accuracy: 0.8221 - val_loss: 0.5190 - val_accuracy: 0.7927\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4598 - accuracy: 0.8206 - val_loss: 0.5309 - val_accuracy: 0.7800\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4436 - accuracy: 0.8286 - val_loss: 0.5097 - val_accuracy: 0.7953\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.4307 - accuracy: 0.8332 - val_loss: 0.5039 - val_accuracy: 0.7957\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.4172 - accuracy: 0.8397 - val_loss: 0.4999 - val_accuracy: 0.7937\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 0s 33us/step - loss: 0.4073 - accuracy: 0.8452 - val_loss: 0.4908 - val_accuracy: 0.8037\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.3971 - accuracy: 0.8481 - val_loss: 0.5059 - val_accuracy: 0.7943\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3913 - accuracy: 0.8517 - val_loss: 0.4976 - val_accuracy: 0.7980\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3923 - accuracy: 0.8521 - val_loss: 0.5203 - val_accuracy: 0.7843\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4071 - accuracy: 0.8414 - val_loss: 0.4894 - val_accuracy: 0.8053\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3703 - accuracy: 0.8589 - val_loss: 0.5060 - val_accuracy: 0.7977\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 0s 32us/step - loss: 0.3636 - accuracy: 0.8633 - val_loss: 0.5043 - val_accuracy: 0.7923\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.3670 - accuracy: 0.8612 - val_loss: 0.4790 - val_accuracy: 0.8057\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3521 - accuracy: 0.8677 - val_loss: 0.4801 - val_accuracy: 0.8050\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3531 - accuracy: 0.8660 - val_loss: 0.4847 - val_accuracy: 0.8060\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3460 - accuracy: 0.8701 - val_loss: 0.4822 - val_accuracy: 0.8053\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3329 - accuracy: 0.8748 - val_loss: 0.4874 - val_accuracy: 0.7997\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3168 - accuracy: 0.8832 - val_loss: 0.4760 - val_accuracy: 0.8123\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3111 - accuracy: 0.8865 - val_loss: 0.4817 - val_accuracy: 0.8043\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3219 - accuracy: 0.8780 - val_loss: 0.4701 - val_accuracy: 0.8140\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3109 - accuracy: 0.8816 - val_loss: 0.4813 - val_accuracy: 0.8083\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2900 - accuracy: 0.8938 - val_loss: 0.4801 - val_accuracy: 0.8073\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2909 - accuracy: 0.8944 - val_loss: 0.4869 - val_accuracy: 0.8070\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2890 - accuracy: 0.8951 - val_loss: 0.4784 - val_accuracy: 0.8097\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2859 - accuracy: 0.8932 - val_loss: 0.4775 - val_accuracy: 0.8123\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2734 - accuracy: 0.9038 - val_loss: 0.5203 - val_accuracy: 0.7920\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2759 - accuracy: 0.9003 - val_loss: 0.4741 - val_accuracy: 0.8110\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2806 - accuracy: 0.8977 - val_loss: 0.4997 - val_accuracy: 0.8043\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2667 - accuracy: 0.9010 - val_loss: 0.4786 - val_accuracy: 0.8093\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 0s 33us/step - loss: 0.2520 - accuracy: 0.9110 - val_loss: 0.4800 - val_accuracy: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f65f5130290>,\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'batch_size': [128, 256, 512],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.1],\n",
       "                                        'n_hidden': [2, 3, 4],\n",
       "                                        'n_neurons': [256, 512, 1024]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "params = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.1],\n",
    "    'n_hidden': [2, 3, 4],\n",
    "    'n_neurons': [256, 512, 1024],\n",
    "    'batch_size': [128, 256, 512]}\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(keras_clf, params, n_iter=10, cv=3, random_state=0)\n",
    "random_search_cv.fit(partial_x_train,\n",
    "                     partial_y_train,\n",
    "                     epochs=100,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     callbacks=[EarlyStopping(patience=10)],\n",
    "                     verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 512, 'n_hidden': 2, 'learning_rate': 0.0001, 'batch_size': 512}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8012500007947286"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the best model and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2697 - accuracy: 0.9012\n",
      "Epoch 2/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2625 - accuracy: 0.9051\n",
      "Epoch 3/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2369 - accuracy: 0.9178\n",
      "Epoch 4/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2441 - accuracy: 0.9123\n",
      "Epoch 5/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2336 - accuracy: 0.9195\n",
      "Epoch 6/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2198 - accuracy: 0.9227\n",
      "Epoch 7/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2239 - accuracy: 0.9218\n",
      "Epoch 8/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2131 - accuracy: 0.9249\n",
      "Epoch 9/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2239 - accuracy: 0.9173\n",
      "Epoch 10/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2056 - accuracy: 0.9299\n",
      "Epoch 11/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1937 - accuracy: 0.9359\n",
      "Epoch 12/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1927 - accuracy: 0.9317\n",
      "Epoch 13/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1905 - accuracy: 0.9341\n",
      "Epoch 14/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1932 - accuracy: 0.9317\n",
      "Epoch 15/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1847 - accuracy: 0.9357\n",
      "Epoch 16/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1895 - accuracy: 0.9357\n",
      "Epoch 17/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1830 - accuracy: 0.9353\n",
      "Epoch 18/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1811 - accuracy: 0.9367\n",
      "Epoch 19/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1669 - accuracy: 0.9461\n",
      "Epoch 20/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1621 - accuracy: 0.9467\n",
      "Epoch 21/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1622 - accuracy: 0.9457\n",
      "Epoch 22/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1598 - accuracy: 0.9479\n",
      "Epoch 23/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1484 - accuracy: 0.9523\n",
      "Epoch 24/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1665 - accuracy: 0.9413\n",
      "Epoch 25/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1469 - accuracy: 0.9516\n",
      "Epoch 26/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.1540 - accuracy: 0.9483\n",
      "Epoch 27/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1476 - accuracy: 0.9521\n",
      "Epoch 28/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1422 - accuracy: 0.9553\n",
      "Epoch 29/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1340 - accuracy: 0.9599\n",
      "Epoch 30/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1295 - accuracy: 0.9602\n",
      "Epoch 31/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1277 - accuracy: 0.9615\n",
      "Epoch 32/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1352 - accuracy: 0.9547\n",
      "Epoch 33/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1241 - accuracy: 0.9623\n",
      "Epoch 34/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1236 - accuracy: 0.9601\n",
      "Epoch 35/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.1181 - accuracy: 0.9637\n",
      "Epoch 36/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1302 - accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1145 - accuracy: 0.9645\n",
      "Epoch 38/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1128 - accuracy: 0.9659\n",
      "Epoch 39/100\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.1052 - accuracy: 0.9703\n",
      "Epoch 40/100\n",
      "15000/15000 [==============================] - 0s 32us/step - loss: 0.1102 - accuracy: 0.9658\n",
      "Epoch 41/100\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.1057 - accuracy: 0.9695\n",
      "Epoch 42/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1003 - accuracy: 0.9711\n",
      "Epoch 43/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1038 - accuracy: 0.9689\n",
      "Epoch 44/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0967 - accuracy: 0.9724\n",
      "Epoch 45/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.1084 - accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0878 - accuracy: 0.9767\n",
      "Epoch 47/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0974 - accuracy: 0.9704\n",
      "Epoch 48/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0868 - accuracy: 0.9767\n",
      "Epoch 49/100\n",
      "15000/15000 [==============================] - 0s 30us/step - loss: 0.1062 - accuracy: 0.9651\n",
      "Epoch 50/100\n",
      "15000/15000 [==============================] - 0s 28us/step - loss: 0.0858 - accuracy: 0.9768\n",
      "Epoch 51/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0802 - accuracy: 0.9803\n",
      "Epoch 52/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0879 - accuracy: 0.9741\n",
      "Epoch 53/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.0843 - accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0828 - accuracy: 0.9777\n",
      "Epoch 55/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0929 - accuracy: 0.9721\n",
      "Epoch 56/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0809 - accuracy: 0.9757\n",
      "Epoch 57/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0690 - accuracy: 0.9823\n",
      "Epoch 58/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0671 - accuracy: 0.9835\n",
      "Epoch 59/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0652 - accuracy: 0.9841\n",
      "Epoch 60/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0684 - accuracy: 0.9829\n",
      "Epoch 61/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0797 - accuracy: 0.9760\n",
      "Epoch 62/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0622 - accuracy: 0.9839\n",
      "Epoch 63/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0641 - accuracy: 0.9840\n",
      "Epoch 64/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.0596 - accuracy: 0.9851\n",
      "Epoch 65/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.0599 - accuracy: 0.9862\n",
      "Epoch 66/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0614 - accuracy: 0.9849\n",
      "Epoch 67/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0648 - accuracy: 0.9835\n",
      "Epoch 68/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0585 - accuracy: 0.9841\n",
      "Epoch 69/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0599 - accuracy: 0.9845\n",
      "Epoch 70/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0569 - accuracy: 0.9861\n",
      "Epoch 71/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.0767 - accuracy: 0.9761\n",
      "Epoch 72/100\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.0679 - accuracy: 0.9799\n",
      "Epoch 73/100\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.0626 - accuracy: 0.9842\n",
      "Epoch 74/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0595 - accuracy: 0.9834\n",
      "Epoch 75/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0523 - accuracy: 0.9871\n",
      "Epoch 76/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0507 - accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0520 - accuracy: 0.9869\n",
      "Epoch 78/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0554 - accuracy: 0.9857\n",
      "Epoch 79/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0414 - accuracy: 0.9913\n",
      "Epoch 80/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0401 - accuracy: 0.9929\n",
      "Epoch 81/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0448 - accuracy: 0.9896\n",
      "Epoch 82/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0411 - accuracy: 0.9914\n",
      "Epoch 83/100\n",
      "15000/15000 [==============================] - 0s 28us/step - loss: 0.0407 - accuracy: 0.9903\n",
      "Epoch 84/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0361 - accuracy: 0.9929\n",
      "Epoch 85/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0523 - accuracy: 0.9845\n",
      "Epoch 86/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0426 - accuracy: 0.9896\n",
      "Epoch 87/100\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.0377 - accuracy: 0.9922\n",
      "Epoch 88/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0451 - accuracy: 0.9882\n",
      "Epoch 89/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0425 - accuracy: 0.9893\n",
      "Epoch 90/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0517 - accuracy: 0.9858\n",
      "Epoch 91/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0434 - accuracy: 0.9890\n",
      "Epoch 92/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0411 - accuracy: 0.9902\n",
      "Epoch 93/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0391 - accuracy: 0.9902\n",
      "Epoch 94/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0415 - accuracy: 0.9895\n",
      "Epoch 95/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0614 - accuracy: 0.9796\n",
      "Epoch 96/100\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.0395 - accuracy: 0.9897\n",
      "Epoch 97/100\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.0347 - accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "15000/15000 [==============================] - 0s 28us/step - loss: 0.0281 - accuracy: 0.9945\n",
      "Epoch 99/100\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.0301 - accuracy: 0.9935\n",
      "Epoch 100/100\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.0277 - accuracy: 0.9948\n",
      "3000/3000 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7204937424659729, 0.8130000233650208]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_model = random_search_cv.best_estimator_.model\n",
    "cifar_model.fit(x_train,\n",
    "                y_train,\n",
    "                epochs=100,\n",
    "                batch_size=512)\n",
    "\n",
    "cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 0s 35us/step - loss: 0.9022 - accuracy: 0.6005 - val_loss: 0.7747 - val_accuracy: 0.6927\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.7513 - accuracy: 0.7023 - val_loss: 0.7243 - val_accuracy: 0.7097\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.7111 - accuracy: 0.7132 - val_loss: 0.6944 - val_accuracy: 0.7203\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.6703 - accuracy: 0.7367 - val_loss: 0.6467 - val_accuracy: 0.7370\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.6472 - accuracy: 0.7417 - val_loss: 0.6304 - val_accuracy: 0.7463\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.6159 - accuracy: 0.7607 - val_loss: 0.6196 - val_accuracy: 0.7503\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.5975 - accuracy: 0.7643 - val_loss: 0.5973 - val_accuracy: 0.7580\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5743 - accuracy: 0.7760 - val_loss: 0.5927 - val_accuracy: 0.7590\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5618 - accuracy: 0.7806 - val_loss: 0.5967 - val_accuracy: 0.7537\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5496 - accuracy: 0.7832 - val_loss: 0.5738 - val_accuracy: 0.7637\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5324 - accuracy: 0.7932 - val_loss: 0.5524 - val_accuracy: 0.7690\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.5249 - accuracy: 0.7940 - val_loss: 0.5569 - val_accuracy: 0.7710\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.5112 - accuracy: 0.8003 - val_loss: 0.5345 - val_accuracy: 0.7787\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4907 - accuracy: 0.8101 - val_loss: 0.5355 - val_accuracy: 0.7750\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4827 - accuracy: 0.8132 - val_loss: 0.5277 - val_accuracy: 0.7843\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4817 - accuracy: 0.8104 - val_loss: 0.5289 - val_accuracy: 0.7833\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4632 - accuracy: 0.8190 - val_loss: 0.5173 - val_accuracy: 0.7873\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4507 - accuracy: 0.8250 - val_loss: 0.5174 - val_accuracy: 0.7890\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4421 - accuracy: 0.8261 - val_loss: 0.5100 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.4367 - accuracy: 0.8313 - val_loss: 0.5047 - val_accuracy: 0.7927\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4325 - accuracy: 0.8322 - val_loss: 0.5194 - val_accuracy: 0.7860\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4188 - accuracy: 0.8393 - val_loss: 0.5072 - val_accuracy: 0.7890\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.4047 - accuracy: 0.8432 - val_loss: 0.4998 - val_accuracy: 0.7987\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3955 - accuracy: 0.8503 - val_loss: 0.4973 - val_accuracy: 0.7997\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3911 - accuracy: 0.8469 - val_loss: 0.5031 - val_accuracy: 0.7980\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3875 - accuracy: 0.8522 - val_loss: 0.5008 - val_accuracy: 0.7980\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3878 - accuracy: 0.8503 - val_loss: 0.5557 - val_accuracy: 0.7727\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3768 - accuracy: 0.8558 - val_loss: 0.4902 - val_accuracy: 0.8070\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3632 - accuracy: 0.8641 - val_loss: 0.4990 - val_accuracy: 0.8020\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3557 - accuracy: 0.8629 - val_loss: 0.5512 - val_accuracy: 0.7777\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3593 - accuracy: 0.8648 - val_loss: 0.4806 - val_accuracy: 0.8083\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3382 - accuracy: 0.8748 - val_loss: 0.4959 - val_accuracy: 0.8027\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3347 - accuracy: 0.8737 - val_loss: 0.4937 - val_accuracy: 0.8023\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3322 - accuracy: 0.8751 - val_loss: 0.5121 - val_accuracy: 0.7930\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3305 - accuracy: 0.8748 - val_loss: 0.4865 - val_accuracy: 0.8067\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.3153 - accuracy: 0.8827 - val_loss: 0.4895 - val_accuracy: 0.8013\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3042 - accuracy: 0.8873 - val_loss: 0.5011 - val_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.3091 - accuracy: 0.8837 - val_loss: 0.5089 - val_accuracy: 0.8037\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.3008 - accuracy: 0.8888 - val_loss: 0.5053 - val_accuracy: 0.8010\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2887 - accuracy: 0.8957 - val_loss: 0.4798 - val_accuracy: 0.8100\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2824 - accuracy: 0.8988 - val_loss: 0.5601 - val_accuracy: 0.7810\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2829 - accuracy: 0.8968 - val_loss: 0.4740 - val_accuracy: 0.8160\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2704 - accuracy: 0.9020 - val_loss: 0.4881 - val_accuracy: 0.8073\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2679 - accuracy: 0.9056 - val_loss: 0.4920 - val_accuracy: 0.8070\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2582 - accuracy: 0.9099 - val_loss: 0.4796 - val_accuracy: 0.8110\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2540 - accuracy: 0.9096 - val_loss: 0.4780 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2510 - accuracy: 0.9090 - val_loss: 0.5497 - val_accuracy: 0.7890\n",
      "Epoch 48/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2609 - accuracy: 0.9017 - val_loss: 0.4783 - val_accuracy: 0.8177\n",
      "Epoch 49/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.2643 - accuracy: 0.9032 - val_loss: 0.4796 - val_accuracy: 0.8140\n",
      "Epoch 50/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.2420 - accuracy: 0.9145 - val_loss: 0.5081 - val_accuracy: 0.8053\n",
      "Epoch 51/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2382 - accuracy: 0.9163 - val_loss: 0.4733 - val_accuracy: 0.8200\n",
      "Epoch 52/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2260 - accuracy: 0.9218 - val_loss: 0.4739 - val_accuracy: 0.8187\n",
      "Epoch 53/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2226 - accuracy: 0.9237 - val_loss: 0.4925 - val_accuracy: 0.8143\n",
      "Epoch 54/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2290 - accuracy: 0.9184 - val_loss: 0.4894 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2051 - accuracy: 0.9325 - val_loss: 0.4830 - val_accuracy: 0.8210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "12000/12000 [==============================] - 0s 24us/step - loss: 0.2128 - accuracy: 0.9248 - val_loss: 0.5099 - val_accuracy: 0.8063\n",
      "Epoch 57/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2130 - accuracy: 0.9254 - val_loss: 0.4768 - val_accuracy: 0.8240\n",
      "Epoch 58/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.2009 - accuracy: 0.9323 - val_loss: 0.4922 - val_accuracy: 0.8173\n",
      "Epoch 59/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.1928 - accuracy: 0.9358 - val_loss: 0.4931 - val_accuracy: 0.8157\n",
      "Epoch 60/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.1905 - accuracy: 0.9371 - val_loss: 0.4805 - val_accuracy: 0.8233\n",
      "Epoch 61/100\n",
      "12000/12000 [==============================] - 0s 25us/step - loss: 0.1873 - accuracy: 0.9383 - val_loss: 0.4979 - val_accuracy: 0.8150\n",
      "3000/3000 [==============================] - 0s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4764563307762146, 0.8243333101272583]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "cifar_model = build_model(learning_rate=1e-4, n_hidden=2, n_neurons=512)\n",
    "cifar_model.fit(partial_x_train,\n",
    "                partial_y_train,\n",
    "                epochs=100,\n",
    "                batch_size=512,\n",
    "                validation_data=(x_val, y_val),\n",
    "                callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "15000/15000 [==============================] - 0s 28us/step - loss: 0.8806 - accuracy: 0.6159\n",
      "Epoch 2/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.7365 - accuracy: 0.7032\n",
      "Epoch 3/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6838 - accuracy: 0.7286\n",
      "Epoch 4/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6547 - accuracy: 0.7420\n",
      "Epoch 5/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6232 - accuracy: 0.7533\n",
      "Epoch 6/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.5978 - accuracy: 0.7631\n",
      "Epoch 7/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5761 - accuracy: 0.7731\n",
      "Epoch 8/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5556 - accuracy: 0.7827\n",
      "Epoch 9/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5427 - accuracy: 0.7819\n",
      "Epoch 10/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.5277 - accuracy: 0.7950\n",
      "Epoch 11/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.5066 - accuracy: 0.8010\n",
      "Epoch 12/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.5023 - accuracy: 0.8001\n",
      "Epoch 13/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4911 - accuracy: 0.8075\n",
      "Epoch 14/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4786 - accuracy: 0.8094\n",
      "Epoch 15/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4671 - accuracy: 0.8159\n",
      "Epoch 16/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4648 - accuracy: 0.8171\n",
      "Epoch 17/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4462 - accuracy: 0.8258\n",
      "Epoch 18/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4401 - accuracy: 0.8291\n",
      "Epoch 19/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4306 - accuracy: 0.8297\n",
      "Epoch 20/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4168 - accuracy: 0.8383\n",
      "Epoch 21/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.4099 - accuracy: 0.8401\n",
      "Epoch 22/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4103 - accuracy: 0.8407\n",
      "Epoch 23/51\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.3974 - accuracy: 0.8437\n",
      "Epoch 24/51\n",
      "15000/15000 [==============================] - 0s 27us/step - loss: 0.3848 - accuracy: 0.8524\n",
      "Epoch 25/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3766 - accuracy: 0.8542\n",
      "Epoch 26/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3642 - accuracy: 0.8625\n",
      "Epoch 27/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3581 - accuracy: 0.8627\n",
      "Epoch 28/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3533 - accuracy: 0.8646\n",
      "Epoch 29/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3518 - accuracy: 0.8653\n",
      "Epoch 30/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3386 - accuracy: 0.8704\n",
      "Epoch 31/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3299 - accuracy: 0.8735\n",
      "Epoch 32/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3256 - accuracy: 0.8771\n",
      "Epoch 33/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.3310 - accuracy: 0.8741\n",
      "Epoch 34/51\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.3109 - accuracy: 0.8835\n",
      "Epoch 35/51\n",
      "15000/15000 [==============================] - 0s 30us/step - loss: 0.3128 - accuracy: 0.8821\n",
      "Epoch 36/51\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.3050 - accuracy: 0.8855\n",
      "Epoch 37/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2948 - accuracy: 0.8905\n",
      "Epoch 38/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2981 - accuracy: 0.8882\n",
      "Epoch 39/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2821 - accuracy: 0.8947\n",
      "Epoch 40/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2807 - accuracy: 0.8978\n",
      "Epoch 41/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2707 - accuracy: 0.9023\n",
      "Epoch 42/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2792 - accuracy: 0.8920\n",
      "Epoch 43/51\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2658 - accuracy: 0.9025\n",
      "Epoch 44/51\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2531 - accuracy: 0.9073\n",
      "Epoch 45/51\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2492 - accuracy: 0.9113\n",
      "Epoch 46/51\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2566 - accuracy: 0.9050\n",
      "Epoch 47/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2535 - accuracy: 0.9052\n",
      "Epoch 48/51\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.2378 - accuracy: 0.9140\n",
      "Epoch 49/51\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.2294 - accuracy: 0.9194\n",
      "Epoch 50/51\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.2302 - accuracy: 0.9166\n",
      "Epoch 51/51\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2182 - accuracy: 0.9242\n",
      "3000/3000 [==============================] - 0s 78us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43873230934143065, 0.8386666774749756]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "cifar_model = build_model(learning_rate=1e-4, n_hidden=2, n_neurons=512)\n",
    "cifar_model.fit(x_train,\n",
    "                y_train,\n",
    "                epochs=51,\n",
    "                batch_size=512)\n",
    "\n",
    "cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 0s 41us/step - loss: 1.5407 - accuracy: 0.4467 - val_loss: 1.0245 - val_accuracy: 0.6327\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.9860 - accuracy: 0.6276 - val_loss: 0.9521 - val_accuracy: 0.6423\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.9082 - accuracy: 0.6648 - val_loss: 0.8559 - val_accuracy: 0.6950\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.8549 - accuracy: 0.6908 - val_loss: 0.8517 - val_accuracy: 0.6863\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.8244 - accuracy: 0.7017 - val_loss: 0.7795 - val_accuracy: 0.7260\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.7802 - accuracy: 0.7223 - val_loss: 0.7585 - val_accuracy: 0.7310\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.7477 - accuracy: 0.7345 - val_loss: 0.7749 - val_accuracy: 0.7070\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.7213 - accuracy: 0.7429 - val_loss: 0.7179 - val_accuracy: 0.7417\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.7168 - accuracy: 0.7424 - val_loss: 0.7581 - val_accuracy: 0.7203\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.7022 - accuracy: 0.7466 - val_loss: 0.6693 - val_accuracy: 0.7570\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.6723 - accuracy: 0.7643 - val_loss: 0.6603 - val_accuracy: 0.7633\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.6471 - accuracy: 0.7710 - val_loss: 0.6720 - val_accuracy: 0.7573\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6300 - accuracy: 0.7759 - val_loss: 0.6521 - val_accuracy: 0.7623\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.6206 - accuracy: 0.7810 - val_loss: 0.6461 - val_accuracy: 0.7717\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.6010 - accuracy: 0.7876 - val_loss: 0.6297 - val_accuracy: 0.7760\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.6097 - accuracy: 0.7843 - val_loss: 0.6320 - val_accuracy: 0.7707\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5825 - accuracy: 0.7961 - val_loss: 0.6385 - val_accuracy: 0.7693\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5827 - accuracy: 0.7949 - val_loss: 0.7112 - val_accuracy: 0.7453\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.5680 - accuracy: 0.8040 - val_loss: 0.6115 - val_accuracy: 0.7820\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5371 - accuracy: 0.8129 - val_loss: 0.6378 - val_accuracy: 0.7740\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5344 - accuracy: 0.8123 - val_loss: 0.6172 - val_accuracy: 0.7827\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5480 - accuracy: 0.8076 - val_loss: 0.6111 - val_accuracy: 0.7860\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5269 - accuracy: 0.8145 - val_loss: 0.6377 - val_accuracy: 0.7750\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5194 - accuracy: 0.8177 - val_loss: 0.6115 - val_accuracy: 0.7863\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5062 - accuracy: 0.8228 - val_loss: 0.5934 - val_accuracy: 0.7933\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5030 - accuracy: 0.8259 - val_loss: 0.5917 - val_accuracy: 0.7910\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4913 - accuracy: 0.8294 - val_loss: 0.5937 - val_accuracy: 0.7917\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.4604 - accuracy: 0.8438 - val_loss: 0.5666 - val_accuracy: 0.8023\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.4794 - accuracy: 0.8310 - val_loss: 0.6668 - val_accuracy: 0.7593\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4872 - accuracy: 0.8309 - val_loss: 0.6813 - val_accuracy: 0.7543\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.4837 - accuracy: 0.8313 - val_loss: 0.5769 - val_accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4594 - accuracy: 0.8395 - val_loss: 0.6153 - val_accuracy: 0.7783\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4536 - accuracy: 0.8443 - val_loss: 0.5908 - val_accuracy: 0.7927\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4330 - accuracy: 0.8540 - val_loss: 0.5759 - val_accuracy: 0.8023\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.4173 - accuracy: 0.8595 - val_loss: 0.6377 - val_accuracy: 0.7827\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.4369 - accuracy: 0.8512 - val_loss: 0.5839 - val_accuracy: 0.7977\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.4228 - accuracy: 0.8567 - val_loss: 0.5734 - val_accuracy: 0.7993\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.4134 - accuracy: 0.8612 - val_loss: 0.5914 - val_accuracy: 0.7910\n",
      "3000/3000 [==============================] - 0s 61us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5865164754390717, 0.7946666479110718]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "l2_cifar_model = Sequential()\n",
    "l2_cifar_model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "                    activation='relu', input_shape=(x_train.shape[1],)))\n",
    "l2_cifar_model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "                      activation='relu'))\n",
    "l2_cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "l2_cifar_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "l2_cifar_model.fit(partial_x_train, \n",
    "                    partial_y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "l2_cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "15000/15000 [==============================] - 1s 33us/step - loss: 1.3604 - accuracy: 0.5025\n",
      "Epoch 2/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.9039 - accuracy: 0.6742\n",
      "Epoch 3/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.8375 - accuracy: 0.7011\n",
      "Epoch 4/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.8001 - accuracy: 0.7112\n",
      "Epoch 5/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.7730 - accuracy: 0.7179\n",
      "Epoch 6/28\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.7702 - accuracy: 0.7155\n",
      "Epoch 7/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.7133 - accuracy: 0.7464\n",
      "Epoch 8/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6750 - accuracy: 0.7607\n",
      "Epoch 9/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6595 - accuracy: 0.7638\n",
      "Epoch 10/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6423 - accuracy: 0.7699\n",
      "Epoch 11/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6292 - accuracy: 0.7757\n",
      "Epoch 12/28\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.6478 - accuracy: 0.7663\n",
      "Epoch 13/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6040 - accuracy: 0.7855\n",
      "Epoch 14/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5909 - accuracy: 0.7926\n",
      "Epoch 15/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5719 - accuracy: 0.7959\n",
      "Epoch 16/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5677 - accuracy: 0.7974\n",
      "Epoch 17/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5702 - accuracy: 0.7953\n",
      "Epoch 18/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5714 - accuracy: 0.7935\n",
      "Epoch 19/28\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5447 - accuracy: 0.8092\n",
      "Epoch 20/28\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5134 - accuracy: 0.8191\n",
      "Epoch 21/28\n",
      "15000/15000 [==============================] - 0s 30us/step - loss: 0.5089 - accuracy: 0.8211\n",
      "Epoch 22/28\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.5206 - accuracy: 0.8178\n",
      "Epoch 23/28\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.5131 - accuracy: 0.8165\n",
      "Epoch 24/28\n",
      "15000/15000 [==============================] - 0s 29us/step - loss: 0.4863 - accuracy: 0.8301\n",
      "Epoch 25/28\n",
      "15000/15000 [==============================] - 0s 33us/step - loss: 0.4995 - accuracy: 0.8207\n",
      "Epoch 26/28\n",
      "15000/15000 [==============================] - 0s 33us/step - loss: 0.4624 - accuracy: 0.8403\n",
      "Epoch 27/28\n",
      "15000/15000 [==============================] - 1s 34us/step - loss: 0.4610 - accuracy: 0.8385\n",
      "Epoch 28/28\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.4533 - accuracy: 0.8405\n",
      "3000/3000 [==============================] - 0s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5325062424341838, 0.8100000023841858]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "l2_cifar_model = Sequential()\n",
    "l2_cifar_model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "                    activation='relu', input_shape=(x_train.shape[1],)))\n",
    "l2_cifar_model.add(Dense(512, kernel_regularizer=keras.regularizers.l2(0.0001),\n",
    "                      activation='relu'))\n",
    "l2_cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "l2_cifar_model.compile(optimizer='adam',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "l2_cifar_model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=28,\n",
    "                    batch_size=512)\n",
    "\n",
    "l2_cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 0s 41us/step - loss: 1.5703 - accuracy: 0.3821 - val_loss: 0.9849 - val_accuracy: 0.5540\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.9211 - accuracy: 0.5807 - val_loss: 0.8027 - val_accuracy: 0.6570\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.8155 - accuracy: 0.6576 - val_loss: 0.7379 - val_accuracy: 0.7040\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.7624 - accuracy: 0.6889 - val_loss: 0.6944 - val_accuracy: 0.7173\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.7193 - accuracy: 0.7079 - val_loss: 0.6814 - val_accuracy: 0.7177\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.7106 - accuracy: 0.7064 - val_loss: 0.6824 - val_accuracy: 0.7160\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.6852 - accuracy: 0.7233 - val_loss: 0.6462 - val_accuracy: 0.7350\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6670 - accuracy: 0.7290 - val_loss: 0.6247 - val_accuracy: 0.7390\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6457 - accuracy: 0.7387 - val_loss: 0.6344 - val_accuracy: 0.7333\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6283 - accuracy: 0.7466 - val_loss: 0.6070 - val_accuracy: 0.7527\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6269 - accuracy: 0.7447 - val_loss: 0.6008 - val_accuracy: 0.7503\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6200 - accuracy: 0.7503 - val_loss: 0.6017 - val_accuracy: 0.7533\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.6048 - accuracy: 0.7551 - val_loss: 0.5973 - val_accuracy: 0.7573\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.6263 - accuracy: 0.7402 - val_loss: 0.6131 - val_accuracy: 0.7450\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5834 - accuracy: 0.7663 - val_loss: 0.5875 - val_accuracy: 0.7627\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5801 - accuracy: 0.7702 - val_loss: 0.5755 - val_accuracy: 0.7653\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 0s 31us/step - loss: 0.5788 - accuracy: 0.7661 - val_loss: 0.6254 - val_accuracy: 0.7430\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.5679 - accuracy: 0.7721 - val_loss: 0.5858 - val_accuracy: 0.7593\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 0s 31us/step - loss: 0.5646 - accuracy: 0.7735 - val_loss: 0.5752 - val_accuracy: 0.7643\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.5696 - accuracy: 0.7710 - val_loss: 0.5751 - val_accuracy: 0.7630\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5702 - accuracy: 0.7730 - val_loss: 0.5684 - val_accuracy: 0.7747\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 0s 28us/step - loss: 0.5553 - accuracy: 0.7754 - val_loss: 0.5557 - val_accuracy: 0.7757\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5528 - accuracy: 0.7772 - val_loss: 0.5576 - val_accuracy: 0.7737\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5258 - accuracy: 0.7887 - val_loss: 0.5551 - val_accuracy: 0.7767\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5269 - accuracy: 0.7907 - val_loss: 0.5635 - val_accuracy: 0.7760\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5341 - accuracy: 0.7847 - val_loss: 0.5640 - val_accuracy: 0.7697\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5508 - accuracy: 0.7772 - val_loss: 0.5446 - val_accuracy: 0.7767\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 0s 29us/step - loss: 0.5317 - accuracy: 0.7859 - val_loss: 0.5372 - val_accuracy: 0.7823\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5246 - accuracy: 0.7943 - val_loss: 0.5567 - val_accuracy: 0.7757\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5294 - accuracy: 0.7849 - val_loss: 0.5815 - val_accuracy: 0.7623\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5233 - accuracy: 0.7912 - val_loss: 0.6193 - val_accuracy: 0.7493\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 0s 38us/step - loss: 0.5176 - accuracy: 0.7936 - val_loss: 0.5732 - val_accuracy: 0.7663\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 0s 38us/step - loss: 0.5229 - accuracy: 0.7895 - val_loss: 0.5531 - val_accuracy: 0.7770\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 0s 33us/step - loss: 0.5076 - accuracy: 0.7962 - val_loss: 0.5498 - val_accuracy: 0.7767\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 0s 30us/step - loss: 0.5107 - accuracy: 0.7973 - val_loss: 0.5778 - val_accuracy: 0.7640\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 0s 27us/step - loss: 0.5138 - accuracy: 0.7951 - val_loss: 0.5329 - val_accuracy: 0.7867\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.4887 - accuracy: 0.8062 - val_loss: 0.5490 - val_accuracy: 0.7840\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.4932 - accuracy: 0.8043 - val_loss: 0.5723 - val_accuracy: 0.7730\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.4925 - accuracy: 0.8038 - val_loss: 0.5517 - val_accuracy: 0.7797\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.4858 - accuracy: 0.8064 - val_loss: 0.5390 - val_accuracy: 0.7917\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 0s 26us/step - loss: 0.4800 - accuracy: 0.8095 - val_loss: 0.5480 - val_accuracy: 0.7850\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 0s 31us/step - loss: 0.4883 - accuracy: 0.8011 - val_loss: 0.5356 - val_accuracy: 0.7840\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 0s 32us/step - loss: 0.4766 - accuracy: 0.8114 - val_loss: 0.5385 - val_accuracy: 0.7877\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 0s 36us/step - loss: 0.4694 - accuracy: 0.8152 - val_loss: 0.5552 - val_accuracy: 0.7820\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 0s 36us/step - loss: 0.4756 - accuracy: 0.8136 - val_loss: 0.5354 - val_accuracy: 0.7883\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 0s 32us/step - loss: 0.4576 - accuracy: 0.8183 - val_loss: 0.5451 - val_accuracy: 0.7910\n",
      "3000/3000 [==============================] - 0s 54us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.518735467116038, 0.7960000038146973]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "do_cifar_model = Sequential()\n",
    "do_cifar_model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "do_cifar_model.add(Dropout(0.2))\n",
    "do_cifar_model.add(Dense(512, activation='relu'))\n",
    "do_cifar_model.add(Dropout(0.2))\n",
    "do_cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "do_cifar_model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "do_cifar_model.fit(partial_x_train, \n",
    "                    partial_y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[EarlyStopping(patience=10)])\n",
    "do_cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "15000/15000 [==============================] - 1s 33us/step - loss: 1.3237 - accuracy: 0.4345\n",
      "Epoch 2/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.8519 - accuracy: 0.6364\n",
      "Epoch 3/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.7727 - accuracy: 0.6789\n",
      "Epoch 4/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.7243 - accuracy: 0.7053\n",
      "Epoch 5/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.7058 - accuracy: 0.7087\n",
      "Epoch 6/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6895 - accuracy: 0.7153\n",
      "Epoch 7/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6626 - accuracy: 0.7315\n",
      "Epoch 8/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6416 - accuracy: 0.7427\n",
      "Epoch 9/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6255 - accuracy: 0.7457\n",
      "Epoch 10/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.6128 - accuracy: 0.7503\n",
      "Epoch 11/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.6022 - accuracy: 0.7570\n",
      "Epoch 12/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5881 - accuracy: 0.7639\n",
      "Epoch 13/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5880 - accuracy: 0.7601\n",
      "Epoch 14/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5835 - accuracy: 0.7621\n",
      "Epoch 15/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5834 - accuracy: 0.7648\n",
      "Epoch 16/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5644 - accuracy: 0.7765\n",
      "Epoch 17/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5619 - accuracy: 0.7747\n",
      "Epoch 18/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5484 - accuracy: 0.7765\n",
      "Epoch 19/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5655 - accuracy: 0.7726\n",
      "Epoch 20/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5400 - accuracy: 0.7822\n",
      "Epoch 21/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5316 - accuracy: 0.7877\n",
      "Epoch 22/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5389 - accuracy: 0.7868\n",
      "Epoch 23/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5338 - accuracy: 0.7861\n",
      "Epoch 24/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5272 - accuracy: 0.7896\n",
      "Epoch 25/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5274 - accuracy: 0.7905\n",
      "Epoch 26/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5249 - accuracy: 0.7917\n",
      "Epoch 27/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5231 - accuracy: 0.7904\n",
      "Epoch 28/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5167 - accuracy: 0.7933\n",
      "Epoch 29/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.5155 - accuracy: 0.7948\n",
      "Epoch 30/36\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.5154 - accuracy: 0.7935\n",
      "Epoch 31/36\n",
      "15000/15000 [==============================] - 0s 26us/step - loss: 0.5090 - accuracy: 0.7987\n",
      "Epoch 32/36\n",
      "15000/15000 [==============================] - 0s 32us/step - loss: 0.4947 - accuracy: 0.8032\n",
      "Epoch 33/36\n",
      "15000/15000 [==============================] - 0s 31us/step - loss: 0.4908 - accuracy: 0.8043\n",
      "Epoch 34/36\n",
      "15000/15000 [==============================] - 0s 32us/step - loss: 0.4844 - accuracy: 0.8073\n",
      "Epoch 35/36\n",
      "15000/15000 [==============================] - 0s 27us/step - loss: 0.4945 - accuracy: 0.8023\n",
      "Epoch 36/36\n",
      "15000/15000 [==============================] - 0s 25us/step - loss: 0.4822 - accuracy: 0.8076\n",
      "3000/3000 [==============================] - 0s 82us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5020982257525126, 0.8026666641235352]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "do_cifar_model = Sequential()\n",
    "do_cifar_model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))\n",
    "do_cifar_model.add(Dropout(0.2))\n",
    "do_cifar_model.add(Dense(512, activation='relu'))\n",
    "do_cifar_model.add(Dropout(0.2))\n",
    "do_cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "do_cifar_model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "do_cifar_model.fit(x_train, \n",
    "                    y_train,\n",
    "                    epochs=36,\n",
    "                    batch_size=512)\n",
    "do_cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/51\n",
      "15000/15000 [==============================] - 0s 28us/step - loss: 0.8780 - accuracy: 0.6215\n",
      "Epoch 2/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.7339 - accuracy: 0.7084\n",
      "Epoch 3/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6824 - accuracy: 0.7266\n",
      "Epoch 4/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6513 - accuracy: 0.7427\n",
      "Epoch 5/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6200 - accuracy: 0.7561\n",
      "Epoch 6/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.5963 - accuracy: 0.7653\n",
      "Epoch 7/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5751 - accuracy: 0.7747\n",
      "Epoch 8/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5554 - accuracy: 0.7823\n",
      "Epoch 9/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5457 - accuracy: 0.7843\n",
      "Epoch 10/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5279 - accuracy: 0.7937\n",
      "Epoch 11/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.5108 - accuracy: 0.8011\n",
      "Epoch 12/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.5058 - accuracy: 0.7989\n",
      "Epoch 13/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4912 - accuracy: 0.8092\n",
      "Epoch 14/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4779 - accuracy: 0.8141\n",
      "Epoch 15/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4749 - accuracy: 0.8145\n",
      "Epoch 16/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4611 - accuracy: 0.8204\n",
      "Epoch 17/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4487 - accuracy: 0.8272\n",
      "Epoch 18/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4434 - accuracy: 0.8267\n",
      "Epoch 19/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4352 - accuracy: 0.8275\n",
      "Epoch 20/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4220 - accuracy: 0.8363\n",
      "Epoch 21/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4260 - accuracy: 0.8337\n",
      "Epoch 22/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4128 - accuracy: 0.8399\n",
      "Epoch 23/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4055 - accuracy: 0.8429\n",
      "Epoch 24/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3870 - accuracy: 0.8543\n",
      "Epoch 25/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3783 - accuracy: 0.8553\n",
      "Epoch 26/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3702 - accuracy: 0.8591\n",
      "Epoch 27/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3641 - accuracy: 0.8632\n",
      "Epoch 28/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3586 - accuracy: 0.8626\n",
      "Epoch 29/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3589 - accuracy: 0.8598\n",
      "Epoch 30/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3461 - accuracy: 0.8698\n",
      "Epoch 31/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3367 - accuracy: 0.8720\n",
      "Epoch 32/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3339 - accuracy: 0.8751\n",
      "Epoch 33/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3368 - accuracy: 0.8713\n",
      "Epoch 34/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3203 - accuracy: 0.8817\n",
      "Epoch 35/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3217 - accuracy: 0.8779\n",
      "Epoch 36/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3133 - accuracy: 0.8808\n",
      "Epoch 37/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3082 - accuracy: 0.8869\n",
      "Epoch 38/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3046 - accuracy: 0.8869\n",
      "Epoch 39/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2919 - accuracy: 0.8901\n",
      "Epoch 40/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2832 - accuracy: 0.8973\n",
      "Epoch 41/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2790 - accuracy: 0.8991\n",
      "Epoch 42/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2922 - accuracy: 0.8887\n",
      "Epoch 43/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2747 - accuracy: 0.8976\n",
      "Epoch 44/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2608 - accuracy: 0.9051\n",
      "Epoch 45/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2621 - accuracy: 0.9061\n",
      "Epoch 46/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2756 - accuracy: 0.8986\n",
      "Epoch 47/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2538 - accuracy: 0.9099\n",
      "Epoch 48/51\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2481 - accuracy: 0.9126\n",
      "Epoch 49/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2500 - accuracy: 0.9091\n",
      "Epoch 50/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2436 - accuracy: 0.9121\n",
      "Epoch 51/51\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2250 - accuracy: 0.9209\n",
      "3000/3000 [==============================] - 0s 52us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44081248982747395, 0.8336666822433472]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "cifar_model = Sequential()\n",
    "cifar_model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "cifar_model.add(Dense(512, activation='relu'))\n",
    "cifar_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "cifar_model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "cifar_history = cifar_model.fit(x_train, \n",
    "                                y_train,\n",
    "                                epochs=51,\n",
    "                                batch_size=512)\n",
    "cifar_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_model.save('keras_cifar10_trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 0s 70us/step\n",
      "Test loss 0.44081248982747395\n",
      "Test accuracy 0.8336666822433472\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('keras_cifar10_trained_model.h5')\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss', scores[0])\n",
    "print('Test accuracy', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
