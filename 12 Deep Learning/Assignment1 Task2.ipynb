{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1 \n",
    "### Christopher Hong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spambase data set\n",
    "spambase_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
    "col_names = ['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d', 'word_freq_our',\\\n",
    "             'word_freq_over', 'word_freq_remove', 'word_freq_internet', 'word_freq_order', 'word_freq_mail',\\\n",
    "             'word_freq_receive', 'word_freq_will', 'word_freq_people', 'word_freq_report', 'word_freq_addresses',\\\n",
    "             'word_freq_free', 'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\\\n",
    "             'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money', 'word_freq_hp',\\\n",
    "             'word_freq_hpl', 'word_freq_george', 'word_freq_650', 'word_freq_lab', 'word_freq_labs',\\\n",
    "             'word_freq_telnet', 'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\\\n",
    "             'word_freq_technology', 'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\\\n",
    "             'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project', 'word_freq_re',\\\n",
    "             'word_freq_edu', 'word_freq_table', 'word_freq_conference', 'char_freq_;:', 'char_freq_(:',\\\n",
    "             'char_freq_[:', 'char_freq_!:', 'char_freq_$:', 'char_freq_#:', 'capital_run_length_average',\\\n",
    "             'capital_run_length_longest', 'capital_run_length_total', 'class']\n",
    "spambase = pd.read_csv(spambase_url, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;:  char_freq_(:  \\\n",
       "0             0.00            0.00  ...          0.00         0.000   \n",
       "1             0.00            0.94  ...          0.00         0.132   \n",
       "2             0.64            0.25  ...          0.01         0.143   \n",
       "3             0.31            0.63  ...          0.00         0.137   \n",
       "4             0.31            0.63  ...          0.00         0.135   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.778         0.000         0.000   \n",
       "1           0.0         0.372         0.180         0.048   \n",
       "2           0.0         0.276         0.184         0.010   \n",
       "3           0.0         0.137         0.000         0.000   \n",
       "4           0.0         0.135         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "4596            0.31                0.0           0.62           0.0   \n",
       "4597            0.00                0.0           0.00           0.0   \n",
       "4598            0.30                0.0           0.30           0.0   \n",
       "4599            0.96                0.0           0.00           0.0   \n",
       "4600            0.00                0.0           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "4596           0.00            0.31               0.0                 0.0   \n",
       "4597           0.00            0.00               0.0                 0.0   \n",
       "4598           0.00            0.00               0.0                 0.0   \n",
       "4599           0.32            0.00               0.0                 0.0   \n",
       "4600           0.00            0.00               0.0                 0.0   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  char_freq_;:  char_freq_(:  \\\n",
       "4596              0.0             0.0  ...         0.000         0.232   \n",
       "4597              0.0             0.0  ...         0.000         0.000   \n",
       "4598              0.0             0.0  ...         0.102         0.718   \n",
       "4599              0.0             0.0  ...         0.000         0.057   \n",
       "4600              0.0             0.0  ...         0.000         0.000   \n",
       "\n",
       "      char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "4596           0.0         0.000           0.0           0.0   \n",
       "4597           0.0         0.353           0.0           0.0   \n",
       "4598           0.0         0.000           0.0           0.0   \n",
       "4599           0.0         0.000           0.0           0.0   \n",
       "4600           0.0         0.125           0.0           0.0   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  class  \n",
       "4596                        88      0  \n",
       "4597                        14      0  \n",
       "4598                       118      0  \n",
       "4599                        78      0  \n",
       "4600                        40      0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4601.000000        4601.000000    4601.000000   4601.000000   \n",
       "mean         0.104553           0.213015       0.280656      0.065425   \n",
       "std          0.305358           1.290575       0.504143      1.395151   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4601.000000     4601.000000       4601.000000         4601.000000   \n",
       "mean        0.312223        0.095901          0.114208            0.105295   \n",
       "std         0.672513        0.273824          0.391441            0.401071   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.380000        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  char_freq_;:  char_freq_(:  \\\n",
       "count      4601.000000     4601.000000  ...   4601.000000   4601.000000   \n",
       "mean          0.090067        0.239413  ...      0.038575      0.139030   \n",
       "std           0.278616        0.644755  ...      0.243471      0.270355   \n",
       "min           0.000000        0.000000  ...      0.000000      0.000000   \n",
       "25%           0.000000        0.000000  ...      0.000000      0.000000   \n",
       "50%           0.000000        0.000000  ...      0.000000      0.065000   \n",
       "75%           0.000000        0.160000  ...      0.000000      0.188000   \n",
       "max           5.260000       18.180000  ...      4.385000      9.752000   \n",
       "\n",
       "       char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "count   4601.000000   4601.000000   4601.000000   4601.000000   \n",
       "mean       0.016976      0.269071      0.075811      0.044238   \n",
       "std        0.109394      0.815672      0.245882      0.429342   \n",
       "min        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.315000      0.052000      0.000000   \n",
       "max        4.081000     32.478000      6.003000     19.829000   \n",
       "\n",
       "       capital_run_length_average  capital_run_length_longest  \\\n",
       "count                 4601.000000                 4601.000000   \n",
       "mean                     5.191515                   52.172789   \n",
       "std                     31.729449                  194.891310   \n",
       "min                      1.000000                    1.000000   \n",
       "25%                      1.588000                    6.000000   \n",
       "50%                      2.276000                   15.000000   \n",
       "75%                      3.706000                   43.000000   \n",
       "max                   1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total        class  \n",
       "count               4601.000000  4601.000000  \n",
       "mean                 283.289285     0.394045  \n",
       "std                  606.347851     0.488698  \n",
       "min                    1.000000     0.000000  \n",
       "25%                   35.000000     0.000000  \n",
       "50%                   95.000000     0.000000  \n",
       "75%                  266.000000     1.000000  \n",
       "max                15841.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spambase.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4601 non-null   float64\n",
      " 1   word_freq_address           4601 non-null   float64\n",
      " 2   word_freq_all               4601 non-null   float64\n",
      " 3   word_freq_3d                4601 non-null   float64\n",
      " 4   word_freq_our               4601 non-null   float64\n",
      " 5   word_freq_over              4601 non-null   float64\n",
      " 6   word_freq_remove            4601 non-null   float64\n",
      " 7   word_freq_internet          4601 non-null   float64\n",
      " 8   word_freq_order             4601 non-null   float64\n",
      " 9   word_freq_mail              4601 non-null   float64\n",
      " 10  word_freq_receive           4601 non-null   float64\n",
      " 11  word_freq_will              4601 non-null   float64\n",
      " 12  word_freq_people            4601 non-null   float64\n",
      " 13  word_freq_report            4601 non-null   float64\n",
      " 14  word_freq_addresses         4601 non-null   float64\n",
      " 15  word_freq_free              4601 non-null   float64\n",
      " 16  word_freq_business          4601 non-null   float64\n",
      " 17  word_freq_email             4601 non-null   float64\n",
      " 18  word_freq_you               4601 non-null   float64\n",
      " 19  word_freq_credit            4601 non-null   float64\n",
      " 20  word_freq_your              4601 non-null   float64\n",
      " 21  word_freq_font              4601 non-null   float64\n",
      " 22  word_freq_000               4601 non-null   float64\n",
      " 23  word_freq_money             4601 non-null   float64\n",
      " 24  word_freq_hp                4601 non-null   float64\n",
      " 25  word_freq_hpl               4601 non-null   float64\n",
      " 26  word_freq_george            4601 non-null   float64\n",
      " 27  word_freq_650               4601 non-null   float64\n",
      " 28  word_freq_lab               4601 non-null   float64\n",
      " 29  word_freq_labs              4601 non-null   float64\n",
      " 30  word_freq_telnet            4601 non-null   float64\n",
      " 31  word_freq_857               4601 non-null   float64\n",
      " 32  word_freq_data              4601 non-null   float64\n",
      " 33  word_freq_415               4601 non-null   float64\n",
      " 34  word_freq_85                4601 non-null   float64\n",
      " 35  word_freq_technology        4601 non-null   float64\n",
      " 36  word_freq_1999              4601 non-null   float64\n",
      " 37  word_freq_parts             4601 non-null   float64\n",
      " 38  word_freq_pm                4601 non-null   float64\n",
      " 39  word_freq_direct            4601 non-null   float64\n",
      " 40  word_freq_cs                4601 non-null   float64\n",
      " 41  word_freq_meeting           4601 non-null   float64\n",
      " 42  word_freq_original          4601 non-null   float64\n",
      " 43  word_freq_project           4601 non-null   float64\n",
      " 44  word_freq_re                4601 non-null   float64\n",
      " 45  word_freq_edu               4601 non-null   float64\n",
      " 46  word_freq_table             4601 non-null   float64\n",
      " 47  word_freq_conference        4601 non-null   float64\n",
      " 48  char_freq_;:                4601 non-null   float64\n",
      " 49  char_freq_(:                4601 non-null   float64\n",
      " 50  char_freq_[:                4601 non-null   float64\n",
      " 51  char_freq_!:                4601 non-null   float64\n",
      " 52  char_freq_$:                4601 non-null   float64\n",
      " 53  char_freq_#:                4601 non-null   float64\n",
      " 54  capital_run_length_average  4601 non-null   float64\n",
      " 55  capital_run_length_longest  4601 non-null   int64  \n",
      " 56  capital_run_length_total    4601 non-null   int64  \n",
      " 57  class                       4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "spambase.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;:                  0\n",
      "char_freq_(:                  0\n",
      "char_freq_[:                  0\n",
      "char_freq_!:                  0\n",
      "char_freq_$:                  0\n",
      "char_freq_#:                  0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "class                         0\n",
      "dtype: int64\n",
      "word_freq_make                0\n",
      "word_freq_address             0\n",
      "word_freq_all                 0\n",
      "word_freq_3d                  0\n",
      "word_freq_our                 0\n",
      "word_freq_over                0\n",
      "word_freq_remove              0\n",
      "word_freq_internet            0\n",
      "word_freq_order               0\n",
      "word_freq_mail                0\n",
      "word_freq_receive             0\n",
      "word_freq_will                0\n",
      "word_freq_people              0\n",
      "word_freq_report              0\n",
      "word_freq_addresses           0\n",
      "word_freq_free                0\n",
      "word_freq_business            0\n",
      "word_freq_email               0\n",
      "word_freq_you                 0\n",
      "word_freq_credit              0\n",
      "word_freq_your                0\n",
      "word_freq_font                0\n",
      "word_freq_000                 0\n",
      "word_freq_money               0\n",
      "word_freq_hp                  0\n",
      "word_freq_hpl                 0\n",
      "word_freq_george              0\n",
      "word_freq_650                 0\n",
      "word_freq_lab                 0\n",
      "word_freq_labs                0\n",
      "word_freq_telnet              0\n",
      "word_freq_857                 0\n",
      "word_freq_data                0\n",
      "word_freq_415                 0\n",
      "word_freq_85                  0\n",
      "word_freq_technology          0\n",
      "word_freq_1999                0\n",
      "word_freq_parts               0\n",
      "word_freq_pm                  0\n",
      "word_freq_direct              0\n",
      "word_freq_cs                  0\n",
      "word_freq_meeting             0\n",
      "word_freq_original            0\n",
      "word_freq_project             0\n",
      "word_freq_re                  0\n",
      "word_freq_edu                 0\n",
      "word_freq_table               0\n",
      "word_freq_conference          0\n",
      "char_freq_;:                  0\n",
      "char_freq_(:                  0\n",
      "char_freq_[:                  0\n",
      "char_freq_!:                  0\n",
      "char_freq_$:                  0\n",
      "char_freq_#:                  0\n",
      "capital_run_length_average    0\n",
      "capital_run_length_longest    0\n",
      "capital_run_length_total      0\n",
      "class                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing values\n",
    "print('?' in spambase)\n",
    "print('N/A' in spambase)\n",
    "print(np.nan in spambase)\n",
    "print('NaN' in spambase)\n",
    "print(pd.isna(spambase).sum())\n",
    "print(pd.isnull(spambase).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del spambase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading spam email dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spam_data():\n",
    "    \"\"\"\n",
    "    Load the spam email data from the UCI repository.\n",
    "    Return a training and testing subsets.\n",
    "    \"\"\"\n",
    "    \n",
    "    spambase_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\n",
    "    \n",
    "    # Load the data into DataFrame\n",
    "    spambase = pd.read_csv(spambase_url, header=None)\n",
    "    \n",
    "    # Split the data into features and class\n",
    "    X = spambase.iloc[:,:-1].astype('float32')\n",
    "    y = spambase.iloc[:,-1].astype('float32')\n",
    "    \n",
    "    # Normalize the data\n",
    "    X.iloc[:,:] = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Transform the data into ndarray, split it into 80/20 with stratify\n",
    "    np.random.seed(0)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X.values, \n",
    "                                                        y.values, \n",
    "                                                        test_size=0.2, \n",
    "                                                        stratify=y.values, \n",
    "                                                        random_state=0)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = load_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3680, 57)\n",
      "3680 train_samples\n",
      "921 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train_samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting aside a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partial_x_train, x_val, partial_y_train, y_val = train_test_split(x_train, \n",
    "                                                                  y_train, \n",
    "                                                                  test_size=0.25, \n",
    "                                                                  stratify=y_train, \n",
    "                                                                  random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2760 train_samples\n",
      "920 validation samples\n",
      "921 test samples\n"
     ]
    }
   ],
   "source": [
    "print(partial_x_train.shape[0], 'train_samples')\n",
    "print(x_val.shape[0], 'validation samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_model = keras.models.Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(57,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 66us/step - loss: 0.6459 - accuracy: 0.6736 - val_loss: 0.5706 - val_accuracy: 0.7717\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.5422 - accuracy: 0.7895 - val_loss: 0.4921 - val_accuracy: 0.8304\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.4612 - accuracy: 0.8446 - val_loss: 0.4282 - val_accuracy: 0.8598\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.3941 - accuracy: 0.8732 - val_loss: 0.3771 - val_accuracy: 0.8848\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.3405 - accuracy: 0.8888 - val_loss: 0.3384 - val_accuracy: 0.8902\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.3007 - accuracy: 0.8971 - val_loss: 0.3118 - val_accuracy: 0.8989\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.2721 - accuracy: 0.9062 - val_loss: 0.2922 - val_accuracy: 0.9033\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.2519 - accuracy: 0.9116 - val_loss: 0.2775 - val_accuracy: 0.9120\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.2349 - accuracy: 0.9203 - val_loss: 0.2656 - val_accuracy: 0.9120\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.2216 - accuracy: 0.9250 - val_loss: 0.2557 - val_accuracy: 0.9109\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.2105 - accuracy: 0.9272 - val_loss: 0.2464 - val_accuracy: 0.9141\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.2009 - accuracy: 0.9319 - val_loss: 0.2386 - val_accuracy: 0.9174\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.1928 - accuracy: 0.9348 - val_loss: 0.2326 - val_accuracy: 0.9239\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.1861 - accuracy: 0.9380 - val_loss: 0.2267 - val_accuracy: 0.9261\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1796 - accuracy: 0.9388 - val_loss: 0.2217 - val_accuracy: 0.9283\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1744 - accuracy: 0.9413 - val_loss: 0.2163 - val_accuracy: 0.9272\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1694 - accuracy: 0.9428 - val_loss: 0.2134 - val_accuracy: 0.9293\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1648 - accuracy: 0.9428 - val_loss: 0.2108 - val_accuracy: 0.9293\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1613 - accuracy: 0.9420 - val_loss: 0.2086 - val_accuracy: 0.9304\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1578 - accuracy: 0.9438 - val_loss: 0.2051 - val_accuracy: 0.9304\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.1539 - accuracy: 0.9453 - val_loss: 0.2041 - val_accuracy: 0.9304\n",
      "Epoch 22/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1505 - accuracy: 0.9467 - val_loss: 0.2035 - val_accuracy: 0.9293\n",
      "Epoch 23/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1477 - accuracy: 0.9475 - val_loss: 0.2014 - val_accuracy: 0.9304\n",
      "Epoch 24/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1446 - accuracy: 0.9471 - val_loss: 0.1988 - val_accuracy: 0.9272\n",
      "Epoch 25/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1422 - accuracy: 0.9482 - val_loss: 0.1977 - val_accuracy: 0.9304\n",
      "Epoch 26/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1390 - accuracy: 0.9482 - val_loss: 0.1965 - val_accuracy: 0.9283\n",
      "Epoch 27/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1370 - accuracy: 0.9486 - val_loss: 0.1949 - val_accuracy: 0.9272\n",
      "Epoch 28/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1340 - accuracy: 0.9504 - val_loss: 0.1936 - val_accuracy: 0.9272\n",
      "Epoch 29/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1314 - accuracy: 0.9500 - val_loss: 0.1925 - val_accuracy: 0.9272\n",
      "Epoch 30/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1290 - accuracy: 0.9518 - val_loss: 0.1911 - val_accuracy: 0.9293\n",
      "Epoch 31/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1264 - accuracy: 0.9536 - val_loss: 0.1900 - val_accuracy: 0.9272\n",
      "Epoch 32/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1240 - accuracy: 0.9540 - val_loss: 0.1901 - val_accuracy: 0.9293\n",
      "Epoch 33/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1219 - accuracy: 0.9543 - val_loss: 0.1884 - val_accuracy: 0.9261\n",
      "Epoch 34/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1194 - accuracy: 0.9558 - val_loss: 0.1876 - val_accuracy: 0.9283\n",
      "Epoch 35/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1171 - accuracy: 0.9562 - val_loss: 0.1858 - val_accuracy: 0.9261\n",
      "Epoch 36/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1150 - accuracy: 0.9591 - val_loss: 0.1853 - val_accuracy: 0.9239\n",
      "Epoch 37/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1128 - accuracy: 0.9598 - val_loss: 0.1841 - val_accuracy: 0.9250\n",
      "Epoch 38/100\n",
      "2760/2760 [==============================] - 0s 17us/step - loss: 0.1107 - accuracy: 0.9598 - val_loss: 0.1843 - val_accuracy: 0.9261\n",
      "Epoch 39/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1084 - accuracy: 0.9605 - val_loss: 0.1853 - val_accuracy: 0.9293\n",
      "Epoch 40/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1077 - accuracy: 0.9616 - val_loss: 0.1844 - val_accuracy: 0.9293\n",
      "Epoch 41/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.1045 - accuracy: 0.9623 - val_loss: 0.1824 - val_accuracy: 0.9261\n",
      "Epoch 42/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.1035 - accuracy: 0.9627 - val_loss: 0.1819 - val_accuracy: 0.9261\n",
      "Epoch 43/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.1030 - accuracy: 0.9641 - val_loss: 0.1865 - val_accuracy: 0.9261\n",
      "Epoch 44/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.1003 - accuracy: 0.9645 - val_loss: 0.1854 - val_accuracy: 0.9326\n",
      "Epoch 45/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0983 - accuracy: 0.9649 - val_loss: 0.1845 - val_accuracy: 0.9283\n",
      "Epoch 46/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0971 - accuracy: 0.9649 - val_loss: 0.1844 - val_accuracy: 0.9272\n",
      "Epoch 47/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.1821 - val_accuracy: 0.9337\n",
      "Epoch 48/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0937 - accuracy: 0.9649 - val_loss: 0.1833 - val_accuracy: 0.9272\n",
      "Epoch 49/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0913 - accuracy: 0.9681 - val_loss: 0.1832 - val_accuracy: 0.9283\n",
      "Epoch 50/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0891 - accuracy: 0.9692 - val_loss: 0.1833 - val_accuracy: 0.9315\n",
      "Epoch 51/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0883 - accuracy: 0.9692 - val_loss: 0.1841 - val_accuracy: 0.9304\n",
      "Epoch 52/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0869 - accuracy: 0.9699 - val_loss: 0.1838 - val_accuracy: 0.9315\n",
      "Epoch 53/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0849 - accuracy: 0.9696 - val_loss: 0.1837 - val_accuracy: 0.9293\n",
      "Epoch 54/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0841 - accuracy: 0.9699 - val_loss: 0.1846 - val_accuracy: 0.9315\n",
      "Epoch 55/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0823 - accuracy: 0.9710 - val_loss: 0.1853 - val_accuracy: 0.9326\n",
      "Epoch 56/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0815 - accuracy: 0.9725 - val_loss: 0.1854 - val_accuracy: 0.9348\n",
      "Epoch 57/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0798 - accuracy: 0.9717 - val_loss: 0.1857 - val_accuracy: 0.9337\n",
      "Epoch 58/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0784 - accuracy: 0.9725 - val_loss: 0.1861 - val_accuracy: 0.9348\n",
      "Epoch 59/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0780 - accuracy: 0.9725 - val_loss: 0.1870 - val_accuracy: 0.9348\n",
      "Epoch 60/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.1892 - val_accuracy: 0.9337\n",
      "Epoch 61/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0753 - accuracy: 0.9732 - val_loss: 0.1894 - val_accuracy: 0.9337\n",
      "Epoch 62/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0749 - accuracy: 0.9732 - val_loss: 0.1881 - val_accuracy: 0.9348\n",
      "Epoch 63/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0727 - accuracy: 0.9732 - val_loss: 0.1881 - val_accuracy: 0.9348\n",
      "Epoch 64/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.0715 - accuracy: 0.9750 - val_loss: 0.1905 - val_accuracy: 0.9348\n",
      "Epoch 65/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0706 - accuracy: 0.9772 - val_loss: 0.1929 - val_accuracy: 0.9370\n",
      "Epoch 66/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0695 - accuracy: 0.9775 - val_loss: 0.1928 - val_accuracy: 0.9359\n",
      "Epoch 67/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.1925 - val_accuracy: 0.9348\n",
      "Epoch 68/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0671 - accuracy: 0.9768 - val_loss: 0.1920 - val_accuracy: 0.9348\n",
      "Epoch 69/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.1918 - val_accuracy: 0.9380\n",
      "Epoch 70/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0658 - accuracy: 0.9783 - val_loss: 0.1937 - val_accuracy: 0.9359\n",
      "Epoch 71/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0671 - accuracy: 0.9786 - val_loss: 0.1956 - val_accuracy: 0.9348\n",
      "Epoch 72/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0644 - accuracy: 0.9812 - val_loss: 0.2010 - val_accuracy: 0.9337\n",
      "Epoch 73/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.1988 - val_accuracy: 0.9348\n",
      "Epoch 74/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.1988 - val_accuracy: 0.9315\n",
      "Epoch 75/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0606 - accuracy: 0.9822 - val_loss: 0.1990 - val_accuracy: 0.9315\n",
      "Epoch 76/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0603 - accuracy: 0.9819 - val_loss: 0.1997 - val_accuracy: 0.9348\n",
      "Epoch 77/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0591 - accuracy: 0.9819 - val_loss: 0.1998 - val_accuracy: 0.9391\n",
      "Epoch 78/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.2007 - val_accuracy: 0.9348\n",
      "Epoch 79/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0573 - accuracy: 0.9826 - val_loss: 0.2006 - val_accuracy: 0.9348\n",
      "Epoch 80/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.0569 - accuracy: 0.9819 - val_loss: 0.2011 - val_accuracy: 0.9337\n",
      "Epoch 81/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.0565 - accuracy: 0.9841 - val_loss: 0.2037 - val_accuracy: 0.9315\n",
      "Epoch 82/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.0559 - accuracy: 0.9848 - val_loss: 0.2037 - val_accuracy: 0.9348\n",
      "Epoch 83/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0542 - accuracy: 0.9859 - val_loss: 0.2069 - val_accuracy: 0.9315\n",
      "Epoch 84/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.0535 - accuracy: 0.9844 - val_loss: 0.2083 - val_accuracy: 0.9326\n",
      "Epoch 85/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.0529 - accuracy: 0.9851 - val_loss: 0.2084 - val_accuracy: 0.9326\n",
      "Epoch 86/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.2088 - val_accuracy: 0.9326\n",
      "Epoch 87/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0511 - accuracy: 0.9851 - val_loss: 0.2102 - val_accuracy: 0.9326\n",
      "Epoch 88/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0507 - accuracy: 0.9862 - val_loss: 0.2104 - val_accuracy: 0.9326\n",
      "Epoch 89/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0499 - accuracy: 0.9862 - val_loss: 0.2114 - val_accuracy: 0.9315\n",
      "Epoch 90/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0492 - accuracy: 0.9851 - val_loss: 0.2118 - val_accuracy: 0.9326\n",
      "Epoch 91/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0484 - accuracy: 0.9862 - val_loss: 0.2135 - val_accuracy: 0.9315\n",
      "Epoch 92/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0481 - accuracy: 0.9855 - val_loss: 0.2156 - val_accuracy: 0.9293\n",
      "Epoch 93/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.2167 - val_accuracy: 0.9337\n",
      "Epoch 94/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0467 - accuracy: 0.9873 - val_loss: 0.2185 - val_accuracy: 0.9304\n",
      "Epoch 95/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.0462 - accuracy: 0.9866 - val_loss: 0.2179 - val_accuracy: 0.9315\n",
      "Epoch 96/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0455 - accuracy: 0.9866 - val_loss: 0.2185 - val_accuracy: 0.9326\n",
      "Epoch 97/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0449 - accuracy: 0.9862 - val_loss: 0.2206 - val_accuracy: 0.9304\n",
      "Epoch 98/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.2204 - val_accuracy: 0.9315\n",
      "Epoch 99/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0444 - accuracy: 0.9866 - val_loss: 0.2227 - val_accuracy: 0.9304\n",
      "Epoch 100/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.2231 - val_accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "spam_history = spam_model.fit(partial_x_train,\n",
    "                              partial_y_train,\n",
    "                              epochs=100,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the training and validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_performance(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss)+1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show();\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model_performance(spam_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 51us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2559755987343131, 0.9391965270042419]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find out the best # of epochs using EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 67us/step - loss: 0.6329 - accuracy: 0.6623 - val_loss: 0.5640 - val_accuracy: 0.7913\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.5154 - accuracy: 0.8127 - val_loss: 0.4724 - val_accuracy: 0.8391\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 20us/step - loss: 0.4293 - accuracy: 0.8551 - val_loss: 0.4045 - val_accuracy: 0.8739\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.3648 - accuracy: 0.8815 - val_loss: 0.3561 - val_accuracy: 0.8946\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 20us/step - loss: 0.3191 - accuracy: 0.8989 - val_loss: 0.3214 - val_accuracy: 0.9043\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.2867 - accuracy: 0.9069 - val_loss: 0.2970 - val_accuracy: 0.9087\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.2651 - accuracy: 0.9112 - val_loss: 0.2806 - val_accuracy: 0.9174\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.2483 - accuracy: 0.9156 - val_loss: 0.2677 - val_accuracy: 0.9174\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.2348 - accuracy: 0.9203 - val_loss: 0.2576 - val_accuracy: 0.9207\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.2238 - accuracy: 0.9257 - val_loss: 0.2502 - val_accuracy: 0.9217\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.2143 - accuracy: 0.9275 - val_loss: 0.2422 - val_accuracy: 0.9217\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.2057 - accuracy: 0.9297 - val_loss: 0.2363 - val_accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.1985 - accuracy: 0.9315 - val_loss: 0.2310 - val_accuracy: 0.9261\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1920 - accuracy: 0.9344 - val_loss: 0.2269 - val_accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.1860 - accuracy: 0.9366 - val_loss: 0.2223 - val_accuracy: 0.9272\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1799 - accuracy: 0.9384 - val_loss: 0.2193 - val_accuracy: 0.9304\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.1753 - accuracy: 0.9377 - val_loss: 0.2165 - val_accuracy: 0.9315\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1701 - accuracy: 0.9395 - val_loss: 0.2127 - val_accuracy: 0.9304\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1654 - accuracy: 0.9409 - val_loss: 0.2097 - val_accuracy: 0.9293\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.1612 - accuracy: 0.9417 - val_loss: 0.2070 - val_accuracy: 0.9315\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.1571 - accuracy: 0.9424 - val_loss: 0.2036 - val_accuracy: 0.9315\n",
      "Epoch 22/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.1533 - accuracy: 0.9446 - val_loss: 0.2013 - val_accuracy: 0.9304\n",
      "Epoch 23/100\n",
      "2760/2760 [==============================] - 0s 16us/step - loss: 0.1493 - accuracy: 0.9478 - val_loss: 0.1991 - val_accuracy: 0.9293\n",
      "Epoch 24/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1463 - accuracy: 0.9500 - val_loss: 0.1973 - val_accuracy: 0.9293\n",
      "Epoch 25/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1427 - accuracy: 0.9507 - val_loss: 0.1953 - val_accuracy: 0.9293\n",
      "Epoch 26/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1395 - accuracy: 0.9511 - val_loss: 0.1935 - val_accuracy: 0.9337\n",
      "Epoch 27/100\n",
      "2760/2760 [==============================] - 0s 20us/step - loss: 0.1366 - accuracy: 0.9514 - val_loss: 0.1911 - val_accuracy: 0.9326\n",
      "Epoch 28/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1334 - accuracy: 0.9525 - val_loss: 0.1893 - val_accuracy: 0.9261\n",
      "Epoch 29/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.1310 - accuracy: 0.9533 - val_loss: 0.1882 - val_accuracy: 0.9326\n",
      "Epoch 30/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1283 - accuracy: 0.9533 - val_loss: 0.1884 - val_accuracy: 0.9337\n",
      "Epoch 31/100\n",
      "2760/2760 [==============================] - 0s 18us/step - loss: 0.1254 - accuracy: 0.9536 - val_loss: 0.1863 - val_accuracy: 0.9293\n",
      "Epoch 32/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.1229 - accuracy: 0.9543 - val_loss: 0.1836 - val_accuracy: 0.9315\n",
      "Epoch 33/100\n",
      "2760/2760 [==============================] - 0s 13us/step - loss: 0.1205 - accuracy: 0.9558 - val_loss: 0.1824 - val_accuracy: 0.9304\n",
      "Epoch 34/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.1178 - accuracy: 0.9565 - val_loss: 0.1823 - val_accuracy: 0.9348\n",
      "Epoch 35/100\n",
      "2760/2760 [==============================] - 0s 19us/step - loss: 0.1153 - accuracy: 0.9576 - val_loss: 0.1835 - val_accuracy: 0.9359\n",
      "Epoch 36/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.1132 - accuracy: 0.9587 - val_loss: 0.1821 - val_accuracy: 0.9326\n",
      "Epoch 37/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.1109 - accuracy: 0.9594 - val_loss: 0.1808 - val_accuracy: 0.9315\n",
      "Epoch 38/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1091 - accuracy: 0.9616 - val_loss: 0.1802 - val_accuracy: 0.9326\n",
      "Epoch 39/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1064 - accuracy: 0.9612 - val_loss: 0.1799 - val_accuracy: 0.9304\n",
      "Epoch 40/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1045 - accuracy: 0.9620 - val_loss: 0.1791 - val_accuracy: 0.9304\n",
      "Epoch 41/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.1026 - accuracy: 0.9638 - val_loss: 0.1792 - val_accuracy: 0.9293\n",
      "Epoch 42/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.1005 - accuracy: 0.9645 - val_loss: 0.1786 - val_accuracy: 0.9337\n",
      "Epoch 43/100\n",
      "2760/2760 [==============================] - 0s 15us/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.1791 - val_accuracy: 0.9337\n",
      "Epoch 44/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0977 - accuracy: 0.9645 - val_loss: 0.1792 - val_accuracy: 0.9326\n",
      "Epoch 45/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0956 - accuracy: 0.9678 - val_loss: 0.1790 - val_accuracy: 0.9348\n",
      "Epoch 46/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0947 - accuracy: 0.9681 - val_loss: 0.1797 - val_accuracy: 0.9315\n",
      "Epoch 47/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0923 - accuracy: 0.9667 - val_loss: 0.1810 - val_accuracy: 0.9370\n",
      "Epoch 48/100\n",
      "2760/2760 [==============================] - 0s 11us/step - loss: 0.0907 - accuracy: 0.9692 - val_loss: 0.1809 - val_accuracy: 0.9337\n",
      "Epoch 49/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0887 - accuracy: 0.9688 - val_loss: 0.1802 - val_accuracy: 0.9315\n",
      "Epoch 50/100\n",
      "2760/2760 [==============================] - 0s 10us/step - loss: 0.0873 - accuracy: 0.9699 - val_loss: 0.1805 - val_accuracy: 0.9359\n",
      "Epoch 51/100\n",
      "2760/2760 [==============================] - 0s 14us/step - loss: 0.0857 - accuracy: 0.9710 - val_loss: 0.1822 - val_accuracy: 0.9380\n",
      "Epoch 52/100\n",
      "2760/2760 [==============================] - 0s 12us/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.1833 - val_accuracy: 0.9337\n",
      "921/921 [==============================] - 0s 42us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16970302128960074, 0.9446253776550293]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "spam_model = keras.models.Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(57,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "spam_history = spam_model.fit(partial_x_train,\n",
    "                              partial_y_train,\n",
    "                              epochs=100,\n",
    "                              batch_size=512,\n",
    "                              validation_data=(x_val, y_val),\n",
    "                              callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "3680/3680 [==============================] - 0s 43us/step - loss: 0.6750 - accuracy: 0.5750\n",
      "Epoch 2/42\n",
      "3680/3680 [==============================] - 0s 14us/step - loss: 0.5396 - accuracy: 0.7948\n",
      "Epoch 3/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.4473 - accuracy: 0.8516\n",
      "Epoch 4/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.3758 - accuracy: 0.8747\n",
      "Epoch 5/42\n",
      "3680/3680 [==============================] - 0s 14us/step - loss: 0.3213 - accuracy: 0.8910\n",
      "Epoch 6/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.2816 - accuracy: 0.9024\n",
      "Epoch 7/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.2543 - accuracy: 0.9149\n",
      "Epoch 8/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.2346 - accuracy: 0.9177\n",
      "Epoch 9/42\n",
      "3680/3680 [==============================] - 0s 15us/step - loss: 0.2198 - accuracy: 0.9228\n",
      "Epoch 10/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.2084 - accuracy: 0.9272\n",
      "Epoch 11/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1993 - accuracy: 0.9321\n",
      "Epoch 12/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1917 - accuracy: 0.9353\n",
      "Epoch 13/42\n",
      "3680/3680 [==============================] - 0s 17us/step - loss: 0.1851 - accuracy: 0.9359\n",
      "Epoch 14/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1795 - accuracy: 0.9361\n",
      "Epoch 15/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1746 - accuracy: 0.9375\n",
      "Epoch 16/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1696 - accuracy: 0.9399\n",
      "Epoch 17/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1658 - accuracy: 0.9418\n",
      "Epoch 18/42\n",
      "3680/3680 [==============================] - 0s 14us/step - loss: 0.1618 - accuracy: 0.9432\n",
      "Epoch 19/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1582 - accuracy: 0.9446\n",
      "Epoch 20/42\n",
      "3680/3680 [==============================] - 0s 10us/step - loss: 0.1545 - accuracy: 0.9446\n",
      "Epoch 21/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1513 - accuracy: 0.9465\n",
      "Epoch 22/42\n",
      "3680/3680 [==============================] - 0s 15us/step - loss: 0.1484 - accuracy: 0.9470\n",
      "Epoch 23/42\n",
      "3680/3680 [==============================] - 0s 10us/step - loss: 0.1452 - accuracy: 0.9484\n",
      "Epoch 24/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1428 - accuracy: 0.9476\n",
      "Epoch 25/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1398 - accuracy: 0.9481\n",
      "Epoch 26/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1379 - accuracy: 0.9511\n",
      "Epoch 27/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1333 - accuracy: 0.9524\n",
      "Epoch 28/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1321 - accuracy: 0.9516\n",
      "Epoch 29/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1296 - accuracy: 0.9541\n",
      "Epoch 30/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1262 - accuracy: 0.9543\n",
      "Epoch 31/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1242 - accuracy: 0.9563\n",
      "Epoch 32/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1221 - accuracy: 0.9582\n",
      "Epoch 33/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1198 - accuracy: 0.9579\n",
      "Epoch 34/42\n",
      "3680/3680 [==============================] - 0s 15us/step - loss: 0.1175 - accuracy: 0.9579\n",
      "Epoch 35/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1161 - accuracy: 0.9598\n",
      "Epoch 36/42\n",
      "3680/3680 [==============================] - 0s 11us/step - loss: 0.1156 - accuracy: 0.9582\n",
      "Epoch 37/42\n",
      "3680/3680 [==============================] - 0s 13us/step - loss: 0.1120 - accuracy: 0.9598\n",
      "Epoch 38/42\n",
      "3680/3680 [==============================] - 0s 12us/step - loss: 0.1104 - accuracy: 0.9598\n",
      "Epoch 39/42\n",
      "3680/3680 [==============================] - 0s 16us/step - loss: 0.1084 - accuracy: 0.9601\n",
      "Epoch 40/42\n",
      "3680/3680 [==============================] - 0s 10us/step - loss: 0.1072 - accuracy: 0.9630\n",
      "Epoch 41/42\n",
      "3680/3680 [==============================] - 0s 9us/step - loss: 0.1050 - accuracy: 0.9625\n",
      "Epoch 42/42\n",
      "3680/3680 [==============================] - 0s 10us/step - loss: 0.1047 - accuracy: 0.9647\n",
      "921/921 [==============================] - 0s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16537360245125302, 0.9478827118873596]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "spam_model = keras.models.Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(57,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "spam_history = spam_model.fit(x_train,\n",
    "                              y_train,\n",
    "                              epochs=42,\n",
    "                              batch_size=512)\n",
    "\n",
    "spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomized serach CV for best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classification model with given hyperperameters\n",
    "def build_model(learning_rate=1e-3, n_hidden=2, n_neurons=64, input_shape=57):   \n",
    "    model = Sequential()\n",
    "    for i in range(n_hidden):\n",
    "        if i == 0:\n",
    "            model.add(Dense(n_neurons, activation='relu', input_shape=(input_shape,)))\n",
    "        else:\n",
    "            model.add(Dense(n_neurons, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a Keras classifier\n",
    "keras_clf = KerasClassifier(build_fn=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920/920 [==============================] - 0s 39us/step\n",
      "920/920 [==============================] - 0s 27us/step\n",
      "920/920 [==============================] - 0s 22us/step\n",
      "920/920 [==============================] - 0s 9us/step\n",
      "920/920 [==============================] - 0s 14us/step\n",
      "920/920 [==============================] - 0s 7us/step\n",
      "920/920 [==============================] - 0s 7us/step\n",
      "920/920 [==============================] - 0s 9us/step\n",
      "920/920 [==============================] - 0s 7us/step\n",
      "920/920 [==============================] - 0s 61us/step\n",
      "920/920 [==============================] - 0s 40us/step\n",
      "920/920 [==============================] - 0s 35us/step\n",
      "920/920 [==============================] - 0s 5us/step\n",
      "920/920 [==============================] - 0s 5us/step\n",
      "920/920 [==============================] - 0s 5us/step\n",
      "920/920 [==============================] - 0s 9us/step\n",
      "920/920 [==============================] - 0s 17us/step\n",
      "920/920 [==============================] - 0s 11us/step\n",
      "920/920 [==============================] - 0s 13us/step\n",
      "920/920 [==============================] - 0s 17us/step\n",
      "920/920 [==============================] - 0s 24us/step\n",
      "920/920 [==============================] - 0s 32us/step\n",
      "920/920 [==============================] - 0s 37us/step\n",
      "920/920 [==============================] - 0s 40us/step\n",
      "920/920 [==============================] - 0s 7us/step\n",
      "920/920 [==============================] - 0s 5us/step\n",
      "920/920 [==============================] - 0s 7us/step\n",
      "920/920 [==============================] - 0s 25us/step\n",
      "920/920 [==============================] - 0s 51us/step\n",
      "920/920 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fdd484b4690>,\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'batch_size': [64, 128, 256, 512],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.1],\n",
       "                                        'n_hidden': [2, 3, 4],\n",
       "                                        'n_neurons': [64, 128, 256, 512]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "params = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.1],\n",
    "    'n_hidden': [2, 3, 4],\n",
    "    'n_neurons': [64, 128, 256, 512],\n",
    "    'batch_size': [64, 128, 256, 512]}\n",
    "\n",
    "random_search_cv = RandomizedSearchCV(keras_clf, params, n_iter=10, cv=3, random_state=0)\n",
    "random_search_cv.fit(partial_x_train,\n",
    "                     partial_y_train,\n",
    "                     epochs=100,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                     callbacks=[EarlyStopping(patience=10)],\n",
    "                     verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 128, 'n_hidden': 3, 'learning_rate': 0.001, 'batch_size': 256}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuilt the best model and retrain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 83us/step - loss: 0.5627 - accuracy: 0.7457 - val_loss: 0.4196 - val_accuracy: 0.8522\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.3310 - accuracy: 0.8757 - val_loss: 0.3047 - val_accuracy: 0.9022\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 31us/step - loss: 0.2478 - accuracy: 0.9174 - val_loss: 0.2531 - val_accuracy: 0.9174\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.2097 - accuracy: 0.9275 - val_loss: 0.2262 - val_accuracy: 0.9228\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1819 - accuracy: 0.9399 - val_loss: 0.2114 - val_accuracy: 0.9261\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 0.1661 - accuracy: 0.9446 - val_loss: 0.2035 - val_accuracy: 0.9304\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.1493 - accuracy: 0.9489 - val_loss: 0.1968 - val_accuracy: 0.9304\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.1368 - accuracy: 0.9522 - val_loss: 0.1908 - val_accuracy: 0.9272\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1305 - accuracy: 0.9533 - val_loss: 0.1895 - val_accuracy: 0.9304\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1177 - accuracy: 0.9551 - val_loss: 0.1822 - val_accuracy: 0.9348\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1077 - accuracy: 0.9620 - val_loss: 0.1842 - val_accuracy: 0.9326\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.1007 - accuracy: 0.9649 - val_loss: 0.1888 - val_accuracy: 0.9326\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.0920 - accuracy: 0.9678 - val_loss: 0.1843 - val_accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0868 - accuracy: 0.9710 - val_loss: 0.1923 - val_accuracy: 0.9391\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0810 - accuracy: 0.9743 - val_loss: 0.1911 - val_accuracy: 0.9391\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.0743 - accuracy: 0.9764 - val_loss: 0.1915 - val_accuracy: 0.9293\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0730 - accuracy: 0.9757 - val_loss: 0.2036 - val_accuracy: 0.9315\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0690 - accuracy: 0.9768 - val_loss: 0.2014 - val_accuracy: 0.9293\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.0650 - accuracy: 0.9772 - val_loss: 0.2058 - val_accuracy: 0.9326\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0624 - accuracy: 0.9786 - val_loss: 0.2019 - val_accuracy: 0.9359\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0597 - accuracy: 0.9797 - val_loss: 0.2104 - val_accuracy: 0.9348\n",
      "Epoch 22/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0534 - accuracy: 0.9822 - val_loss: 0.1996 - val_accuracy: 0.9391\n",
      "Epoch 23/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 0.2101 - val_accuracy: 0.9402\n",
      "Epoch 24/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.2242 - val_accuracy: 0.9380\n",
      "Epoch 25/100\n",
      "2760/2760 [==============================] - 0s 47us/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.2217 - val_accuracy: 0.9413\n",
      "Epoch 26/100\n",
      "2760/2760 [==============================] - 0s 48us/step - loss: 0.0371 - accuracy: 0.9899 - val_loss: 0.2310 - val_accuracy: 0.9402\n",
      "Epoch 27/100\n",
      "2760/2760 [==============================] - 0s 40us/step - loss: 0.0356 - accuracy: 0.9873 - val_loss: 0.2329 - val_accuracy: 0.9424\n",
      "Epoch 28/100\n",
      "2760/2760 [==============================] - 0s 42us/step - loss: 0.0327 - accuracy: 0.9891 - val_loss: 0.2339 - val_accuracy: 0.9435\n",
      "Epoch 29/100\n",
      "2760/2760 [==============================] - 0s 43us/step - loss: 0.0315 - accuracy: 0.9913 - val_loss: 0.2488 - val_accuracy: 0.9391\n",
      "Epoch 30/100\n",
      "2760/2760 [==============================] - 0s 41us/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.2514 - val_accuracy: 0.9413\n",
      "Epoch 31/100\n",
      "2760/2760 [==============================] - 0s 43us/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.2580 - val_accuracy: 0.9391\n",
      "Epoch 32/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.2722 - val_accuracy: 0.9424\n",
      "Epoch 33/100\n",
      "2760/2760 [==============================] - 0s 45us/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.2568 - val_accuracy: 0.9457\n",
      "Epoch 34/100\n",
      "2760/2760 [==============================] - 0s 46us/step - loss: 0.0323 - accuracy: 0.9913 - val_loss: 0.2649 - val_accuracy: 0.9359\n",
      "Epoch 35/100\n",
      "2760/2760 [==============================] - 0s 36us/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.2685 - val_accuracy: 0.9391\n",
      "Epoch 36/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0267 - accuracy: 0.9917 - val_loss: 0.2710 - val_accuracy: 0.9413\n",
      "Epoch 37/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 0.2818 - val_accuracy: 0.9359\n",
      "Epoch 38/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.2914 - val_accuracy: 0.9391\n",
      "Epoch 39/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.2857 - val_accuracy: 0.9402\n",
      "Epoch 40/100\n",
      "2760/2760 [==============================] - 0s 20us/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.2890 - val_accuracy: 0.9402\n",
      "Epoch 41/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.3041 - val_accuracy: 0.9435\n",
      "Epoch 42/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.2977 - val_accuracy: 0.9380\n",
      "Epoch 43/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.0196 - accuracy: 0.9938 - val_loss: 0.3144 - val_accuracy: 0.9413\n",
      "Epoch 44/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.3044 - val_accuracy: 0.9370\n",
      "Epoch 45/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.3254 - val_accuracy: 0.9435\n",
      "Epoch 46/100\n",
      "2760/2760 [==============================] - 0s 20us/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 0.3203 - val_accuracy: 0.9402\n",
      "Epoch 47/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.3055 - val_accuracy: 0.9380\n",
      "Epoch 48/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.3030 - val_accuracy: 0.9380\n",
      "Epoch 49/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.3126 - val_accuracy: 0.9370\n",
      "Epoch 50/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.3222 - val_accuracy: 0.9370\n",
      "Epoch 51/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.3330 - val_accuracy: 0.9424\n",
      "Epoch 52/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.3264 - val_accuracy: 0.9380\n",
      "Epoch 53/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 0.3251 - val_accuracy: 0.9391\n",
      "Epoch 54/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.3413 - val_accuracy: 0.9337\n",
      "Epoch 55/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0239 - accuracy: 0.9931 - val_loss: 0.3292 - val_accuracy: 0.9337\n",
      "Epoch 56/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.3373 - val_accuracy: 0.9413\n",
      "Epoch 57/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.3338 - val_accuracy: 0.9370\n",
      "Epoch 58/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.3498 - val_accuracy: 0.9391\n",
      "Epoch 59/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.3432 - val_accuracy: 0.9337\n",
      "Epoch 60/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0241 - accuracy: 0.9931 - val_loss: 0.3474 - val_accuracy: 0.9326\n",
      "Epoch 61/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.3374 - val_accuracy: 0.9391\n",
      "Epoch 62/100\n",
      "2760/2760 [==============================] - 0s 28us/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.3358 - val_accuracy: 0.9391\n",
      "Epoch 63/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.3425 - val_accuracy: 0.9380\n",
      "Epoch 64/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0187 - accuracy: 0.9942 - val_loss: 0.3670 - val_accuracy: 0.9446\n",
      "Epoch 65/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0179 - accuracy: 0.9935 - val_loss: 0.3541 - val_accuracy: 0.9391\n",
      "Epoch 66/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.3553 - val_accuracy: 0.9424\n",
      "Epoch 67/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.3631 - val_accuracy: 0.9413\n",
      "Epoch 68/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.3533 - val_accuracy: 0.9370\n",
      "Epoch 69/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.3460 - val_accuracy: 0.9380\n",
      "Epoch 70/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.3507 - val_accuracy: 0.9413\n",
      "Epoch 71/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.3579 - val_accuracy: 0.9348\n",
      "Epoch 72/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.3632 - val_accuracy: 0.9359\n",
      "Epoch 73/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.3660 - val_accuracy: 0.9380\n",
      "Epoch 74/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.3737 - val_accuracy: 0.9370\n",
      "Epoch 75/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 0.3807 - val_accuracy: 0.9402\n",
      "Epoch 76/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 0.0196 - accuracy: 0.9920 - val_loss: 0.3864 - val_accuracy: 0.9446\n",
      "Epoch 77/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.3733 - val_accuracy: 0.9402\n",
      "Epoch 78/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.3849 - val_accuracy: 0.9391\n",
      "Epoch 79/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0381 - accuracy: 0.9917 - val_loss: 0.3617 - val_accuracy: 0.9380\n",
      "Epoch 80/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.0340 - accuracy: 0.9906 - val_loss: 0.3479 - val_accuracy: 0.9326\n",
      "Epoch 81/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.3678 - val_accuracy: 0.9370\n",
      "Epoch 82/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.3452 - val_accuracy: 0.9380\n",
      "Epoch 83/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 0.3348 - val_accuracy: 0.9402\n",
      "Epoch 84/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.3689 - val_accuracy: 0.9435\n",
      "Epoch 85/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.3669 - val_accuracy: 0.9413\n",
      "Epoch 86/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.3569 - val_accuracy: 0.9370\n",
      "Epoch 87/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.3621 - val_accuracy: 0.9380\n",
      "Epoch 88/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.3850 - val_accuracy: 0.9413\n",
      "Epoch 89/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.3732 - val_accuracy: 0.9359\n",
      "Epoch 90/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.3740 - val_accuracy: 0.9380\n",
      "Epoch 91/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.3762 - val_accuracy: 0.9359\n",
      "Epoch 92/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.3738 - val_accuracy: 0.9359\n",
      "Epoch 93/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0206 - accuracy: 0.9942 - val_loss: 0.3864 - val_accuracy: 0.9380\n",
      "Epoch 94/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.3829 - val_accuracy: 0.9413\n",
      "Epoch 95/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.3651 - val_accuracy: 0.9370\n",
      "Epoch 96/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.3772 - val_accuracy: 0.9391\n",
      "Epoch 97/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0160 - accuracy: 0.9967 - val_loss: 0.3672 - val_accuracy: 0.9348\n",
      "Epoch 98/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.3726 - val_accuracy: 0.9370\n",
      "Epoch 99/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.3802 - val_accuracy: 0.9380\n",
      "Epoch 100/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.3818 - val_accuracy: 0.9348\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 87us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4575970869847087, 0.9467969536781311]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "best_spam_model = build_model(1e-3, 3, 128)\n",
    "best_spam_model_history = best_spam_model.fit(partial_x_train,\n",
    "                                              partial_y_train,\n",
    "                                              epochs=100,\n",
    "                                              batch_size=256,\n",
    "                                              validation_data=(x_val, y_val))\n",
    "plot_model_performance(best_spam_model_history)\n",
    "best_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 85us/step - loss: 0.5754 - accuracy: 0.7402 - val_loss: 0.4324 - val_accuracy: 0.8761\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.3342 - accuracy: 0.8902 - val_loss: 0.3085 - val_accuracy: 0.8989\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.2485 - accuracy: 0.9141 - val_loss: 0.2629 - val_accuracy: 0.9141\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2106 - accuracy: 0.9315 - val_loss: 0.2320 - val_accuracy: 0.9250\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.1838 - accuracy: 0.9384 - val_loss: 0.2172 - val_accuracy: 0.9315\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.1686 - accuracy: 0.9420 - val_loss: 0.2121 - val_accuracy: 0.9304\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1520 - accuracy: 0.9446 - val_loss: 0.2031 - val_accuracy: 0.9326\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1404 - accuracy: 0.9489 - val_loss: 0.1962 - val_accuracy: 0.9315\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.1334 - accuracy: 0.9500 - val_loss: 0.1932 - val_accuracy: 0.9359\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1194 - accuracy: 0.9580 - val_loss: 0.1956 - val_accuracy: 0.9348\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1137 - accuracy: 0.9591 - val_loss: 0.1862 - val_accuracy: 0.9370\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1049 - accuracy: 0.9630 - val_loss: 0.1903 - val_accuracy: 0.9326\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 28us/step - loss: 0.0976 - accuracy: 0.9670 - val_loss: 0.1884 - val_accuracy: 0.9315\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0881 - accuracy: 0.9714 - val_loss: 0.1944 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.1965 - val_accuracy: 0.9348\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0762 - accuracy: 0.9750 - val_loss: 0.2008 - val_accuracy: 0.9304\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.0739 - accuracy: 0.9779 - val_loss: 0.2129 - val_accuracy: 0.9250\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.0701 - accuracy: 0.9764 - val_loss: 0.2115 - val_accuracy: 0.9272\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0672 - accuracy: 0.9786 - val_loss: 0.2095 - val_accuracy: 0.9359\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.0631 - accuracy: 0.9797 - val_loss: 0.2179 - val_accuracy: 0.9348\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.2105 - val_accuracy: 0.9348\n",
      "921/921 [==============================] - 0s 55us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20953155986875716, 0.9446253776550293]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "es_best_spam_model = build_model(1e-3, 3, 128)\n",
    "es_best_spam_model.fit(partial_x_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=100,\n",
    "                        batch_size=256,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[EarlyStopping(patience=10)])\n",
    "es_best_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "3680/3680 [==============================] - 0s 59us/step - loss: 0.5470 - accuracy: 0.7533\n",
      "Epoch 2/11\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2992 - accuracy: 0.8954\n",
      "Epoch 3/11\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2202 - accuracy: 0.9253\n",
      "Epoch 4/11\n",
      "3680/3680 [==============================] - 0s 20us/step - loss: 0.1871 - accuracy: 0.9345\n",
      "Epoch 5/11\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1665 - accuracy: 0.9429\n",
      "Epoch 6/11\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1573 - accuracy: 0.9427\n",
      "Epoch 7/11\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.1436 - accuracy: 0.9470\n",
      "Epoch 8/11\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.1315 - accuracy: 0.9530\n",
      "Epoch 9/11\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1239 - accuracy: 0.9522\n",
      "Epoch 10/11\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.1162 - accuracy: 0.9568\n",
      "Epoch 11/11\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1022 - accuracy: 0.9603\n",
      "921/921 [==============================] - 0s 80us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1684231774297004, 0.9522258639335632]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "es_best_spam_model = build_model(1e-3, 3, 128)\n",
    "es_best_spam_model.fit(x_train,\n",
    "                       y_train,\n",
    "                       epochs=11,\n",
    "                       batch_size=256)\n",
    "es_best_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 93us/step - loss: 3.7007 - accuracy: 0.7344 - val_loss: 3.3224 - val_accuracy: 0.8761\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 3.0453 - accuracy: 0.8851 - val_loss: 2.7558 - val_accuracy: 0.8978\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 2.5280 - accuracy: 0.9091 - val_loss: 2.3100 - val_accuracy: 0.9087\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 2.1128 - accuracy: 0.9192 - val_loss: 1.9389 - val_accuracy: 0.9196\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 1.7670 - accuracy: 0.9308 - val_loss: 1.6323 - val_accuracy: 0.9239\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 1.4824 - accuracy: 0.9351 - val_loss: 1.3779 - val_accuracy: 0.9272\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 1.2466 - accuracy: 0.9402 - val_loss: 1.1687 - val_accuracy: 0.9261\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 1.0552 - accuracy: 0.9399 - val_loss: 0.9976 - val_accuracy: 0.9272\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 34us/step - loss: 0.8983 - accuracy: 0.9406 - val_loss: 0.8602 - val_accuracy: 0.9293\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.7686 - accuracy: 0.9424 - val_loss: 0.7440 - val_accuracy: 0.9293\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.6647 - accuracy: 0.9438 - val_loss: 0.6517 - val_accuracy: 0.9304\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 31us/step - loss: 0.5798 - accuracy: 0.9438 - val_loss: 0.5800 - val_accuracy: 0.9272\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.5131 - accuracy: 0.9446 - val_loss: 0.5222 - val_accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.4569 - accuracy: 0.9471 - val_loss: 0.4714 - val_accuracy: 0.9283\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.4131 - accuracy: 0.9471 - val_loss: 0.4343 - val_accuracy: 0.9272\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.3760 - accuracy: 0.9471 - val_loss: 0.4058 - val_accuracy: 0.9348\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.3499 - accuracy: 0.9493 - val_loss: 0.3767 - val_accuracy: 0.9337\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.3235 - accuracy: 0.9514 - val_loss: 0.3574 - val_accuracy: 0.9315\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.3046 - accuracy: 0.9449 - val_loss: 0.3400 - val_accuracy: 0.9315\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.2881 - accuracy: 0.9493 - val_loss: 0.3268 - val_accuracy: 0.9359\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2746 - accuracy: 0.9493 - val_loss: 0.3184 - val_accuracy: 0.9359\n",
      "Epoch 22/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2646 - accuracy: 0.9522 - val_loss: 0.3075 - val_accuracy: 0.9304\n",
      "Epoch 23/100\n",
      "2760/2760 [==============================] - 0s 28us/step - loss: 0.2576 - accuracy: 0.9525 - val_loss: 0.3014 - val_accuracy: 0.9261\n",
      "Epoch 24/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.2494 - accuracy: 0.9525 - val_loss: 0.2930 - val_accuracy: 0.9337\n",
      "Epoch 25/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.2426 - accuracy: 0.9496 - val_loss: 0.2889 - val_accuracy: 0.9359\n",
      "Epoch 26/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.2360 - accuracy: 0.9543 - val_loss: 0.2883 - val_accuracy: 0.9337\n",
      "Epoch 27/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.2317 - accuracy: 0.9558 - val_loss: 0.2813 - val_accuracy: 0.9293\n",
      "Epoch 28/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2270 - accuracy: 0.9562 - val_loss: 0.2784 - val_accuracy: 0.9337\n",
      "Epoch 29/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.2242 - accuracy: 0.9580 - val_loss: 0.2756 - val_accuracy: 0.9359\n",
      "Epoch 30/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.2222 - accuracy: 0.9569 - val_loss: 0.2747 - val_accuracy: 0.9326\n",
      "Epoch 31/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.2201 - accuracy: 0.9551 - val_loss: 0.2851 - val_accuracy: 0.9326\n",
      "Epoch 32/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.2214 - accuracy: 0.9551 - val_loss: 0.2729 - val_accuracy: 0.9359\n",
      "Epoch 33/100\n",
      "2760/2760 [==============================] - 0s 32us/step - loss: 0.2148 - accuracy: 0.9580 - val_loss: 0.2692 - val_accuracy: 0.9348\n",
      "Epoch 34/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2125 - accuracy: 0.9572 - val_loss: 0.2679 - val_accuracy: 0.9359\n",
      "Epoch 35/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.2095 - accuracy: 0.9583 - val_loss: 0.2707 - val_accuracy: 0.9348\n",
      "Epoch 36/100\n",
      "2760/2760 [==============================] - 0s 31us/step - loss: 0.2077 - accuracy: 0.9591 - val_loss: 0.2678 - val_accuracy: 0.9337\n",
      "Epoch 37/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.2061 - accuracy: 0.9580 - val_loss: 0.2659 - val_accuracy: 0.9370\n",
      "Epoch 38/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.2050 - accuracy: 0.9616 - val_loss: 0.2642 - val_accuracy: 0.9359\n",
      "Epoch 39/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.2050 - accuracy: 0.9620 - val_loss: 0.2641 - val_accuracy: 0.9359\n",
      "Epoch 40/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.2020 - accuracy: 0.9601 - val_loss: 0.2682 - val_accuracy: 0.9326\n",
      "Epoch 41/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.2032 - accuracy: 0.9609 - val_loss: 0.2674 - val_accuracy: 0.9326\n",
      "Epoch 42/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.2015 - accuracy: 0.9598 - val_loss: 0.2626 - val_accuracy: 0.9359\n",
      "Epoch 43/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1998 - accuracy: 0.9605 - val_loss: 0.2601 - val_accuracy: 0.9337\n",
      "Epoch 44/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1959 - accuracy: 0.9634 - val_loss: 0.2664 - val_accuracy: 0.9380\n",
      "Epoch 45/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1985 - accuracy: 0.9601 - val_loss: 0.2593 - val_accuracy: 0.9380\n",
      "Epoch 46/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1956 - accuracy: 0.9620 - val_loss: 0.2591 - val_accuracy: 0.9391\n",
      "Epoch 47/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1931 - accuracy: 0.9620 - val_loss: 0.2593 - val_accuracy: 0.9402\n",
      "Epoch 48/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1930 - accuracy: 0.9634 - val_loss: 0.2567 - val_accuracy: 0.9413\n",
      "Epoch 49/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1917 - accuracy: 0.9652 - val_loss: 0.2612 - val_accuracy: 0.9359\n",
      "Epoch 50/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1933 - accuracy: 0.9645 - val_loss: 0.2558 - val_accuracy: 0.9402\n",
      "Epoch 51/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1896 - accuracy: 0.9659 - val_loss: 0.2548 - val_accuracy: 0.9370\n",
      "Epoch 52/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1902 - accuracy: 0.9638 - val_loss: 0.2599 - val_accuracy: 0.9348\n",
      "Epoch 53/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1923 - accuracy: 0.9649 - val_loss: 0.2574 - val_accuracy: 0.9359\n",
      "Epoch 54/100\n",
      "2760/2760 [==============================] - 0s 21us/step - loss: 0.1891 - accuracy: 0.9620 - val_loss: 0.2573 - val_accuracy: 0.9391\n",
      "Epoch 55/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1890 - accuracy: 0.9656 - val_loss: 0.2559 - val_accuracy: 0.9424\n",
      "Epoch 56/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1934 - accuracy: 0.9612 - val_loss: 0.2558 - val_accuracy: 0.9326\n",
      "Epoch 57/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1914 - accuracy: 0.9634 - val_loss: 0.2597 - val_accuracy: 0.9402\n",
      "Epoch 58/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1865 - accuracy: 0.9623 - val_loss: 0.2515 - val_accuracy: 0.9380\n",
      "Epoch 59/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1847 - accuracy: 0.9652 - val_loss: 0.2556 - val_accuracy: 0.9413\n",
      "Epoch 60/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1837 - accuracy: 0.9670 - val_loss: 0.2580 - val_accuracy: 0.9326\n",
      "Epoch 61/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1826 - accuracy: 0.9659 - val_loss: 0.2551 - val_accuracy: 0.9359\n",
      "Epoch 62/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1831 - accuracy: 0.9667 - val_loss: 0.2626 - val_accuracy: 0.9348\n",
      "Epoch 63/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1831 - accuracy: 0.9638 - val_loss: 0.2575 - val_accuracy: 0.9359\n",
      "Epoch 64/100\n",
      "2760/2760 [==============================] - 0s 25us/step - loss: 0.1835 - accuracy: 0.9678 - val_loss: 0.2589 - val_accuracy: 0.9359\n",
      "Epoch 65/100\n",
      "2760/2760 [==============================] - 0s 23us/step - loss: 0.1815 - accuracy: 0.9678 - val_loss: 0.2530 - val_accuracy: 0.9370\n",
      "Epoch 66/100\n",
      "2760/2760 [==============================] - 0s 22us/step - loss: 0.1790 - accuracy: 0.9678 - val_loss: 0.2532 - val_accuracy: 0.9348\n",
      "Epoch 67/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1809 - accuracy: 0.9652 - val_loss: 0.2590 - val_accuracy: 0.9359\n",
      "Epoch 68/100\n",
      "2760/2760 [==============================] - 0s 24us/step - loss: 0.1785 - accuracy: 0.9714 - val_loss: 0.2523 - val_accuracy: 0.9337\n",
      "921/921 [==============================] - 0s 57us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23819103060405494, 0.9457111954689026]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "l2_best_spam_model = keras.models.Sequential([\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu', input_shape=(57,)),\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'),\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "l2_best_spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "l2_best_spam_model.fit(partial_x_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=100,\n",
    "                        batch_size=256,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "l2_best_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58\n",
      "3680/3680 [==============================] - 0s 63us/step - loss: 3.6211 - accuracy: 0.7432\n",
      "Epoch 2/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 2.7896 - accuracy: 0.8842\n",
      "Epoch 3/58\n",
      "3680/3680 [==============================] - 0s 20us/step - loss: 2.1722 - accuracy: 0.9087\n",
      "Epoch 4/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 1.7020 - accuracy: 0.9236\n",
      "Epoch 5/58\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 1.3416 - accuracy: 0.9283\n",
      "Epoch 6/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 1.0688 - accuracy: 0.9340\n",
      "Epoch 7/58\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 0.8615 - accuracy: 0.9359\n",
      "Epoch 8/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.7045 - accuracy: 0.9383\n",
      "Epoch 9/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.5882 - accuracy: 0.9418\n",
      "Epoch 10/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.4994 - accuracy: 0.9451\n",
      "Epoch 11/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.4327 - accuracy: 0.9438\n",
      "Epoch 12/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.3843 - accuracy: 0.9435\n",
      "Epoch 13/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.3491 - accuracy: 0.9478\n",
      "Epoch 14/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.3203 - accuracy: 0.9446\n",
      "Epoch 15/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.3011 - accuracy: 0.9459\n",
      "Epoch 16/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.2857 - accuracy: 0.9476\n",
      "Epoch 17/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2697 - accuracy: 0.9467\n",
      "Epoch 18/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2606 - accuracy: 0.9473\n",
      "Epoch 19/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2525 - accuracy: 0.9489\n",
      "Epoch 20/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2481 - accuracy: 0.9470\n",
      "Epoch 21/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2406 - accuracy: 0.9503\n",
      "Epoch 22/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.2368 - accuracy: 0.9497\n",
      "Epoch 23/58\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.2326 - accuracy: 0.9508\n",
      "Epoch 24/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2327 - accuracy: 0.9519\n",
      "Epoch 25/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.2283 - accuracy: 0.9508\n",
      "Epoch 26/58\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 0.2276 - accuracy: 0.9505\n",
      "Epoch 27/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.2250 - accuracy: 0.9505\n",
      "Epoch 28/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2207 - accuracy: 0.9508\n",
      "Epoch 29/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2170 - accuracy: 0.9538\n",
      "Epoch 30/58\n",
      "3680/3680 [==============================] - 0s 27us/step - loss: 0.2148 - accuracy: 0.9535\n",
      "Epoch 31/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2187 - accuracy: 0.9538\n",
      "Epoch 32/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2150 - accuracy: 0.9516\n",
      "Epoch 33/58\n",
      "3680/3680 [==============================] - 0s 30us/step - loss: 0.2142 - accuracy: 0.9554\n",
      "Epoch 34/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2144 - accuracy: 0.9519\n",
      "Epoch 35/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2082 - accuracy: 0.9560\n",
      "Epoch 36/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2065 - accuracy: 0.9571\n",
      "Epoch 37/58\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.2077 - accuracy: 0.9524\n",
      "Epoch 38/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2055 - accuracy: 0.9560\n",
      "Epoch 39/58\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.2094 - accuracy: 0.9511\n",
      "Epoch 40/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.2041 - accuracy: 0.9565\n",
      "Epoch 41/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2020 - accuracy: 0.9554\n",
      "Epoch 42/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2021 - accuracy: 0.9552\n",
      "Epoch 43/58\n",
      "3680/3680 [==============================] - 0s 28us/step - loss: 0.2038 - accuracy: 0.9549\n",
      "Epoch 44/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2038 - accuracy: 0.9535\n",
      "Epoch 45/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2042 - accuracy: 0.9530\n",
      "Epoch 46/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.2020 - accuracy: 0.9571\n",
      "Epoch 47/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1975 - accuracy: 0.9568\n",
      "Epoch 48/58\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.1984 - accuracy: 0.9573\n",
      "Epoch 49/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.1954 - accuracy: 0.9582\n",
      "Epoch 50/58\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 0.1958 - accuracy: 0.9579\n",
      "Epoch 51/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1955 - accuracy: 0.9541\n",
      "Epoch 52/58\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1938 - accuracy: 0.9582\n",
      "Epoch 53/58\n",
      "3680/3680 [==============================] - 0s 27us/step - loss: 0.1928 - accuracy: 0.9584\n",
      "Epoch 54/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1935 - accuracy: 0.9563\n",
      "Epoch 55/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.1935 - accuracy: 0.9582\n",
      "Epoch 56/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.1948 - accuracy: 0.9584\n",
      "Epoch 57/58\n",
      "3680/3680 [==============================] - 0s 21us/step - loss: 0.1927 - accuracy: 0.9573\n",
      "Epoch 58/58\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1948 - accuracy: 0.9549\n",
      "921/921 [==============================] - 0s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22419342702814862, 0.9554831981658936]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "l2_best_spam_model = keras.models.Sequential([\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu', input_shape=(57,)),\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'),\n",
    "    Dense(128, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "l2_best_spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "l2_best_spam_model.fit(x_train,\n",
    "                       y_train,\n",
    "                       epochs=58,\n",
    "                       batch_size=256)\n",
    "\n",
    "l2_best_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2760 samples, validate on 920 samples\n",
      "Epoch 1/100\n",
      "2760/2760 [==============================] - 0s 136us/step - loss: 0.5753 - accuracy: 0.7475 - val_loss: 0.4302 - val_accuracy: 0.8652\n",
      "Epoch 2/100\n",
      "2760/2760 [==============================] - 0s 38us/step - loss: 0.3573 - accuracy: 0.8685 - val_loss: 0.3037 - val_accuracy: 0.8924\n",
      "Epoch 3/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.2743 - accuracy: 0.9022 - val_loss: 0.2552 - val_accuracy: 0.9185\n",
      "Epoch 4/100\n",
      "2760/2760 [==============================] - 0s 38us/step - loss: 0.2402 - accuracy: 0.9094 - val_loss: 0.2374 - val_accuracy: 0.9228\n",
      "Epoch 5/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.2090 - accuracy: 0.9210 - val_loss: 0.2232 - val_accuracy: 0.9293\n",
      "Epoch 6/100\n",
      "2760/2760 [==============================] - 0s 37us/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 0.2127 - val_accuracy: 0.9315\n",
      "Epoch 7/100\n",
      "2760/2760 [==============================] - 0s 30us/step - loss: 0.1915 - accuracy: 0.9308 - val_loss: 0.2159 - val_accuracy: 0.9283\n",
      "Epoch 8/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1761 - accuracy: 0.9348 - val_loss: 0.2048 - val_accuracy: 0.9315\n",
      "Epoch 9/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.1763 - accuracy: 0.9355 - val_loss: 0.2004 - val_accuracy: 0.9337\n",
      "Epoch 10/100\n",
      "2760/2760 [==============================] - 0s 27us/step - loss: 0.1624 - accuracy: 0.9370 - val_loss: 0.1922 - val_accuracy: 0.9380\n",
      "Epoch 11/100\n",
      "2760/2760 [==============================] - 0s 38us/step - loss: 0.1591 - accuracy: 0.9420 - val_loss: 0.1873 - val_accuracy: 0.9391\n",
      "Epoch 12/100\n",
      "2760/2760 [==============================] - 0s 28us/step - loss: 0.1634 - accuracy: 0.9388 - val_loss: 0.2058 - val_accuracy: 0.9359\n",
      "Epoch 13/100\n",
      "2760/2760 [==============================] - 0s 31us/step - loss: 0.1519 - accuracy: 0.9417 - val_loss: 0.1876 - val_accuracy: 0.9402\n",
      "Epoch 14/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1565 - accuracy: 0.9413 - val_loss: 0.1924 - val_accuracy: 0.9380\n",
      "Epoch 15/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.1455 - accuracy: 0.9457 - val_loss: 0.1820 - val_accuracy: 0.9370\n",
      "Epoch 16/100\n",
      "2760/2760 [==============================] - 0s 35us/step - loss: 0.1388 - accuracy: 0.9496 - val_loss: 0.1852 - val_accuracy: 0.9359\n",
      "Epoch 17/100\n",
      "2760/2760 [==============================] - 0s 35us/step - loss: 0.1363 - accuracy: 0.9489 - val_loss: 0.1831 - val_accuracy: 0.9326\n",
      "Epoch 18/100\n",
      "2760/2760 [==============================] - 0s 35us/step - loss: 0.1324 - accuracy: 0.9522 - val_loss: 0.1898 - val_accuracy: 0.9370\n",
      "Epoch 19/100\n",
      "2760/2760 [==============================] - 0s 26us/step - loss: 0.1328 - accuracy: 0.9500 - val_loss: 0.1798 - val_accuracy: 0.9391\n",
      "Epoch 20/100\n",
      "2760/2760 [==============================] - 0s 33us/step - loss: 0.1335 - accuracy: 0.9504 - val_loss: 0.1778 - val_accuracy: 0.9391\n",
      "Epoch 21/100\n",
      "2760/2760 [==============================] - 0s 35us/step - loss: 0.1242 - accuracy: 0.9522 - val_loss: 0.1782 - val_accuracy: 0.9446\n",
      "Epoch 22/100\n",
      "2760/2760 [==============================] - 0s 37us/step - loss: 0.1247 - accuracy: 0.9551 - val_loss: 0.1823 - val_accuracy: 0.9402\n",
      "Epoch 23/100\n",
      "2760/2760 [==============================] - 0s 35us/step - loss: 0.1143 - accuracy: 0.9605 - val_loss: 0.1831 - val_accuracy: 0.9380\n",
      "Epoch 24/100\n",
      "2760/2760 [==============================] - 0s 36us/step - loss: 0.1181 - accuracy: 0.9587 - val_loss: 0.1858 - val_accuracy: 0.9380\n",
      "Epoch 25/100\n",
      "2760/2760 [==============================] - 0s 37us/step - loss: 0.1093 - accuracy: 0.9601 - val_loss: 0.1857 - val_accuracy: 0.9402\n",
      "Epoch 26/100\n",
      "2760/2760 [==============================] - 0s 31us/step - loss: 0.1068 - accuracy: 0.9616 - val_loss: 0.1876 - val_accuracy: 0.9391\n",
      "Epoch 27/100\n",
      "2760/2760 [==============================] - 0s 29us/step - loss: 0.1087 - accuracy: 0.9627 - val_loss: 0.1864 - val_accuracy: 0.9435\n",
      "Epoch 28/100\n",
      "2760/2760 [==============================] - 0s 39us/step - loss: 0.1096 - accuracy: 0.9616 - val_loss: 0.1903 - val_accuracy: 0.9446\n",
      "Epoch 29/100\n",
      "2760/2760 [==============================] - 0s 36us/step - loss: 0.1036 - accuracy: 0.9630 - val_loss: 0.1868 - val_accuracy: 0.9413\n",
      "Epoch 30/100\n",
      "2760/2760 [==============================] - 0s 37us/step - loss: 0.0968 - accuracy: 0.9634 - val_loss: 0.1878 - val_accuracy: 0.9424\n",
      "921/921 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1867113827801553, 0.9467969536781311]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "do_spam_model = keras.models.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(57,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "do_spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "do_spam_model.fit(partial_x_train,\n",
    "                partial_y_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                validation_data=(x_val, y_val),\n",
    "                callbacks=[EarlyStopping(patience=10)])\n",
    "\n",
    "do_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3680/3680 [==============================] - 0s 92us/step - loss: 0.5707 - accuracy: 0.7201\n",
      "Epoch 2/20\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.3334 - accuracy: 0.8766\n",
      "Epoch 3/20\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2581 - accuracy: 0.9060\n",
      "Epoch 4/20\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.2316 - accuracy: 0.9144\n",
      "Epoch 5/20\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.2074 - accuracy: 0.9266\n",
      "Epoch 6/20\n",
      "3680/3680 [==============================] - 0s 28us/step - loss: 0.2028 - accuracy: 0.9280\n",
      "Epoch 7/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1899 - accuracy: 0.9285\n",
      "Epoch 8/20\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.1751 - accuracy: 0.9329\n",
      "Epoch 9/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1670 - accuracy: 0.9389\n",
      "Epoch 10/20\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1624 - accuracy: 0.9359\n",
      "Epoch 11/20\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 0.1532 - accuracy: 0.9427\n",
      "Epoch 12/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1517 - accuracy: 0.9427\n",
      "Epoch 13/20\n",
      "3680/3680 [==============================] - 0s 26us/step - loss: 0.1453 - accuracy: 0.9454\n",
      "Epoch 14/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1433 - accuracy: 0.9446\n",
      "Epoch 15/20\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1408 - accuracy: 0.9462\n",
      "Epoch 16/20\n",
      "3680/3680 [==============================] - 0s 23us/step - loss: 0.1351 - accuracy: 0.9519\n",
      "Epoch 17/20\n",
      "3680/3680 [==============================] - 0s 22us/step - loss: 0.1301 - accuracy: 0.9486\n",
      "Epoch 18/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1276 - accuracy: 0.9538\n",
      "Epoch 19/20\n",
      "3680/3680 [==============================] - 0s 24us/step - loss: 0.1227 - accuracy: 0.9549\n",
      "Epoch 20/20\n",
      "3680/3680 [==============================] - 0s 25us/step - loss: 0.1200 - accuracy: 0.9565\n",
      "921/921 [==============================] - 0s 88us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15823437265412685, 0.9576547145843506]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "do_spam_model = keras.models.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(57,)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "do_spam_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "do_spam_model.fit(x_train,\n",
    "                y_train,\n",
    "                epochs=20,\n",
    "                batch_size=256)\n",
    "\n",
    "do_spam_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_spam_model.save('keras_spam_trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921/921 [==============================] - 0s 101us/step\n",
      "Test loss 0.15823437265412685\n",
      "Test accuracy 0.9576547145843506\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('keras_spam_trained_model.h5')\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss', scores[0])\n",
    "print('Test accuracy', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
