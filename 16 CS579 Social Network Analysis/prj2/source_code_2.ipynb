{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "source_code_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-XiFhrKZnTF"
      },
      "source": [
        "## CS579 Project II LSTM Tuning Road Map\n",
        "\n",
        "Author: Christopher Hong\n",
        "\n",
        "* Step 1: Preparing data\n",
        "  * Step 1.1: Loading data\n",
        "  * Step 1.2: Partitioning data\n",
        "  * Step 1.3: Wrangling data\n",
        "  * Step 1.4: Engineering feature\n",
        "  * Step 1.5: Encoding label\n",
        "* Step 2: Cross-validating baseline LSTM model\n",
        "* Step 3: Tuning LSTM hyperparameters\n",
        "* Step 4: Assessing final model performance\n",
        "* Step 5: Saving tuning histories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i23CvEpW7P1x",
        "outputId": "bd7702d1-4ea3-40b3-db30-1f689d4ab9d9"
      },
      "source": [
        "# Common library\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Text processing packages\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Visualization packages\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=16)\n",
        "mpl.rc('xtick', labelsize=14)\n",
        "mpl.rc('ytick', labelsize=14)\n",
        "\n",
        "# Machine Learning packages\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "\n",
        "# Aesthetic setting\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reproducibility setting\n",
        "np.random.seed(2020)\n",
        "tf.random.set_seed(2020)\n",
        "random_state = 2020\n",
        "\n",
        "# Set up path to local Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAKUUzLzn1pV"
      },
      "source": [
        "<a id='1'></a>\n",
        "## 1 Preparing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyVb5xgQoEgx"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "### 1.1 Loading the data\n",
        "\n",
        "**Note**: Assume `/content/drive/MyDrive/CS579_Projct_2/option1-data/train.csv` exists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PWdCqkq7YXR",
        "outputId": "f4129174-c102-4436-86cc-7e5a3719bea4"
      },
      "source": [
        "# Define the base dir to local Google Drive\n",
        "BASE_PATH = \"/content/drive/MyDrive/CS579_Project_2/\"\n",
        "\n",
        "# Define base dir to local drive\n",
        "DATA_PATH = os.path.join(BASE_PATH, \"option1-data\")\n",
        "\n",
        "# Define dir to model dir to store training history\n",
        "MODEL_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "\n",
        "# Create file paths if not extists\n",
        "os.makedirs(BASE_PATH, exist_ok=True)\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Define dir to train data\n",
        "TRAIN_DATA_PATH = os.path.join(DATA_PATH, \"train.csv\")\n",
        "\n",
        "print(\"train data path:\", TRAIN_DATA_PATH)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data path: /content/drive/MyDrive/CS579_Project_2/option1-data/train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCvSAyIF7s0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc543c2-b146-4553-fd4a-feb3ed43c9ea"
      },
      "source": [
        "# Load train data\n",
        "df_train = pd.read_csv(TRAIN_DATA_PATH)\n",
        "\n",
        "# Data quality check\n",
        "df_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256442, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAJT-mZcoJhw"
      },
      "source": [
        "<a id='1.2'></a>\n",
        "### 1.2 Partitioning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYrynjH37vBe"
      },
      "source": [
        "# Split the train data into 75/25 train and validation set\n",
        "test_size= 0.25\n",
        "\n",
        "# Stratified random sampling\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
        "for train_index, val_index in split.split(df_train, df_train['label']):\n",
        "    data_train = df_train.loc[train_index].copy().reset_index(drop=True)\n",
        "    data_val = df_train.loc[val_index].copy().reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvh0eu7Eochc"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "### 1.3 Normalizing the text feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xktpjBmf72Nf"
      },
      "source": [
        "def normalize(text):\n",
        "    \"\"\"\n",
        "    Lowercase, tokenize, lemmatize, \n",
        "    remove stop and unwanted tokens. \n",
        "    \"\"\"\n",
        "    # Tokenization \n",
        "    lower_tokens = word_tokenize(text.lower())\n",
        "    \n",
        "    # Retain alphabetic words\n",
        "    alpha_tokens = [w for w in lower_tokens if w.isalpha()]\n",
        "    \n",
        "    # Create a lemmatizer object\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    # Lemmatize all tokens\n",
        "    lemmatized = [wordnet_lemmatizer.lemmatize(w) for w in alpha_tokens]\n",
        "    \n",
        "    # Create a set of stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    \n",
        "    # Remove stop words and word length less than 3\n",
        "    no_stops = [w for w in lemmatized if len(w) > 2 and w not in stop_words]\n",
        "    \n",
        "    return ' '.join(no_stops)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCVX31jRkGJg"
      },
      "source": [
        "def normalize_sequences(data, normalize=normalize):\n",
        "    \"\"\"\n",
        "    Combine the normalize title 1 & 2 into one column.\n",
        "    \"\"\"\n",
        "    # Normalize title 1 & 2 columns\n",
        "    data['title1_en_normalized'] = data['title1_en'].map(normalize)\n",
        "    data['title2_en_normalized'] = data['title2_en'].map(normalize)\n",
        "\n",
        "    # Combine train normalized title 1 & 2 columns into one column\n",
        "    data['title_1_2_normalized'] = \\\n",
        "        data['title1_en_normalized'].str.cat(data['title2_en_normalized'], sep=\" \")\n",
        "\n",
        "    return data.drop(columns=['id', 'tid1', 'tid2'], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0FDxK7Z76at"
      },
      "source": [
        "# Normalize train data\n",
        "data_train = normalize_sequences(data_train)\n",
        "\n",
        "# Normalize validation data\n",
        "data_val = normalize_sequences(data_val)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB3cqGQZpyeB"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "### 1.4 Vectorizing the text feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbm5L2860T9O"
      },
      "source": [
        "def create_tokenizer(data, num_words):\n",
        "    \"\"\"\n",
        "    Create a vectorizer with vocabulary size of num_words.\n",
        "    \"\"\"\n",
        "    # Create a tokenizer object\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=num_words, lower=False)\n",
        "    # Fit the tokenizer on train text\n",
        "    tokenizer.fit_on_texts(data['title_1_2_normalized'].values)\n",
        "\n",
        "    return tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aBSzESPFAJJ"
      },
      "source": [
        "def vectorize_sequences(data, tokenizer, max_length):\n",
        "    \"\"\"\n",
        "    Vectorize data.\n",
        "    \"\"\"\n",
        "    # Transform text to a sequence of integers\n",
        "    sequence = tokenizer.texts_to_sequences(data['title_1_2_normalized'].values)\n",
        "    # Pad the sequence with 0\n",
        "    X = tf.keras.preprocessing.sequence.pad_sequences(sequence, max_length)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnLC2r4Q8Rwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf18b01b-8d08-4e88-96f7-967d14bfbd76"
      },
      "source": [
        "# Max number of words\n",
        "num_words = 2000\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = create_tokenizer(data_train, num_words)\n",
        "\n",
        "# Sequece length\n",
        "max_length = 2**7\n",
        "\n",
        "# Vectorize train data\n",
        "X_train = vectorize_sequences(data_train, tokenizer, max_length)\n",
        "\n",
        "# Vectorize validation data\n",
        "X_val = vectorize_sequences(data_val, tokenizer, max_length)\n",
        "\n",
        "# Data quality check\n",
        "X_train.shape == (data_train.shape[0], max_length)\n",
        "X_val.shape == (data_val.shape[0], max_length)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yr7ppKHwa9H"
      },
      "source": [
        "<a id='1.5'></a>\n",
        "### 1.5 Encoding the categorical `label`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZorxq6-qFZT"
      },
      "source": [
        "def to_one_hot(data, num_classes, lab_2_int):\n",
        "    \"\"\"\n",
        "    One-hot encode labels.\n",
        "    \"\"\"\n",
        "    y = data['label'].map(lab_2_int)\n",
        "    y_one_hot = tf.keras.utils.to_categorical(y, num_classes)\n",
        "\n",
        "    return y, y_one_hot"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Ofybuz8ELl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f985c61-8440-4e94-99d8-5ad2ee90bc73"
      },
      "source": [
        "# Get target names\n",
        "target_names = data_train.label.unique().tolist()\n",
        "print(target_names)\n",
        "\n",
        "# unrelated -> 0, agreed -> 1, disagreed -> 2\n",
        "lab_2_int = dict(zip(target_names, range(3)))\n",
        "print(lab_2_int)\n",
        "\n",
        "# unrelated <- 0, agreed <- 1, disagreed <- 2\n",
        "int_2_lab = dict(zip(lab_2_int.values(), lab_2_int.keys()))\n",
        "print(int_2_lab)\n",
        "\n",
        "# Encode train label\n",
        "num_classes = len(target_names)\n",
        "y_train, y_train_one_hot = to_one_hot(data_train, num_classes, lab_2_int)\n",
        "\n",
        "# Encode validation label\n",
        "y_val, y_val_one_hot = to_one_hot(data_val, num_classes, lab_2_int)\n",
        "\n",
        "# Data quality check\n",
        "y_train_one_hot.shape == (y_train.shape[0], num_classes)\n",
        "y_val_one_hot.shape == (y_val.shape[0], num_classes)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['unrelated', 'agreed', 'disagreed']\n",
            "{'unrelated': 0, 'agreed': 1, 'disagreed': 2}\n",
            "{0: 'unrelated', 1: 'agreed', 2: 'disagreed'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3_OMP4ZzEAz"
      },
      "source": [
        "<a id='2'></a>\n",
        "## 2 Modeling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWiIB_yK9f6E"
      },
      "source": [
        "def kfold_cross_validation(X, y_one_hot, y,\n",
        "                           num_words,\n",
        "                           embedding_size,\n",
        "                           lstm_units,\n",
        "                           num_output=3,\n",
        "                           n_splits=3,\n",
        "                           target_names=['unrelated', 'agreed', 'disagreed']):\n",
        "    \"\"\"\n",
        "    Calculate f1-score using K-fold cross-validation.\n",
        "    \"\"\"\n",
        "    # Create stratified K-fold cross-validator\n",
        "    skf = StratifiedKFold(n_splits=n_splits, random_state=None)\n",
        "    # Store K-fold f1-score\n",
        "    k_f1 = np.array([0.0] * len(target_names))\n",
        "    # Counter for K\n",
        "    K = 0\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        # Extract train and test data\n",
        "        X_train = X[train_index]\n",
        "        y_train = y[train_index]\n",
        "        X_test = X[test_index]\n",
        "        y_test = y[test_index]\n",
        "        # Define a sequential model architecture\n",
        "        model = tf.keras.Sequential()\n",
        "        model.add(tf.keras.layers.Embedding(num_words, embedding_size, input_length=max_length))\n",
        "        model.add(tf.keras.layers.LSTM(lstm_units))\n",
        "        model.add(tf.keras.layers.Dense(num_output, activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        # Fit the model\n",
        "        model.fit(X, y_one_hot,\n",
        "                  batch_size=128,\n",
        "                  epochs=6,\n",
        "                  verbose=0)\n",
        "        # Predict label\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred = [np.argmax(y_hat) for y_hat in y_pred]\n",
        "        # Calculate f1-score\n",
        "        f1 = f1_score(y_test, y_pred, average=None)\n",
        "        f1 = f1.round(2)\n",
        "        k_f1 += f1\n",
        "        K += 1\n",
        "        # Print report\n",
        "        print(\"Fold {} f1-score {}:{} {}:{} {}:{}\".format(K,\n",
        "            target_names[0], f1[0],\n",
        "            target_names[1], f1[1],\n",
        "            target_names[2], f1[2]))\n",
        "    k_f1 = (k_f1 / n_splits).round(2)\n",
        "    print(\"Avg. f1-score {}:{} {}:{} {}:{}\".format(\n",
        "        target_names[0], k_f1[0],\n",
        "        target_names[1], k_f1[1],\n",
        "        target_names[2], k_f1[2]))\n",
        "    return k_f1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPrM1irqqthd"
      },
      "source": [
        "def train_lstm(X_train, y_train_one_hot,\n",
        "               X_val, y_val_one_hot,\n",
        "               max_features, \n",
        "               embedding_size,\n",
        "               max_length, \n",
        "               lstm_units,\n",
        "               model_name,\n",
        "               bidirection=False,\n",
        "               add_layer=False,\n",
        "               num_output=3, \n",
        "               epochs=15,\n",
        "               verbose=1,\n",
        "               batch_size=128,\n",
        "               model_path=MODEL_PATH):\n",
        "    \"\"\"\n",
        "    Define model architecture.\n",
        "    Complile the defined model.\n",
        "    Train the model with early stopping.\n",
        "    \"\"\"\n",
        "    # Define a sequential model architecture\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Embedding(max_features, embedding_size, input_length=max_length))\n",
        "    if bidirection:\n",
        "        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units)))\n",
        "    elif add_layer:\n",
        "        model.add(tf.keras.layers.LSTM(lstm_units, return_sequences=True))\n",
        "        model.add(tf.keras.layers.LSTM(lstm_units))\n",
        "    else:\n",
        "        model.add(tf.keras.layers.LSTM(lstm_units))\n",
        "    model.add(tf.keras.layers.Dense(num_output, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    model_name = os.path.join(model_path, model_name)\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(model_name, \n",
        "                                                    monitor='val_accuracy',\n",
        "                                                    mode='max',\n",
        "                                                    save_best_only=True)\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', \n",
        "                                                mode='max', \n",
        "                                                patience=2, \n",
        "                                                restore_best_weights=True)\n",
        "    history = model.fit(X_train, y_train_one_hot,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(X_val, y_val_one_hot),\n",
        "                        callbacks=[callback, checkpoint],\n",
        "                        verbose=verbose)\n",
        "    return history, model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBLXuyBAlsgn"
      },
      "source": [
        "def predict_lstm(model, X, y):\n",
        "    \"\"\"\n",
        "    Calculate the f1 score on categories of label.\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X)\n",
        "    y_pred = [np.argmax(y_hat) for y_hat in y_pred]\n",
        "    return (f1_score(y, y_pred, average=None)).round(2).tolist()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6sWkxEY3zNG"
      },
      "source": [
        "def store_score(df, score):\n",
        "    \"\"\"\n",
        "    Store model params and f1 scores into a dataframe.\n",
        "    \"\"\"\n",
        "    to_append = pd.Series(score, index=df.columns)\n",
        "    return df.append(to_append, ignore_index=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zSdEg1-m9wJ"
      },
      "source": [
        "def tune_hyperparams(X_train, \n",
        "                     y_train_one_hot,\n",
        "                     X_val, \n",
        "                     y_val_one_hot, \n",
        "                     y_val,\n",
        "                     num_words, \n",
        "                     embedding_size,\n",
        "                     max_length, \n",
        "                     lstm_units,\n",
        "                     model_name, \n",
        "                     layer_name, \n",
        "                     num_layers, \n",
        "                     bidirection=False, \n",
        "                     add_layer=False,\n",
        "                     model_path=MODEL_PATH,\n",
        "                     train_lstm=train_lstm,\n",
        "                     predict_lstm=predict_lstm):\n",
        "    \"\"\"\n",
        "    Tune the hyperparamers of a model.\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    model_name = os.path.join(model_path, model_name + '.h5')\n",
        "    hist, model = train_lstm(X_train, y_train_one_hot, \n",
        "                              X_val, y_val_one_hot,\n",
        "                              num_words,\n",
        "                              embedding_size,\n",
        "                              max_length,\n",
        "                              lstm_units,\n",
        "                              model_name,\n",
        "                              bidirection,\n",
        "                              add_layer)\n",
        "\n",
        "    # Calculate f1 score on validation set\n",
        "    res = predict_lstm(model, X_val, y_val)\n",
        "\n",
        "    # Store params and f1 score into a dataframe\n",
        "    if bidirection:\n",
        "      lstm_units *= 2\n",
        "      layer_name = \"Bi-LSTM\"\n",
        "    if add_layer:\n",
        "      num_layers *= 2\n",
        "    # Create hyperparameter values entry\n",
        "    res = [num_words, max_length, embedding_size, lstm_units, layer_name, num_layers] + res\n",
        "\n",
        "    return [hist, model, res]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKBZCseQ99uu"
      },
      "source": [
        "# Set up model params\n",
        "embedding_size = 2**6\n",
        "lstm_units = 2**5"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxuTMt95QWMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55663f2d-b5be-4686-8721-b3b2a541c0b9"
      },
      "source": [
        "# Cross validate the model on train data\n",
        "res = kfold_cross_validation(X_train, y_train_one_hot, y_train, \n",
        "                             num_words, embedding_size, lstm_units)\n",
        "res"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 1 f1-score unrelated:0.89 agreed:0.75 disagreed:0.45\n",
            "Fold 2 f1-score unrelated:0.89 agreed:0.74 disagreed:0.48\n",
            "Fold 3 f1-score unrelated:0.89 agreed:0.76 disagreed:0.48\n",
            "Avg. f1-score unrelated:0.89 agreed:0.75 disagreed:0.47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.89, 0.75, 0.47])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHNt0_Vz_2JP"
      },
      "source": [
        "<a id='3'></a>\n",
        "## 3 Fine-tuning model hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSXNzka7prkZ"
      },
      "source": [
        "<a id='3.1'></a>\n",
        "### 3.1 Starting with baseline LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuh2JdGuNTk"
      },
      "source": [
        "# A dict to store the train hist, model and score\n",
        "hist_dict = {}\n",
        "\n",
        "# A dataframe to score f1 score \n",
        "scores = pd.DataFrame(\n",
        "    columns=[\n",
        "             'vocabulary', 'sequence', 'embedding', \n",
        "             'units', 'layer', 'n_lyaer', 'unrelated', \n",
        "             'agreed', 'disagreed'])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmW1CJkLpvIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "outputId": "bcaf776d-d986-47ba-ab25-36236f11b4e5"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_2_7_6_5\"\n",
        "layer_name = \"LSTM\"\n",
        "num_layers = 1\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 128, 64)           128000    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 140,515\n",
            "Trainable params: 140,515\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 18s 12ms/step - loss: 0.5630 - accuracy: 0.7345 - val_loss: 0.5172 - val_accuracy: 0.7558\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.4942 - accuracy: 0.7655 - val_loss: 0.4891 - val_accuracy: 0.7695\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.4631 - accuracy: 0.7844 - val_loss: 0.4763 - val_accuracy: 0.7789\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.4363 - accuracy: 0.7994 - val_loss: 0.4646 - val_accuracy: 0.7875\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.4124 - accuracy: 0.8131 - val_loss: 0.4535 - val_accuracy: 0.7953\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.3911 - accuracy: 0.8252 - val_loss: 0.4471 - val_accuracy: 0.7996\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.3721 - accuracy: 0.8355 - val_loss: 0.4474 - val_accuracy: 0.8028\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 16s 10ms/step - loss: 0.3545 - accuracy: 0.8448 - val_loss: 0.4493 - val_accuracy: 0.8010\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.3378 - accuracy: 0.8538 - val_loss: 0.4484 - val_accuracy: 0.8065\n",
            "Epoch 10/15\n",
            "1503/1503 [==============================] - 16s 10ms/step - loss: 0.3212 - accuracy: 0.8621 - val_loss: 0.4675 - val_accuracy: 0.8058\n",
            "Epoch 11/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.3067 - accuracy: 0.8695 - val_loss: 0.4605 - val_accuracy: 0.8080\n",
            "Epoch 12/15\n",
            "1503/1503 [==============================] - 16s 10ms/step - loss: 0.2917 - accuracy: 0.8764 - val_loss: 0.4707 - val_accuracy: 0.8072\n",
            "Epoch 13/15\n",
            "1503/1503 [==============================] - 16s 11ms/step - loss: 0.2781 - accuracy: 0.8835 - val_loss: 0.4812 - val_accuracy: 0.8090\n",
            "Epoch 14/15\n",
            "1503/1503 [==============================] - 16s 10ms/step - loss: 0.2641 - accuracy: 0.8903 - val_loss: 0.4875 - val_accuracy: 0.8077\n",
            "Epoch 15/15\n",
            "1503/1503 [==============================] - 16s 10ms/step - loss: 0.2514 - accuracy: 0.8959 - val_loss: 0.5093 - val_accuracy: 0.8054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32  LSTM       1       0.87    0.69   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM5oYHnYlbE4"
      },
      "source": [
        "#### Increasing embedding size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMOE0-VWlJI6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "outputId": "39f945ba-0ba3-432d-bab8-ee74cedb7abf"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_2_7_7_5\"\n",
        "embedding_size *= 2\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 128, 128)          256000    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                20608     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 276,707\n",
            "Trainable params: 276,707\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.5533 - accuracy: 0.7369 - val_loss: 0.5095 - val_accuracy: 0.7584\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 19s 13ms/step - loss: 0.4800 - accuracy: 0.7750 - val_loss: 0.4742 - val_accuracy: 0.7778\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.4380 - accuracy: 0.7996 - val_loss: 0.4565 - val_accuracy: 0.7906\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.4053 - accuracy: 0.8181 - val_loss: 0.4551 - val_accuracy: 0.7962\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.3788 - accuracy: 0.8332 - val_loss: 0.4477 - val_accuracy: 0.8032\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.3542 - accuracy: 0.8467 - val_loss: 0.4417 - val_accuracy: 0.8062\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.3322 - accuracy: 0.8574 - val_loss: 0.4474 - val_accuracy: 0.8074\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.3125 - accuracy: 0.8669 - val_loss: 0.4515 - val_accuracy: 0.8076\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.2938 - accuracy: 0.8764 - val_loss: 0.4615 - val_accuracy: 0.8118\n",
            "Epoch 10/15\n",
            "1503/1503 [==============================] - 20s 13ms/step - loss: 0.2762 - accuracy: 0.8851 - val_loss: 0.4739 - val_accuracy: 0.8138\n",
            "Epoch 11/15\n",
            "1503/1503 [==============================] - 19s 13ms/step - loss: 0.2597 - accuracy: 0.8924 - val_loss: 0.4871 - val_accuracy: 0.8125\n",
            "Epoch 12/15\n",
            "1503/1503 [==============================] - 19s 13ms/step - loss: 0.2431 - accuracy: 0.8999 - val_loss: 0.5006 - val_accuracy: 0.8134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32  LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32  LSTM       1       0.87    0.71   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO6xHotFxm2T"
      },
      "source": [
        "#### Increasing LSTM units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaDbgHgYxmg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "e5baa70a-944d-4c61-fc04-fa43d5301a85"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_2_7_7_6\"\n",
        "lstm_units *= 2\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 128, 128)          256000    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 305,603\n",
            "Trainable params: 305,603\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 22s 14ms/step - loss: 0.5530 - accuracy: 0.7348 - val_loss: 0.5110 - val_accuracy: 0.7551\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.4807 - val_accuracy: 0.7722\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.4434 - accuracy: 0.7955 - val_loss: 0.4580 - val_accuracy: 0.7881\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.4105 - accuracy: 0.8148 - val_loss: 0.4545 - val_accuracy: 0.7955\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.3817 - accuracy: 0.8317 - val_loss: 0.4422 - val_accuracy: 0.8058\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.3552 - accuracy: 0.8454 - val_loss: 0.4338 - val_accuracy: 0.8081\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.3304 - accuracy: 0.8579 - val_loss: 0.4403 - val_accuracy: 0.8109\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.3067 - accuracy: 0.8701 - val_loss: 0.4460 - val_accuracy: 0.8120\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.2838 - accuracy: 0.8811 - val_loss: 0.4497 - val_accuracy: 0.8131\n",
            "Epoch 10/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.2620 - accuracy: 0.8902 - val_loss: 0.4703 - val_accuracy: 0.8167\n",
            "Epoch 11/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.2414 - accuracy: 0.9009 - val_loss: 0.4950 - val_accuracy: 0.8160\n",
            "Epoch 12/15\n",
            "1503/1503 [==============================] - 21s 14ms/step - loss: 0.2201 - accuracy: 0.9103 - val_loss: 0.5210 - val_accuracy: 0.8156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32  LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32  LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64  LSTM       1       0.87    0.70   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5C09d_a0JAM"
      },
      "source": [
        "#### Using bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObRbYWNP0Mdw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "87e33baf-1d76-4f22-86da-0c6b84532b31"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_2_7_7_6_bi\"\n",
        "bidirection = True\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, \n",
        "                                         num_layers, bidirection)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 128, 128)          256000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 355,203\n",
            "Trainable params: 355,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 33s 22ms/step - loss: 0.5485 - accuracy: 0.7356 - val_loss: 0.5080 - val_accuracy: 0.7565\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.4811 - accuracy: 0.7735 - val_loss: 0.4806 - val_accuracy: 0.7724\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.4420 - accuracy: 0.7973 - val_loss: 0.4571 - val_accuracy: 0.7896\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 33s 22ms/step - loss: 0.4090 - accuracy: 0.8156 - val_loss: 0.4525 - val_accuracy: 0.7981\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 33s 22ms/step - loss: 0.3790 - accuracy: 0.8327 - val_loss: 0.4460 - val_accuracy: 0.8038\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 32s 22ms/step - loss: 0.3516 - accuracy: 0.8467 - val_loss: 0.4402 - val_accuracy: 0.8081\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 33s 22ms/step - loss: 0.3266 - accuracy: 0.8598 - val_loss: 0.4442 - val_accuracy: 0.8099\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.3027 - accuracy: 0.8716 - val_loss: 0.4543 - val_accuracy: 0.8097\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 32s 22ms/step - loss: 0.2795 - accuracy: 0.8830 - val_loss: 0.4571 - val_accuracy: 0.8129\n",
            "Epoch 10/15\n",
            "1503/1503 [==============================] - 32s 22ms/step - loss: 0.2570 - accuracy: 0.8938 - val_loss: 0.4845 - val_accuracy: 0.8143\n",
            "Epoch 11/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.2363 - accuracy: 0.9028 - val_loss: 0.4993 - val_accuracy: 0.8146\n",
            "Epoch 12/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.2153 - accuracy: 0.9123 - val_loss: 0.5320 - val_accuracy: 0.8144\n",
            "Epoch 13/15\n",
            "1503/1503 [==============================] - 32s 21ms/step - loss: 0.1967 - accuracy: 0.9213 - val_loss: 0.5547 - val_accuracy: 0.8117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F8qjDz0KkOJ"
      },
      "source": [
        "<a id='3.2'></a>\n",
        "### 3.2 Increasing vocabulary size and sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZbEI5JlKVYL"
      },
      "source": [
        "# Max number of words\n",
        "num_words = 5000\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = create_tokenizer(data_train, num_words)\n",
        "\n",
        "# Sequece length\n",
        "max_length = 256\n",
        "\n",
        "# Vectorize train data\n",
        "X_train = vectorize_sequences(data_train, tokenizer, max_length)\n",
        "\n",
        "# Vectorize validation data\n",
        "X_val = vectorize_sequences(data_val, tokenizer, max_length)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCVD4of5_PqP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "85c906b4-1cd8-4406-a1a3-6daa66b3de36"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_5_8_8_7\"\n",
        "embedding_size = 256\n",
        "lstm_units = 128\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 256, 256)          1280000   \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,477,507\n",
            "Trainable params: 1,477,507\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 67s 44ms/step - loss: 0.5199 - accuracy: 0.7553 - val_loss: 0.4715 - val_accuracy: 0.7793\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 66s 44ms/step - loss: 0.4304 - accuracy: 0.8031 - val_loss: 0.4367 - val_accuracy: 0.8008\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 66s 44ms/step - loss: 0.3756 - accuracy: 0.8320 - val_loss: 0.4222 - val_accuracy: 0.8118\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 66s 44ms/step - loss: 0.3291 - accuracy: 0.8558 - val_loss: 0.4196 - val_accuracy: 0.8196\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 66s 44ms/step - loss: 0.2857 - accuracy: 0.8773 - val_loss: 0.4295 - val_accuracy: 0.8246\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 65s 44ms/step - loss: 0.2456 - accuracy: 0.8966 - val_loss: 0.4396 - val_accuracy: 0.8230\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 66s 44ms/step - loss: 0.2086 - accuracy: 0.9136 - val_loss: 0.4866 - val_accuracy: 0.8256\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 65s 43ms/step - loss: 0.1733 - accuracy: 0.9296 - val_loss: 0.5261 - val_accuracy: 0.8196\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 65s 43ms/step - loss: 0.1433 - accuracy: 0.9429 - val_loss: 0.5795 - val_accuracy: 0.8227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "4       5000      256       256   128     LSTM       1       0.88    0.73   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  \n",
              "4       0.49  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN6tqRBk4Fik"
      },
      "source": [
        "#### Using bi-directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMUEsP2x4c4O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "51b06e5b-3870-47bd-9021-b87dce6dd4a6"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_5_8_8_7_bi\"\n",
        "bidirection = True\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, \n",
        "                                         num_layers, bidirection)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 256, 256)          1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 1,675,011\n",
            "Trainable params: 1,675,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 108s 72ms/step - loss: 0.5140 - accuracy: 0.7568 - val_loss: 0.4666 - val_accuracy: 0.7826\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 106s 71ms/step - loss: 0.4230 - accuracy: 0.8072 - val_loss: 0.4335 - val_accuracy: 0.8033\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 106s 71ms/step - loss: 0.3678 - accuracy: 0.8369 - val_loss: 0.4179 - val_accuracy: 0.8157\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 107s 71ms/step - loss: 0.3186 - accuracy: 0.8621 - val_loss: 0.4178 - val_accuracy: 0.8233\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 107s 71ms/step - loss: 0.2738 - accuracy: 0.8826 - val_loss: 0.4285 - val_accuracy: 0.8248\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 107s 71ms/step - loss: 0.2336 - accuracy: 0.9017 - val_loss: 0.4559 - val_accuracy: 0.8251\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 107s 71ms/step - loss: 0.1962 - accuracy: 0.9187 - val_loss: 0.4918 - val_accuracy: 0.8272\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 106s 71ms/step - loss: 0.1624 - accuracy: 0.9340 - val_loss: 0.5549 - val_accuracy: 0.8199\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 106s 71ms/step - loss: 0.1342 - accuracy: 0.9465 - val_loss: 0.5910 - val_accuracy: 0.8236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "4       5000      256       256   128     LSTM       1       0.88    0.73   \n",
              "5       5000      256       256   256  Bi-LSTM       1       0.88    0.73   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  \n",
              "4       0.49  \n",
              "5       0.50  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0NX_JTP4Lgj"
      },
      "source": [
        "#### Adding additional LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msi5lTEgzt3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "81e6b79e-3400-4b4c-d709-695ab8288c66"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_5_8_8_7_2\"\n",
        "bidirection = False\n",
        "add_layer = True\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, \n",
        "                                         num_layers, bidirection, add_layer)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 256, 256)          1280000   \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 256, 128)          197120    \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 1,609,091\n",
            "Trainable params: 1,609,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 101s 67ms/step - loss: 0.5179 - accuracy: 0.7558 - val_loss: 0.4689 - val_accuracy: 0.7830\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 100s 67ms/step - loss: 0.4257 - accuracy: 0.8070 - val_loss: 0.4345 - val_accuracy: 0.8036\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 100s 66ms/step - loss: 0.3701 - accuracy: 0.8375 - val_loss: 0.4136 - val_accuracy: 0.8163\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 100s 67ms/step - loss: 0.3215 - accuracy: 0.8628 - val_loss: 0.4106 - val_accuracy: 0.8240\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 100s 66ms/step - loss: 0.2774 - accuracy: 0.8834 - val_loss: 0.4258 - val_accuracy: 0.8269\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 101s 67ms/step - loss: 0.2362 - accuracy: 0.9020 - val_loss: 0.4380 - val_accuracy: 0.8277\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 100s 67ms/step - loss: 0.1995 - accuracy: 0.9181 - val_loss: 0.4738 - val_accuracy: 0.8279\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 100s 66ms/step - loss: 0.1654 - accuracy: 0.9333 - val_loss: 0.5284 - val_accuracy: 0.8224\n",
            "Epoch 9/15\n",
            "1503/1503 [==============================] - 100s 66ms/step - loss: 0.1346 - accuracy: 0.9467 - val_loss: 0.5791 - val_accuracy: 0.8261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "4       5000      256       256   128     LSTM       1       0.88    0.73   \n",
              "5       5000      256       256   256  Bi-LSTM       1       0.88    0.73   \n",
              "6       5000      256       256   128     LSTM       2       0.88    0.73   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  \n",
              "4       0.49  \n",
              "5       0.50  \n",
              "6       0.47  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRwVRBdQlXdb"
      },
      "source": [
        "#### Increasing LSTM units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "w7lR6fHZlfdm",
        "outputId": "890f3398-e448-4862-dea8-4fec87da0cd8"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_5_8_8_8\"\n",
        "embedding_size = 256\n",
        "lstm_units = 256\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 256, 256)          1280000   \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 1,806,083\n",
            "Trainable params: 1,806,083\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 90s 60ms/step - loss: 0.5274 - accuracy: 0.7498 - val_loss: 0.4778 - val_accuracy: 0.7762\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 89s 59ms/step - loss: 0.4403 - accuracy: 0.7980 - val_loss: 0.4424 - val_accuracy: 0.7950\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 89s 59ms/step - loss: 0.3855 - accuracy: 0.8255 - val_loss: 0.4253 - val_accuracy: 0.8088\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 89s 59ms/step - loss: 0.3378 - accuracy: 0.8513 - val_loss: 0.4245 - val_accuracy: 0.8177\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 89s 59ms/step - loss: 0.2944 - accuracy: 0.8734 - val_loss: 0.4248 - val_accuracy: 0.8237\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 89s 59ms/step - loss: 0.2543 - accuracy: 0.8927 - val_loss: 0.4327 - val_accuracy: 0.8252\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 88s 59ms/step - loss: 0.2158 - accuracy: 0.9098 - val_loss: 0.4666 - val_accuracy: 0.8243\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 88s 59ms/step - loss: 0.1794 - accuracy: 0.9258 - val_loss: 0.5222 - val_accuracy: 0.8222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "4       5000      256       256   128     LSTM       1       0.88    0.73   \n",
              "5       5000      256       256   256  Bi-LSTM       1       0.88    0.73   \n",
              "6       5000      256       256   128     LSTM       2       0.88    0.73   \n",
              "7       5000      256       256   256     LSTM       1       0.88    0.72   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  \n",
              "4       0.49  \n",
              "5       0.50  \n",
              "6       0.47  \n",
              "7       0.49  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raZ1KlIY79bG"
      },
      "source": [
        "#### Increasing the vocabulary and embedding size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLXDiVCb4Sze"
      },
      "source": [
        "# Max number of words\n",
        "num_words = 8000\n",
        "\n",
        "# Create a tokenizer\n",
        "tokenizer = create_tokenizer(data_train, num_words)\n",
        "\n",
        "# Sequece length\n",
        "max_length = 256\n",
        "\n",
        "# Vectorize train data\n",
        "X_train = vectorize_sequences(data_train, tokenizer, max_length)\n",
        "\n",
        "# Vectorize validation data\n",
        "X_val = vectorize_sequences(data_val, tokenizer, max_length)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jhg9lRM8FcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "b2d30835-4089-4c6e-b49c-052005393411"
      },
      "source": [
        "# Pamas to tune the model\n",
        "model_name = \"mod_10_8_8_8\"\n",
        "embedding_size = 512\n",
        "lstm_units = 256\n",
        "\n",
        "# Tune the model\n",
        "hist_dict[model_name] = tune_hyperparams(X_train, y_train_one_hot,\n",
        "                                         X_val, y_val_one_hot, y_val,\n",
        "                                         num_words, embedding_size, max_length, \n",
        "                                         lstm_units, model_name, layer_name, num_layers)\n",
        "\n",
        "# Show f1 score by labels\n",
        "scores = store_score(scores, hist_dict[model_name][2])\n",
        "scores"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 256, 512)          4096000   \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 256)               787456    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 4,884,227\n",
            "Trainable params: 4,884,227\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "1503/1503 [==============================] - 137s 91ms/step - loss: 0.5079 - accuracy: 0.7621 - val_loss: 0.4582 - val_accuracy: 0.7895\n",
            "Epoch 2/15\n",
            "1503/1503 [==============================] - 135s 90ms/step - loss: 0.4025 - accuracy: 0.8191 - val_loss: 0.4220 - val_accuracy: 0.8123\n",
            "Epoch 3/15\n",
            "1503/1503 [==============================] - 136s 91ms/step - loss: 0.3366 - accuracy: 0.8529 - val_loss: 0.4127 - val_accuracy: 0.8184\n",
            "Epoch 4/15\n",
            "1503/1503 [==============================] - 135s 90ms/step - loss: 0.2801 - accuracy: 0.8793 - val_loss: 0.4252 - val_accuracy: 0.8271\n",
            "Epoch 5/15\n",
            "1503/1503 [==============================] - 137s 91ms/step - loss: 0.2288 - accuracy: 0.9034 - val_loss: 0.4564 - val_accuracy: 0.8295\n",
            "Epoch 6/15\n",
            "1503/1503 [==============================] - 135s 90ms/step - loss: 0.1831 - accuracy: 0.9242 - val_loss: 0.4965 - val_accuracy: 0.8297\n",
            "Epoch 7/15\n",
            "1503/1503 [==============================] - 136s 90ms/step - loss: 0.1433 - accuracy: 0.9416 - val_loss: 0.5634 - val_accuracy: 0.8283\n",
            "Epoch 8/15\n",
            "1503/1503 [==============================] - 135s 90ms/step - loss: 0.1086 - accuracy: 0.9570 - val_loss: 0.6333 - val_accuracy: 0.8238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>sequence</th>\n",
              "      <th>embedding</th>\n",
              "      <th>units</th>\n",
              "      <th>layer</th>\n",
              "      <th>n_lyaer</th>\n",
              "      <th>unrelated</th>\n",
              "      <th>agreed</th>\n",
              "      <th>disagreed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>32</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>64</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>128</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>128</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>2</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5000</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>256</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8000</td>\n",
              "      <td>256</td>\n",
              "      <td>512</td>\n",
              "      <td>256</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>1</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  vocabulary sequence embedding units    layer n_lyaer  unrelated  agreed  \\\n",
              "0       2000      128        64    32     LSTM       1       0.87    0.69   \n",
              "1       2000      128       128    32     LSTM       1       0.87    0.71   \n",
              "2       2000      128       128    64     LSTM       1       0.87    0.70   \n",
              "3       2000      128       128   128  Bi-LSTM       1       0.87    0.71   \n",
              "4       5000      256       256   128     LSTM       1       0.88    0.73   \n",
              "5       5000      256       256   256  Bi-LSTM       1       0.88    0.73   \n",
              "6       5000      256       256   128     LSTM       2       0.88    0.73   \n",
              "7       5000      256       256   256     LSTM       1       0.88    0.72   \n",
              "8       8000      256       512   256     LSTM       1       0.88    0.74   \n",
              "\n",
              "   disagreed  \n",
              "0       0.43  \n",
              "1       0.42  \n",
              "2       0.44  \n",
              "3       0.42  \n",
              "4       0.49  \n",
              "5       0.50  \n",
              "6       0.47  \n",
              "7       0.49  \n",
              "8       0.52  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzPXsA21wYhr"
      },
      "source": [
        "<a id='4'></a>\n",
        "## 4 Assessing final model performance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AnFIbXewq0j"
      },
      "source": [
        "def plot_performance(hist, metric='loss', figsize=(12,8),):\n",
        "    \"\"\"\n",
        "    Plot the model training and validation performance.\n",
        "    \"\"\"\n",
        "    if metric == 'loss':\n",
        "        ylabel = 'Loss'\n",
        "        title = 'Training and Validation Loss'\n",
        "        train_legend = 'Training Loss'\n",
        "        val_legend = 'Validation Loss'\n",
        "        train_metric = 'loss'\n",
        "        val_metric = 'val_loss'\n",
        "    else:\n",
        "        ylabel = 'Accuracy'\n",
        "        title = 'Training and Validation Accuracy'\n",
        "        train_legend = 'Training Accuracy'\n",
        "        val_legend = 'Validation Accuracy'\n",
        "        train_metric = 'accuracy'\n",
        "        val_metric = 'val_accuracy'\n",
        "    train = hist.history[train_metric]\n",
        "    val = hist.history[val_metric]\n",
        "    epochs = range(1, len(val) + 1)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(epochs, train, 'bo', label=train_legend)\n",
        "    plt.plot(epochs, val, 'b', label=val_legend)\n",
        "    plt.title(title, fontsize=24)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y5a9lavDvc_9",
        "outputId": "32a1b421-3b74-4b96-82b7-38190151ff0e"
      },
      "source": [
        "# Extract the best model training history\n",
        "hist = hist_dict['mod_5_8_8_7'][0]\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plot_performance(hist)\n",
        "\n",
        "# Plot the training and validation accuracy\n",
        "plot_performance(hist, 'accuracy')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiVFRDCI7W8F"
      },
      "source": [
        "<a id='5'></a>\n",
        "## 5 Saving training history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iee7ugC01qFS"
      },
      "source": [
        "def to_pickle(data, filename, base_path=MODEL_PATH):\n",
        "    \"\"\"\n",
        "    Save data as .pkl file.\n",
        "    \"\"\"\n",
        "    filename = os.path.join(base_path, filename)\n",
        "    outfile = open(filename,'wb')\n",
        "    pickle.dump(data, outfile)\n",
        "    outfile.close()\n",
        "\n",
        "def load_pickle(filename, base_path=MODEL_PATH):\n",
        "    \"\"\"\n",
        "    Load .pkl file.\n",
        "    \"\"\"\n",
        "    filename = os.path.join(base_path, filename)\n",
        "    infile = open(filename,'rb')\n",
        "    data = pickle.load(infile)\n",
        "    infile.close()\n",
        "    return data"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmRaLH_z4V2q"
      },
      "source": [
        "# Save model training history as .pkl files\n",
        "hist_to_pickle = {}\n",
        "for k, v in hist_dict.items():\n",
        "  hist_to_pickle[k] = v[0].history\n",
        "to_pickle(hist_to_pickle, 'training_history.pkl')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ua66rol8VRg"
      },
      "source": [
        "# Save hyperparameters tuning results\n",
        "scores.to_csv(os.path.join(DATA_PATH, 'tuning_results.csv'), index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}